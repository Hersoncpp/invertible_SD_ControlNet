nohup: ignoring input
25-09-27 13:05:35.598 - INFO: DataParallel(
  (module): Model(
    (model): Hinet(
      (inv1): INV_block(
        (r): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (y): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (f): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
      (inv2): INV_block(
        (r): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (y): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (f): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
      (inv3): INV_block(
        (r): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (y): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (f): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
      (inv4): INV_block(
        (r): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (y): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (f): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
      (inv5): INV_block(
        (r): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (y): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (f): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
      (inv6): INV_block(
        (r): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (y): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (f): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
      (inv7): INV_block(
        (r): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (y): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (f): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
      (inv8): INV_block(
        (r): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (y): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (f): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
      (inv9): INV_block(
        (r): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (y): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (f): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
      (inv10): INV_block(
        (r): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (y): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (f): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
      (inv11): INV_block(
        (r): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (y): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (f): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
      (inv12): INV_block(
        (r): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (y): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (f): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
      (inv13): INV_block(
        (r): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (y): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (f): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
      (inv14): INV_block(
        (r): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (y): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (f): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
      (inv15): INV_block(
        (r): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (y): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (f): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
      (inv16): INV_block(
        (r): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (y): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (f): ResidualDenseBlock_out(
          (conv1): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): Conv2d(44, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv3): Conv2d(76, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv4): Conv2d(108, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv5): Conv2d(140, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
  )
)
Loaded 103 data from /home/hesong/disk1/DF_INV/code/ControlNet-v1-1-nightly/inv_modules/IVOP/codes/data/dataset/ControlNet_ST/prompts.json
Loaded 103 data from /home/hesong/disk1/DF_INV/code/ControlNet-v1-1-nightly/inv_modules/IVOP/codes/data/dataset/ControlNet_ST/prompts.json
==========================================================================================
Config options:

  IMAGE_PATH               	/home/hesong/disk1/DF_INV/code/ControlNet-v1-1-nightly/inv_modules/HiNet/image/
  IMAGE_PATH_cover         	/home/hesong/disk1/DF_INV/code/ControlNet-v1-1-nightly/inv_modules/HiNet/image/cover/
  IMAGE_PATH_secret        	/home/hesong/disk1/DF_INV/code/ControlNet-v1-1-nightly/inv_modules/HiNet/image/secret/
  IMAGE_PATH_secret_rev    	/home/hesong/disk1/DF_INV/code/ControlNet-v1-1-nightly/inv_modules/HiNet/image/secret-rev/
  IMAGE_PATH_steg          	/home/hesong/disk1/DF_INV/code/ControlNet-v1-1-nightly/inv_modules/HiNet/image/steg/
  MODEL_PATH               	/home/hesong/disk1/DF_INV/code/ControlNet-v1-1-nightly/inv_modules/HiNet/model/
  SAVE_freq                	50
  TRAIN_JSON_PATH          	/home/hesong/disk1/DF_INV/code/ControlNet-v1-1-nightly/inv_modules/IVOP/codes/data/dataset/ControlNet_ST/prompts.json
  VAL_JSON_PATH            	/home/hesong/disk1/DF_INV/code/ControlNet-v1-1-nightly/inv_modules/IVOP/codes/data/dataset/ControlNet_ST/prompts.json
  batch_size               	8
  batchsize_val            	2
  betas                    	(0.5, 0.999)
  channels_in              	3
  checkpoint_on_error      	True
  clamp                    	2.0
  cropsize                 	192
  cropsize_val             	1024
  device_ids               	[3]
  epochs                   	1000
  format_train             	png
  format_val               	png
  gamma                    	0.5
  init_scale               	0.01
  lamda_guide              	1
  lamda_low_frequency      	1
  lamda_reconstruction     	5
  live_visualization       	False
  log10_lr                 	-4.5
  loss_display_cutoff      	2.0
  loss_names               	['L', 'lr']
  lr                       	3.1622776601683795e-05
  progress_bar             	False
  save_suffix              	partial
  shuffle_val              	False
  silent                   	False
  suffix                   	modelmodel_checkpoint_00100.pt
  tain_next                	False
  trained_epoch            	0
  val_freq                 	50
  weight_decay             	1e-05
  weight_step              	1000
==========================================================================================

Epoch		L		lr
{'Total': 4050240, 'Trainable': 4050240}
25-09-27 13:05:48.911 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:05:48.911 - INFO: Train epoch 1:   Loss: 3935150.8229 | r_Loss: 779897.8047 | g_Loss: 29571.9439 | l_Loss: 6089.9098 | 
                                                                                 001		3935150.8229		-4.5000
25-09-27 13:05:59.928 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:05:59.930 - INFO: Train epoch 2:   Loss: 1036724.8438 | r_Loss: 167101.4082 | g_Loss: 175908.6738 | l_Loss: 25309.1549 | 
                                                                                 002		1036724.8438		-4.5000
25-09-27 13:06:10.978 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:06:10.979 - INFO: Train epoch 3:   Loss: 416833.6667 | r_Loss: 71277.2109 | g_Loss: 56989.2969 | l_Loss: 3458.3170 | 
                                                                                 003		416833.6667		-4.5000
25-09-27 13:06:21.901 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:06:21.902 - INFO: Train epoch 4:   Loss: 300583.8802 | r_Loss: 53255.7721 | g_Loss: 32221.5548 | l_Loss: 2083.4648 | 
                                                                                 004		300583.8802		-4.5000
25-09-27 13:06:32.908 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:06:32.909 - INFO: Train epoch 5:   Loss: 232120.2109 | r_Loss: 40528.0918 | g_Loss: 27272.2730 | l_Loss: 2207.4797 | 
                                                                                 005		232120.2109		-4.5000
25-09-27 13:06:43.853 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:06:43.854 - INFO: Train epoch 6:   Loss: 190100.9310 | r_Loss: 32825.6279 | g_Loss: 23967.6720 | l_Loss: 2005.1229 | 
                                                                                 006		190100.9310		-4.5000
25-09-27 13:06:55.028 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:06:55.030 - INFO: Train epoch 7:   Loss: 180222.1979 | r_Loss: 32119.6647 | g_Loss: 18046.4862 | l_Loss: 1577.3875 | 
                                                                                 007		180222.1979		-4.5000
25-09-27 13:07:06.035 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:07:06.036 - INFO: Train epoch 8:   Loss: 143366.5990 | r_Loss: 25137.2127 | g_Loss: 16289.4887 | l_Loss: 1391.0460 | 
                                                                                 008		143366.5990		-4.5000
25-09-27 13:07:17.144 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:07:17.145 - INFO: Train epoch 9:   Loss: 301558.1328 | r_Loss: 56110.2729 | g_Loss: 19311.5767 | l_Loss: 1695.1917 | 
                                                                                 009		301558.1328		-4.5000
25-09-27 13:07:28.146 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:07:28.146 - INFO: Train epoch 10:   Loss: 251496.7891 | r_Loss: 47679.1012 | g_Loss: 11043.3110 | l_Loss: 2057.9735 | 
                                                                                 010		251496.7891		-4.5000
25-09-27 13:07:39.199 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:07:39.201 - INFO: Train epoch 11:   Loss: 148308.4147 | r_Loss: 26283.6141 | g_Loss: 15408.5949 | l_Loss: 1481.7495 | 
                                                                                 011		148308.4147		-4.5000
25-09-27 13:07:50.329 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:07:50.330 - INFO: Train epoch 12:   Loss: 134314.2337 | r_Loss: 23479.0088 | g_Loss: 15664.8845 | l_Loss: 1254.3045 | 
                                                                                 012		134314.2337		-4.5000
25-09-27 13:08:01.442 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:08:01.443 - INFO: Train epoch 13:   Loss: 118099.6745 | r_Loss: 20809.8966 | g_Loss: 13090.7944 | l_Loss: 959.3969 | 
                                                                                 013		118099.6745		-4.5000
25-09-27 13:08:12.605 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:08:12.606 - INFO: Train epoch 14:   Loss: 128516.5430 | r_Loss: 22990.4937 | g_Loss: 12694.4959 | l_Loss: 869.5781 | 
                                                                                 014		128516.5430		-4.5000
25-09-27 13:08:23.678 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:08:23.680 - INFO: Train epoch 15:   Loss: 120781.7298 | r_Loss: 21701.6939 | g_Loss: 11535.8390 | l_Loss: 737.4188 | 
                                                                                 015		120781.7298		-4.5000
25-09-27 13:08:35.028 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:08:35.029 - INFO: Train epoch 16:   Loss: 112236.1315 | r_Loss: 20157.7593 | g_Loss: 10796.1489 | l_Loss: 651.1878 | 
                                                                                 016		112236.1315		-4.5000
25-09-27 13:08:46.146 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:08:46.147 - INFO: Train epoch 17:   Loss: 113676.4173 | r_Loss: 20554.4741 | g_Loss: 10303.4594 | l_Loss: 600.5885 | 
                                                                                 017		113676.4173		-4.5000
25-09-27 13:08:57.479 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:08:57.481 - INFO: Train epoch 18:   Loss: 114243.2552 | r_Loss: 20768.8703 | g_Loss: 9867.1321 | l_Loss: 531.7712 | 
                                                                                 018		114243.2552		-4.5000
25-09-27 13:09:08.719 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:09:08.720 - INFO: Train epoch 19:   Loss: 101968.4238 | r_Loss: 18498.1207 | g_Loss: 8996.3999 | l_Loss: 481.4197 | 
                                                                                 019		101968.4238		-4.5000
25-09-27 13:09:19.835 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:09:19.837 - INFO: Train epoch 20:   Loss: 130239.7826 | r_Loss: 24074.1761 | g_Loss: 9384.3926 | l_Loss: 484.5090 | 
                                                                                 020		130239.7826		-4.5000
25-09-27 13:09:30.865 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:09:30.866 - INFO: Train epoch 21:   Loss: 103673.5872 | r_Loss: 18717.1714 | g_Loss: 9627.4729 | l_Loss: 460.2561 | 
                                                                                 021		103673.5872		-4.5000
25-09-27 13:09:42.141 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:09:42.142 - INFO: Train epoch 22:   Loss: 98836.3685 | r_Loss: 17941.3507 | g_Loss: 8693.2547 | l_Loss: 436.3610 | 
                                                                                 022		98836.3685		-4.5000
25-09-27 13:09:53.431 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:09:53.432 - INFO: Train epoch 23:   Loss: 117459.4792 | r_Loss: 21651.1587 | g_Loss: 8762.0610 | l_Loss: 441.6275 | 
                                                                                 023		117459.4792		-4.5000
25-09-27 13:10:04.622 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:10:04.623 - INFO: Train epoch 24:   Loss: 90511.3620 | r_Loss: 16308.1347 | g_Loss: 8571.0236 | l_Loss: 399.6652 | 
                                                                                 024		90511.3620		-4.5000
25-09-27 13:10:15.838 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:10:15.840 - INFO: Train epoch 25:   Loss: 97500.4642 | r_Loss: 17771.7209 | g_Loss: 8228.4395 | l_Loss: 413.4203 | 
                                                                                 025		97500.4642		-4.5000
25-09-27 13:10:27.067 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:10:27.068 - INFO: Train epoch 26:   Loss: 89878.8060 | r_Loss: 16364.4381 | g_Loss: 7696.6291 | l_Loss: 359.9874 | 
                                                                                 026		89878.8060		-4.5000
25-09-27 13:10:38.258 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:10:38.259 - INFO: Train epoch 27:   Loss: 93519.0977 | r_Loss: 17119.3003 | g_Loss: 7548.3831 | l_Loss: 374.2131 | 
                                                                                 027		93519.0977		-4.5000
25-09-27 13:10:49.388 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:10:49.389 - INFO: Train epoch 28:   Loss: 89561.6432 | r_Loss: 16415.7914 | g_Loss: 7120.6359 | l_Loss: 362.0528 | 
                                                                                 028		89561.6432		-4.5000
25-09-27 13:11:00.482 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:11:00.483 - INFO: Train epoch 29:   Loss: 96155.7236 | r_Loss: 17658.2760 | g_Loss: 7510.1500 | l_Loss: 354.1919 | 
                                                                                 029		96155.7236		-4.5000
25-09-27 13:11:11.588 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:11:11.589 - INFO: Train epoch 30:   Loss: 86391.2292 | r_Loss: 15797.8237 | g_Loss: 7053.8334 | l_Loss: 348.2790 | 
                                                                                 030		86391.2292		-4.5000
25-09-27 13:11:22.663 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:11:22.664 - INFO: Train epoch 31:   Loss: 106408.5592 | r_Loss: 19710.3582 | g_Loss: 7481.6174 | l_Loss: 375.1492 | 
                                                                                 031		106408.5592		-4.5000
25-09-27 13:11:33.948 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:11:33.949 - INFO: Train epoch 32:   Loss: 91184.6891 | r_Loss: 16643.3521 | g_Loss: 7554.0876 | l_Loss: 413.8391 | 
                                                                                 032		91184.6891		-4.5000
25-09-27 13:11:45.096 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:11:45.097 - INFO: Train epoch 33:   Loss: 79860.9538 | r_Loss: 14507.6215 | g_Loss: 6975.6853 | l_Loss: 347.1620 | 
                                                                                 033		79860.9538		-4.5000
25-09-27 13:11:56.246 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:11:56.247 - INFO: Train epoch 34:   Loss: 79459.7064 | r_Loss: 14527.3835 | g_Loss: 6471.8350 | l_Loss: 350.9538 | 
                                                                                 034		79459.7064		-4.5000
25-09-27 13:12:07.535 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:12:07.536 - INFO: Train epoch 35:   Loss: 82762.4762 | r_Loss: 15242.8608 | g_Loss: 6198.0591 | l_Loss: 350.1140 | 
                                                                                 035		82762.4762		-4.5000
25-09-27 13:12:18.636 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:12:18.638 - INFO: Train epoch 36:   Loss: 112114.3994 | r_Loss: 20912.8487 | g_Loss: 7154.6226 | l_Loss: 395.5333 | 
                                                                                 036		112114.3994		-4.5000
25-09-27 13:12:29.868 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:12:29.869 - INFO: Train epoch 37:   Loss: 78200.1221 | r_Loss: 14245.1506 | g_Loss: 6583.7417 | l_Loss: 390.6278 | 
                                                                                 037		78200.1221		-4.5000
25-09-27 13:12:41.078 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:12:41.080 - INFO: Train epoch 38:   Loss: 75898.0400 | r_Loss: 13922.5535 | g_Loss: 5913.0221 | l_Loss: 372.2510 | 
                                                                                 038		75898.0400		-4.5000
25-09-27 13:12:52.184 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:12:52.185 - INFO: Train epoch 39:   Loss: 74251.7344 | r_Loss: 13625.9068 | g_Loss: 5733.5286 | l_Loss: 388.6727 | 
                                                                                 039		74251.7344		-4.5000
25-09-27 13:13:03.199 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:13:03.201 - INFO: Train epoch 40:   Loss: 74941.3945 | r_Loss: 13798.3932 | g_Loss: 5541.3455 | l_Loss: 408.0838 | 
                                                                                 040		74941.3945		-4.5000
25-09-27 13:13:14.477 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:13:14.478 - INFO: Train epoch 41:   Loss: 78162.8291 | r_Loss: 14475.6059 | g_Loss: 5342.2318 | l_Loss: 442.5686 | 
                                                                                 041		78162.8291		-4.5000
25-09-27 13:13:25.718 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:13:25.719 - INFO: Train epoch 42:   Loss: 76108.8874 | r_Loss: 14083.7791 | g_Loss: 5217.5474 | l_Loss: 472.4450 | 
                                                                                 042		76108.8874		-4.5000
25-09-27 13:13:36.876 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:13:36.877 - INFO: Train epoch 43:   Loss: 77337.4440 | r_Loss: 14350.7022 | g_Loss: 5092.2869 | l_Loss: 491.6452 | 
                                                                                 043		77337.4440		-4.5000
25-09-27 13:13:48.002 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:13:48.003 - INFO: Train epoch 44:   Loss: 74941.9932 | r_Loss: 13874.1846 | g_Loss: 5045.8728 | l_Loss: 525.1987 | 
                                                                                 044		74941.9932		-4.5000
25-09-27 13:13:59.350 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:13:59.351 - INFO: Train epoch 45:   Loss: 70078.4043 | r_Loss: 12933.4272 | g_Loss: 4875.1889 | l_Loss: 536.0774 | 
                                                                                 045		70078.4043		-4.5000
25-09-27 13:14:10.461 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:14:10.462 - INFO: Train epoch 46:   Loss: 71192.0798 | r_Loss: 13201.4425 | g_Loss: 4606.0420 | l_Loss: 578.8254 | 
                                                                                 046		71192.0798		-4.5000
25-09-27 13:14:21.661 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:14:21.662 - INFO: Train epoch 47:   Loss: 68969.9167 | r_Loss: 12764.7271 | g_Loss: 4576.5570 | l_Loss: 569.7258 | 
                                                                                 047		68969.9167		-4.5000
25-09-27 13:14:32.877 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:14:32.878 - INFO: Train epoch 48:   Loss: 111476.7451 | r_Loss: 21099.3473 | g_Loss: 5297.4570 | l_Loss: 682.5533 | 
                                                                                 048		111476.7451		-4.5000
25-09-27 13:14:44.111 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:14:44.113 - INFO: Train epoch 49:   Loss: 352639.2656 | r_Loss: 65407.4385 | g_Loss: 23347.1819 | l_Loss: 2254.8914 | 
                                                                                 049		352639.2656		-4.5000
25-09-27 13:25:12.577 - INFO: TEST:   PSNR_S: 18.6505 | PSNR_C: 20.4411 | 
25-09-27 13:25:12.578 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:25:12.578 - INFO: Train epoch 50:   Loss: 93886.9688 | r_Loss: 16386.9755 | g_Loss: 11180.2566 | l_Loss: 771.8337 | 
                                                                                 050		93886.9688		-4.5000
25-09-27 13:25:23.920 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:25:23.921 - INFO: Train epoch 51:   Loss: 89775.8626 | r_Loss: 16120.3896 | g_Loss: 8481.8205 | l_Loss: 692.0947 | 
                                                                                 051		89775.8626		-4.5000
25-09-27 13:25:35.119 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:25:35.120 - INFO: Train epoch 52:   Loss: 84786.4642 | r_Loss: 15343.4054 | g_Loss: 7358.6662 | l_Loss: 710.7708 | 
                                                                                 052		84786.4642		-4.5000
25-09-27 13:25:46.374 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:25:46.375 - INFO: Train epoch 53:   Loss: 89073.6406 | r_Loss: 16020.0994 | g_Loss: 8186.0941 | l_Loss: 787.0461 | 
                                                                                 053		89073.6406		-4.5000
25-09-27 13:25:57.523 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:25:57.524 - INFO: Train epoch 54:   Loss: 80736.0332 | r_Loss: 14536.5770 | g_Loss: 7346.5306 | l_Loss: 706.6175 | 
                                                                                 054		80736.0332		-4.5000
25-09-27 13:26:08.804 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:26:08.805 - INFO: Train epoch 55:   Loss: 78679.0407 | r_Loss: 14176.5591 | g_Loss: 7031.3872 | l_Loss: 764.8586 | 
                                                                                 055		78679.0407		-4.5000
25-09-27 13:26:20.088 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:26:20.090 - INFO: Train epoch 56:   Loss: 103415.7581 | r_Loss: 18738.2441 | g_Loss: 8771.3584 | l_Loss: 953.1789 | 
                                                                                 056		103415.7581		-4.5000
25-09-27 13:26:31.418 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:26:31.419 - INFO: Train epoch 57:   Loss: 74283.3844 | r_Loss: 13197.5011 | g_Loss: 7478.2225 | l_Loss: 817.6567 | 
                                                                                 057		74283.3844		-4.5000
25-09-27 13:26:42.772 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:26:42.773 - INFO: Train epoch 58:   Loss: 71272.5020 | r_Loss: 12759.3936 | g_Loss: 6658.3564 | l_Loss: 817.1778 | 
                                                                                 058		71272.5020		-4.5000
25-09-27 13:26:54.190 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:26:54.191 - INFO: Train epoch 59:   Loss: 71680.0723 | r_Loss: 12902.8619 | g_Loss: 6284.2809 | l_Loss: 881.4812 | 
                                                                                 059		71680.0723		-4.5000
25-09-27 13:27:05.440 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:27:05.441 - INFO: Train epoch 60:   Loss: 85946.6729 | r_Loss: 15474.4424 | g_Loss: 7512.3623 | l_Loss: 1062.0978 | 
                                                                                 060		85946.6729		-4.5000
25-09-27 13:27:16.816 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:27:16.817 - INFO: Train epoch 61:   Loss: 69422.5788 | r_Loss: 12180.9496 | g_Loss: 7461.5852 | l_Loss: 1056.2456 | 
                                                                                 061		69422.5788		-4.5000
25-09-27 13:27:28.129 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:27:28.130 - INFO: Train epoch 62:   Loss: 78378.2432 | r_Loss: 14124.3372 | g_Loss: 6569.7479 | l_Loss: 1186.8078 | 
                                                                                 062		78378.2432		-4.5000
25-09-27 13:27:39.417 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:27:39.418 - INFO: Train epoch 63:   Loss: 77442.9456 | r_Loss: 13669.2791 | g_Loss: 7801.1964 | l_Loss: 1295.3549 | 
                                                                                 063		77442.9456		-4.5000
25-09-27 13:27:50.723 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:27:50.723 - INFO: Train epoch 64:   Loss: 66134.5563 | r_Loss: 11539.6942 | g_Loss: 7188.7267 | l_Loss: 1247.3581 | 
                                                                                 064		66134.5563		-4.5000
25-09-27 13:28:02.016 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:28:02.017 - INFO: Train epoch 65:   Loss: 65455.5794 | r_Loss: 11453.6971 | g_Loss: 6761.0073 | l_Loss: 1426.0860 | 
                                                                                 065		65455.5794		-4.5000
25-09-27 13:28:13.336 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:28:13.337 - INFO: Train epoch 66:   Loss: 78325.8184 | r_Loss: 13989.5761 | g_Loss: 6879.3669 | l_Loss: 1498.5720 | 
                                                                                 066		78325.8184		-4.5000
25-09-27 13:28:24.499 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:28:24.500 - INFO: Train epoch 67:   Loss: 67897.1390 | r_Loss: 11681.3735 | g_Loss: 7790.2169 | l_Loss: 1700.0557 | 
                                                                                 067		67897.1390		-4.5000
25-09-27 13:28:35.992 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:28:35.993 - INFO: Train epoch 68:   Loss: 62738.8480 | r_Loss: 10750.5081 | g_Loss: 7297.1835 | l_Loss: 1689.1230 | 
                                                                                 068		62738.8480		-4.5000
25-09-27 13:28:47.232 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:28:47.234 - INFO: Train epoch 69:   Loss: 65601.6240 | r_Loss: 11317.9380 | g_Loss: 7058.5733 | l_Loss: 1953.3617 | 
                                                                                 069		65601.6240		-4.5000
25-09-27 13:28:58.488 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:28:58.489 - INFO: Train epoch 70:   Loss: 65387.2975 | r_Loss: 11150.7142 | g_Loss: 7480.7801 | l_Loss: 2152.9465 | 
                                                                                 070		65387.2975		-4.5000
25-09-27 13:29:09.781 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:29:09.782 - INFO: Train epoch 71:   Loss: 62941.3219 | r_Loss: 10554.6218 | g_Loss: 7759.2875 | l_Loss: 2408.9244 | 
                                                                                 071		62941.3219		-4.5000
25-09-27 13:29:21.037 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:29:21.038 - INFO: Train epoch 72:   Loss: 80415.8910 | r_Loss: 14023.8696 | g_Loss: 7854.1729 | l_Loss: 2442.3706 | 
                                                                                 072		80415.8910		-4.5000
25-09-27 13:29:32.238 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:29:32.240 - INFO: Train epoch 73:   Loss: 63564.6536 | r_Loss: 10430.0909 | g_Loss: 8826.2711 | l_Loss: 2587.9279 | 
                                                                                 073		63564.6536		-4.5000
25-09-27 13:29:43.404 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:29:43.405 - INFO: Train epoch 74:   Loss: 58337.3581 | r_Loss: 9474.9128 | g_Loss: 8296.5870 | l_Loss: 2666.2075 | 
                                                                                 074		58337.3581		-4.5000
25-09-27 13:29:54.833 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:29:54.834 - INFO: Train epoch 75:   Loss: 60757.1335 | r_Loss: 9898.0627 | g_Loss: 8408.0618 | l_Loss: 2858.7577 | 
                                                                                 075		60757.1335		-4.5000
25-09-27 13:30:06.049 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:30:06.050 - INFO: Train epoch 76:   Loss: 61165.5807 | r_Loss: 9979.4585 | g_Loss: 8363.8263 | l_Loss: 2904.4623 | 
                                                                                 076		61165.5807		-4.5000
25-09-27 13:30:17.331 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:30:17.333 - INFO: Train epoch 77:   Loss: 57364.2865 | r_Loss: 9172.5386 | g_Loss: 8481.6842 | l_Loss: 3019.9096 | 
                                                                                 077		57364.2865		-4.5000
25-09-27 13:30:28.599 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:30:28.600 - INFO: Train epoch 78:   Loss: 55791.2793 | r_Loss: 8913.6916 | g_Loss: 8267.9117 | l_Loss: 2954.9089 | 
                                                                                 078		55791.2793		-4.5000
25-09-27 13:30:39.783 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:30:39.784 - INFO: Train epoch 79:   Loss: 51946.2845 | r_Loss: 8111.7298 | g_Loss: 8405.4757 | l_Loss: 2982.1595 | 
                                                                                 079		51946.2845		-4.5000
25-09-27 13:30:50.918 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:30:50.919 - INFO: Train epoch 80:   Loss: 72933.3086 | r_Loss: 12274.5039 | g_Loss: 8621.8973 | l_Loss: 2938.8918 | 
                                                                                 080		72933.3086		-4.5000
25-09-27 13:31:02.311 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:31:02.312 - INFO: Train epoch 81:   Loss: 49061.2132 | r_Loss: 7565.7151 | g_Loss: 8614.9325 | l_Loss: 2617.7055 | 
                                                                                 081		49061.2132		-4.5000
25-09-27 13:31:13.483 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:31:13.484 - INFO: Train epoch 82:   Loss: 50233.5999 | r_Loss: 7725.0213 | g_Loss: 8687.5925 | l_Loss: 2920.9011 | 
                                                                                 082		50233.5999		-4.5000
25-09-27 13:31:24.750 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:31:24.752 - INFO: Train epoch 83:   Loss: 47454.0830 | r_Loss: 7193.2886 | g_Loss: 8652.3580 | l_Loss: 2835.2817 | 
                                                                                 083		47454.0830		-4.5000
25-09-27 13:31:36.036 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:31:36.037 - INFO: Train epoch 84:   Loss: 51482.8073 | r_Loss: 8026.2315 | g_Loss: 8580.0598 | l_Loss: 2771.5904 | 
                                                                                 084		51482.8073		-4.5000
25-09-27 13:31:47.263 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:31:47.264 - INFO: Train epoch 85:   Loss: 46538.5249 | r_Loss: 7053.3503 | g_Loss: 8496.2388 | l_Loss: 2775.5339 | 
                                                                                 085		46538.5249		-4.5000
25-09-27 13:31:58.524 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:31:58.525 - INFO: Train epoch 86:   Loss: 54622.5127 | r_Loss: 8608.2779 | g_Loss: 8840.2216 | l_Loss: 2740.9019 | 
                                                                                 086		54622.5127		-4.5000
25-09-27 13:32:09.991 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:32:09.992 - INFO: Train epoch 87:   Loss: 46035.1510 | r_Loss: 7052.9790 | g_Loss: 8394.8750 | l_Loss: 2375.3809 | 
                                                                                 087		46035.1510		-4.5000
25-09-27 13:32:21.154 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:32:21.155 - INFO: Train epoch 88:   Loss: 51258.1646 | r_Loss: 8051.6926 | g_Loss: 8483.8829 | l_Loss: 2515.8188 | 
                                                                                 088		51258.1646		-4.5000
25-09-27 13:32:32.310 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:32:32.311 - INFO: Train epoch 89:   Loss: 46969.3888 | r_Loss: 7223.3186 | g_Loss: 8445.5581 | l_Loss: 2407.2377 | 
                                                                                 089		46969.3888		-4.5000
25-09-27 13:32:43.503 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:32:43.504 - INFO: Train epoch 90:   Loss: 44068.6725 | r_Loss: 6691.9429 | g_Loss: 8363.6358 | l_Loss: 2245.3225 | 
                                                                                 090		44068.6725		-4.5000
25-09-27 13:32:54.696 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:32:54.697 - INFO: Train epoch 91:   Loss: 43530.1479 | r_Loss: 6535.8275 | g_Loss: 8571.8293 | l_Loss: 2279.1807 | 
                                                                                 091		43530.1479		-4.5000
25-09-27 13:33:06.009 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:33:06.010 - INFO: Train epoch 92:   Loss: 50510.3053 | r_Loss: 7960.7416 | g_Loss: 8500.8763 | l_Loss: 2205.7208 | 
                                                                                 092		50510.3053		-4.5000
25-09-27 13:33:17.364 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:33:17.365 - INFO: Train epoch 93:   Loss: 42541.8916 | r_Loss: 6350.8418 | g_Loss: 8625.1069 | l_Loss: 2162.5760 | 
                                                                                 093		42541.8916		-4.5000
25-09-27 13:33:28.679 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:33:28.680 - INFO: Train epoch 94:   Loss: 41260.2324 | r_Loss: 6281.5920 | g_Loss: 8001.7905 | l_Loss: 1850.4811 | 
                                                                                 094		41260.2324		-4.5000
25-09-27 13:33:40.002 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:33:40.004 - INFO: Train epoch 95:   Loss: 50134.2741 | r_Loss: 7968.0413 | g_Loss: 8402.3090 | l_Loss: 1891.7583 | 
                                                                                 095		50134.2741		-4.5000
25-09-27 13:33:51.227 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:33:51.227 - INFO: Train epoch 96:   Loss: 40542.4272 | r_Loss: 6056.7707 | g_Loss: 8453.2203 | l_Loss: 1805.3541 | 
                                                                                 096		40542.4272		-4.5000
25-09-27 13:34:02.470 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:34:02.471 - INFO: Train epoch 97:   Loss: 40941.8447 | r_Loss: 6209.6687 | g_Loss: 8189.0811 | l_Loss: 1704.4206 | 
                                                                                 097		40941.8447		-4.5000
25-09-27 13:34:13.898 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:34:13.899 - INFO: Train epoch 98:   Loss: 47090.0260 | r_Loss: 7517.9355 | g_Loss: 7923.3001 | l_Loss: 1577.0488 | 
                                                                                 098		47090.0260		-4.5000
25-09-27 13:34:25.271 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:34:25.272 - INFO: Train epoch 99:   Loss: 40397.2731 | r_Loss: 6089.5538 | g_Loss: 8336.6624 | l_Loss: 1612.8425 | 
                                                                                 099		40397.2731		-4.5000
25-09-27 13:48:27.964 - INFO: TEST:   PSNR_S: 24.2030 | PSNR_C: 20.8847 | 
25-09-27 13:48:27.965 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:48:27.966 - INFO: Train epoch 100:   Loss: 37130.7166 | r_Loss: 5552.5798 | g_Loss: 7931.9491 | l_Loss: 1435.8690 | 
                                                                                 100		37130.7166		-4.5000
25-09-27 13:48:45.847 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:48:45.849 - INFO: Train epoch 101:   Loss: 43643.6491 | r_Loss: 6907.8003 | g_Loss: 7730.6593 | l_Loss: 1373.9881 | 
                                                                                 101		43643.6491		-4.5000
25-09-27 13:48:57.300 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:48:57.301 - INFO: Train epoch 102:   Loss: 41311.2708 | r_Loss: 6448.8432 | g_Loss: 7731.5203 | l_Loss: 1335.5341 | 
                                                                                 102		41311.2708		-4.5000
25-09-27 13:49:08.523 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:49:08.524 - INFO: Train epoch 103:   Loss: 35540.3984 | r_Loss: 5358.1348 | g_Loss: 7559.7353 | l_Loss: 1189.9896 | 
                                                                                 103		35540.3984		-4.5000
25-09-27 13:49:35.299 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:49:35.300 - INFO: Train epoch 104:   Loss: 34533.6533 | r_Loss: 5191.2974 | g_Loss: 7409.3486 | l_Loss: 1167.8176 | 
                                                                                 104		34533.6533		-4.5000
25-09-27 13:49:46.467 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:49:46.468 - INFO: Train epoch 105:   Loss: 57621.4893 | r_Loss: 9860.7332 | g_Loss: 7203.7295 | l_Loss: 1114.0938 | 
                                                                                 105		57621.4893		-4.5000
25-09-27 13:49:57.939 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:49:57.940 - INFO: Train epoch 106:   Loss: 38066.7520 | r_Loss: 5785.2585 | g_Loss: 7977.6197 | l_Loss: 1162.8387 | 
                                                                                 106		38066.7520		-4.5000
25-09-27 13:50:09.034 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:50:09.034 - INFO: Train epoch 107:   Loss: 34585.6030 | r_Loss: 5180.6873 | g_Loss: 7623.0258 | l_Loss: 1059.1402 | 
                                                                                 107		34585.6030		-4.5000
25-09-27 13:50:20.408 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:50:20.410 - INFO: Train epoch 108:   Loss: 34710.6468 | r_Loss: 5268.8186 | g_Loss: 7359.5166 | l_Loss: 1007.0369 | 
                                                                                 108		34710.6468		-4.5000
25-09-27 13:50:48.035 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:50:48.036 - INFO: Train epoch 109:   Loss: 32575.7155 | r_Loss: 4933.8361 | g_Loss: 6988.4738 | l_Loss: 918.0614 | 
                                                                                 109		32575.7155		-4.5000
25-09-27 13:50:59.231 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:50:59.232 - INFO: Train epoch 110:   Loss: 34053.3389 | r_Loss: 5290.7157 | g_Loss: 6756.6044 | l_Loss: 843.1556 | 
                                                                                 110		34053.3389		-4.5000
25-09-27 13:51:10.573 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:51:10.575 - INFO: Train epoch 111:   Loss: 32960.3462 | r_Loss: 5125.0232 | g_Loss: 6531.8829 | l_Loss: 803.3480 | 
                                                                                 111		32960.3462		-4.5000
25-09-27 13:51:42.624 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:51:42.625 - INFO: Train epoch 112:   Loss: 34918.3604 | r_Loss: 5489.6174 | g_Loss: 6675.4135 | l_Loss: 794.8593 | 
                                                                                 112		34918.3604		-4.5000
25-09-27 13:51:53.937 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:51:53.938 - INFO: Train epoch 113:   Loss: 36223.1795 | r_Loss: 5839.6727 | g_Loss: 6299.4984 | l_Loss: 725.3172 | 
                                                                                 113		36223.1795		-4.5000
25-09-27 13:52:05.237 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:52:05.240 - INFO: Train epoch 114:   Loss: 33455.0513 | r_Loss: 5260.6230 | g_Loss: 6415.3605 | l_Loss: 736.5757 | 
                                                                                 114		33455.0513		-4.5000
25-09-27 13:52:16.703 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:52:16.704 - INFO: Train epoch 115:   Loss: 32979.5311 | r_Loss: 5180.0706 | g_Loss: 6356.8427 | l_Loss: 722.3352 | 
                                                                                 115		32979.5311		-4.5000
25-09-27 13:52:34.938 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:52:34.939 - INFO: Train epoch 116:   Loss: 35150.6914 | r_Loss: 5617.7994 | g_Loss: 6371.0235 | l_Loss: 690.6707 | 
                                                                                 116		35150.6914		-4.5000
25-09-27 13:52:46.092 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:52:46.093 - INFO: Train epoch 117:   Loss: 41176.2759 | r_Loss: 6773.8016 | g_Loss: 6583.8351 | l_Loss: 723.4321 | 
                                                                                 117		41176.2759		-4.5000
25-09-27 13:52:57.295 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:52:57.297 - INFO: Train epoch 118:   Loss: 31507.9953 | r_Loss: 4879.2499 | g_Loss: 6454.6499 | l_Loss: 657.0954 | 
                                                                                 118		31507.9953		-4.5000
25-09-27 13:53:08.645 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:53:08.646 - INFO: Train epoch 119:   Loss: 34463.1377 | r_Loss: 5526.6756 | g_Loss: 6233.0552 | l_Loss: 596.7043 | 
                                                                                 119		34463.1377		-4.5000
25-09-27 13:53:19.758 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:53:19.759 - INFO: Train epoch 120:   Loss: 30615.3787 | r_Loss: 4775.7619 | g_Loss: 6130.3865 | l_Loss: 606.1820 | 
                                                                                 120		30615.3787		-4.5000
25-09-27 13:53:31.970 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:53:31.971 - INFO: Train epoch 121:   Loss: 29520.4806 | r_Loss: 4583.3479 | g_Loss: 6025.8747 | l_Loss: 577.8664 | 
                                                                                 121		29520.4806		-4.5000
25-09-27 13:53:43.197 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:53:43.198 - INFO: Train epoch 122:   Loss: 34885.5181 | r_Loss: 5689.3150 | g_Loss: 5887.4383 | l_Loss: 551.5046 | 
                                                                                 122		34885.5181		-4.5000
25-09-27 13:54:01.635 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:54:01.636 - INFO: Train epoch 123:   Loss: 32365.8280 | r_Loss: 5148.6089 | g_Loss: 6051.4370 | l_Loss: 571.3463 | 
                                                                                 123		32365.8280		-4.5000
25-09-27 13:54:13.299 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:54:13.300 - INFO: Train epoch 124:   Loss: 29637.3521 | r_Loss: 4660.2774 | g_Loss: 5810.1853 | l_Loss: 525.7799 | 
                                                                                 124		29637.3521		-4.5000
25-09-27 13:54:24.526 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:54:24.527 - INFO: Train epoch 125:   Loss: 29135.6453 | r_Loss: 4585.0736 | g_Loss: 5701.6584 | l_Loss: 508.6188 | 
                                                                                 125		29135.6453		-4.5000
25-09-27 13:54:40.989 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:54:40.991 - INFO: Train epoch 126:   Loss: 30097.4056 | r_Loss: 4790.8275 | g_Loss: 5649.7655 | l_Loss: 493.5022 | 
                                                                                 126		30097.4056		-4.5000
25-09-27 13:54:52.443 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:54:52.444 - INFO: Train epoch 127:   Loss: 29148.3555 | r_Loss: 4614.8510 | g_Loss: 5595.0991 | l_Loss: 479.0019 | 
                                                                                 127		29148.3555		-4.5000
25-09-27 13:55:03.650 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:55:03.651 - INFO: Train epoch 128:   Loss: 36368.6533 | r_Loss: 6061.8732 | g_Loss: 5580.7541 | l_Loss: 478.5335 | 
                                                                                 128		36368.6533		-4.5000
25-09-27 13:55:23.819 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:55:23.820 - INFO: Train epoch 129:   Loss: 28281.3840 | r_Loss: 4427.6559 | g_Loss: 5660.7806 | l_Loss: 482.3239 | 
                                                                                 129		28281.3840		-4.5000
25-09-27 13:56:34.326 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:56:34.328 - INFO: Train epoch 130:   Loss: 26911.4951 | r_Loss: 4207.2353 | g_Loss: 5428.0492 | l_Loss: 447.2695 | 
                                                                                 130		26911.4951		-4.5000
25-09-27 13:56:45.528 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:56:45.530 - INFO: Train epoch 131:   Loss: 31400.4653 | r_Loss: 5089.6462 | g_Loss: 5506.7524 | l_Loss: 445.4817 | 
                                                                                 131		31400.4653		-4.5000
25-09-27 13:57:42.631 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:57:42.631 - INFO: Train epoch 132:   Loss: 29807.0514 | r_Loss: 4782.1954 | g_Loss: 5459.9401 | l_Loss: 436.1343 | 
                                                                                 132		29807.0514		-4.5000
25-09-27 13:57:53.831 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:57:53.832 - INFO: Train epoch 133:   Loss: 28568.3719 | r_Loss: 4546.9349 | g_Loss: 5408.4788 | l_Loss: 425.2184 | 
                                                                                 133		28568.3719		-4.5000
25-09-27 13:58:05.067 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:58:05.069 - INFO: Train epoch 134:   Loss: 27960.7891 | r_Loss: 4470.1182 | g_Loss: 5203.4202 | l_Loss: 406.7780 | 
                                                                                 134		27960.7891		-4.5000
25-09-27 13:58:16.762 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:58:16.764 - INFO: Train epoch 135:   Loss: 28012.8475 | r_Loss: 4496.1783 | g_Loss: 5139.2195 | l_Loss: 392.7366 | 
                                                                                 135		28012.8475		-4.5000
25-09-27 13:58:27.995 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:58:27.995 - INFO: Train epoch 136:   Loss: 30287.8504 | r_Loss: 4935.9813 | g_Loss: 5206.6740 | l_Loss: 401.2697 | 
                                                                                 136		30287.8504		-4.5000
25-09-27 13:58:49.069 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:58:49.069 - INFO: Train epoch 137:   Loss: 31507.5295 | r_Loss: 5181.7504 | g_Loss: 5207.0549 | l_Loss: 391.7216 | 
                                                                                 137		31507.5295		-4.5000
25-09-27 13:59:00.324 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:59:00.325 - INFO: Train epoch 138:   Loss: 39213.5758 | r_Loss: 6714.8985 | g_Loss: 5219.4385 | l_Loss: 419.6440 | 
                                                                                 138		39213.5758		-4.5000
25-09-27 13:59:11.804 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:59:11.807 - INFO: Train epoch 139:   Loss: 27279.8939 | r_Loss: 4301.3815 | g_Loss: 5376.9129 | l_Loss: 396.0742 | 
                                                                                 139		27279.8939		-4.5000
25-09-27 13:59:23.161 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:59:23.162 - INFO: Train epoch 140:   Loss: 26027.5614 | r_Loss: 4105.9122 | g_Loss: 5124.6802 | l_Loss: 373.3197 | 
                                                                                 140		26027.5614		-4.5000
25-09-27 13:59:41.845 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:59:41.846 - INFO: Train epoch 141:   Loss: 25842.3132 | r_Loss: 4103.5925 | g_Loss: 4964.9324 | l_Loss: 359.4180 | 
                                                                                 141		25842.3132		-4.5000
25-09-27 13:59:53.039 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 13:59:53.040 - INFO: Train epoch 142:   Loss: 27451.6515 | r_Loss: 4438.2776 | g_Loss: 4905.4343 | l_Loss: 354.8292 | 
                                                                                 142		27451.6515		-4.5000
25-09-27 14:00:04.302 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:00:04.303 - INFO: Train epoch 143:   Loss: 27272.0037 | r_Loss: 4428.5764 | g_Loss: 4788.5882 | l_Loss: 340.5336 | 
                                                                                 143		27272.0037		-4.5000
25-09-27 14:00:19.514 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:00:19.515 - INFO: Train epoch 144:   Loss: 25480.6349 | r_Loss: 4080.0225 | g_Loss: 4747.1546 | l_Loss: 333.3679 | 
                                                                                 144		25480.6349		-4.5000
25-09-27 14:00:30.822 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:00:30.823 - INFO: Train epoch 145:   Loss: 34697.3664 | r_Loss: 5887.6193 | g_Loss: 4921.1132 | l_Loss: 338.1571 | 
                                                                                 145		34697.3664		-4.5000
25-09-27 14:00:42.675 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:00:42.676 - INFO: Train epoch 146:   Loss: 26177.3133 | r_Loss: 4152.6523 | g_Loss: 5064.4023 | l_Loss: 349.6499 | 
                                                                                 146		26177.3133		-4.5000
25-09-27 14:00:53.810 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:00:53.812 - INFO: Train epoch 147:   Loss: 24168.5312 | r_Loss: 3805.0250 | g_Loss: 4823.3815 | l_Loss: 320.0249 | 
                                                                                 147		24168.5312		-4.5000
25-09-27 14:01:12.786 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:01:12.787 - INFO: Train epoch 148:   Loss: 26178.7578 | r_Loss: 4211.5336 | g_Loss: 4796.1271 | l_Loss: 324.9624 | 
                                                                                 148		26178.7578		-4.5000
25-09-27 14:01:23.967 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:01:23.967 - INFO: Train epoch 149:   Loss: 24203.9807 | r_Loss: 3848.7327 | g_Loss: 4649.0225 | l_Loss: 311.2947 | 
                                                                                 149		24203.9807		-4.5000
25-09-27 14:09:58.339 - INFO: TEST:   PSNR_S: 25.5694 | PSNR_C: 23.3412 | 
25-09-27 14:09:58.341 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:09:58.342 - INFO: Train epoch 150:   Loss: 25439.2266 | r_Loss: 4083.0499 | g_Loss: 4714.4257 | l_Loss: 309.5512 | 
                                                                                 150		25439.2266		-4.5000
25-09-27 14:10:10.354 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:10:10.355 - INFO: Train epoch 151:   Loss: 24927.8840 | r_Loss: 4007.4452 | g_Loss: 4590.5378 | l_Loss: 300.1201 | 
                                                                                 151		24927.8840		-4.5000
25-09-27 14:10:21.749 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:10:21.751 - INFO: Train epoch 152:   Loss: 25908.6069 | r_Loss: 4226.2271 | g_Loss: 4486.0422 | l_Loss: 291.4299 | 
                                                                                 152		25908.6069		-4.5000
25-09-27 14:10:32.993 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:10:32.995 - INFO: Train epoch 153:   Loss: 24262.8295 | r_Loss: 3909.0763 | g_Loss: 4427.9510 | l_Loss: 289.4970 | 
                                                                                 153		24262.8295		-4.5000
25-09-27 14:10:44.318 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:10:44.319 - INFO: Train epoch 154:   Loss: 25018.7119 | r_Loss: 4068.0406 | g_Loss: 4391.9689 | l_Loss: 286.5406 | 
                                                                                 154		25018.7119		-4.5000
25-09-27 14:10:55.645 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:10:55.646 - INFO: Train epoch 155:   Loss: 23836.6909 | r_Loss: 3833.9274 | g_Loss: 4382.6433 | l_Loss: 284.4109 | 
                                                                                 155		23836.6909		-4.5000
25-09-27 14:11:06.929 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:11:06.930 - INFO: Train epoch 156:   Loss: 31181.3062 | r_Loss: 5315.6074 | g_Loss: 4322.8542 | l_Loss: 280.4145 | 
                                                                                 156		31181.3062		-4.5000
25-09-27 14:11:18.492 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:11:18.494 - INFO: Train epoch 157:   Loss: 26418.3175 | r_Loss: 4327.6369 | g_Loss: 4484.4895 | l_Loss: 295.6434 | 
                                                                                 157		26418.3175		-4.5000
25-09-27 14:11:29.848 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:11:29.849 - INFO: Train epoch 158:   Loss: 27641.5921 | r_Loss: 4570.0931 | g_Loss: 4507.3319 | l_Loss: 283.7946 | 
                                                                                 158		27641.5921		-4.5000
25-09-27 14:11:41.216 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:11:41.218 - INFO: Train epoch 159:   Loss: 22223.1683 | r_Loss: 3496.6488 | g_Loss: 4463.4668 | l_Loss: 276.4573 | 
                                                                                 159		22223.1683		-4.5000
25-09-27 14:12:09.970 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:12:09.972 - INFO: Train epoch 160:   Loss: 27197.6099 | r_Loss: 4513.6253 | g_Loss: 4361.7074 | l_Loss: 267.7758 | 
                                                                                 160		27197.6099		-4.5000
25-09-27 14:12:21.429 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:12:21.431 - INFO: Train epoch 161:   Loss: 22900.4956 | r_Loss: 3647.7471 | g_Loss: 4389.6377 | l_Loss: 272.1220 | 
                                                                                 161		22900.4956		-4.5000
25-09-27 14:12:32.760 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:12:32.762 - INFO: Train epoch 162:   Loss: 22886.2687 | r_Loss: 3661.2028 | g_Loss: 4312.2025 | l_Loss: 268.0519 | 
                                                                                 162		22886.2687		-4.5000
25-09-27 14:12:43.864 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:12:43.867 - INFO: Train epoch 163:   Loss: 23767.5225 | r_Loss: 3850.9327 | g_Loss: 4250.8108 | l_Loss: 262.0485 | 
                                                                                 163		23767.5225		-4.5000
25-09-27 14:12:55.354 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:12:55.355 - INFO: Train epoch 164:   Loss: 23459.9015 | r_Loss: 3807.2218 | g_Loss: 4162.9598 | l_Loss: 260.8327 | 
                                                                                 164		23459.9015		-4.5000
25-09-27 14:13:06.532 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:13:06.533 - INFO: Train epoch 165:   Loss: 24017.2663 | r_Loss: 3922.6292 | g_Loss: 4148.3624 | l_Loss: 255.7578 | 
                                                                                 165		24017.2663		-4.5000
25-09-27 14:13:17.823 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:13:17.825 - INFO: Train epoch 166:   Loss: 22159.9875 | r_Loss: 3560.5655 | g_Loss: 4105.0611 | l_Loss: 252.0988 | 
                                                                                 166		22159.9875		-4.5000
25-09-27 14:13:29.361 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:13:29.363 - INFO: Train epoch 167:   Loss: 26071.2323 | r_Loss: 4343.7731 | g_Loss: 4104.0205 | l_Loss: 248.3464 | 
                                                                                 167		26071.2323		-4.5000
25-09-27 14:13:40.786 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:13:40.787 - INFO: Train epoch 168:   Loss: 27318.6758 | r_Loss: 4586.2202 | g_Loss: 4127.7543 | l_Loss: 259.8203 | 
                                                                                 168		27318.6758		-4.5000
25-09-27 14:13:51.968 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:13:51.969 - INFO: Train epoch 169:   Loss: 21371.7363 | r_Loss: 3388.5660 | g_Loss: 4174.7697 | l_Loss: 254.1363 | 
                                                                                 169		21371.7363		-4.5000
25-09-27 14:14:03.331 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:14:03.332 - INFO: Train epoch 170:   Loss: 21605.4655 | r_Loss: 3462.6030 | g_Loss: 4048.6509 | l_Loss: 243.7990 | 
                                                                                 170		21605.4655		-4.5000
25-09-27 14:14:19.509 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:14:19.510 - INFO: Train epoch 171:   Loss: 26110.7498 | r_Loss: 4349.7453 | g_Loss: 4118.4725 | l_Loss: 243.5506 | 
                                                                                 171		26110.7498		-4.5000
25-09-27 14:14:30.863 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:14:30.865 - INFO: Train epoch 172:   Loss: 23009.5793 | r_Loss: 3750.2721 | g_Loss: 4020.4506 | l_Loss: 237.7686 | 
                                                                                 172		23009.5793		-4.5000
25-09-27 14:14:42.200 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:14:42.201 - INFO: Train epoch 173:   Loss: 20801.1733 | r_Loss: 3320.3393 | g_Loss: 3960.1844 | l_Loss: 239.2924 | 
                                                                                 173		20801.1733		-4.5000
25-09-27 14:14:53.462 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:14:53.463 - INFO: Train epoch 174:   Loss: 22850.6779 | r_Loss: 3726.0908 | g_Loss: 3983.3471 | l_Loss: 236.8773 | 
                                                                                 174		22850.6779		-4.5000
25-09-27 14:15:04.757 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:15:04.758 - INFO: Train epoch 175:   Loss: 20855.9683 | r_Loss: 3340.5058 | g_Loss: 3919.4352 | l_Loss: 234.0038 | 
                                                                                 175		20855.9683		-4.5000
25-09-27 14:15:16.073 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:15:16.075 - INFO: Train epoch 176:   Loss: 22457.7168 | r_Loss: 3671.8735 | g_Loss: 3868.3719 | l_Loss: 229.9775 | 
                                                                                 176		22457.7168		-4.5000
25-09-27 14:15:27.307 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:15:27.309 - INFO: Train epoch 177:   Loss: 26657.9168 | r_Loss: 4503.2890 | g_Loss: 3909.0087 | l_Loss: 232.4635 | 
                                                                                 177		26657.9168		-4.5000
25-09-27 14:16:11.151 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:16:11.153 - INFO: Train epoch 178:   Loss: 22663.4542 | r_Loss: 3691.6086 | g_Loss: 3971.2475 | l_Loss: 234.1644 | 
                                                                                 178		22663.4542		-4.5000
25-09-27 14:16:22.392 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:16:22.393 - INFO: Train epoch 179:   Loss: 20744.7043 | r_Loss: 3322.0069 | g_Loss: 3905.2570 | l_Loss: 229.4131 | 
                                                                                 179		20744.7043		-4.5000
25-09-27 14:16:33.699 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:16:33.700 - INFO: Train epoch 180:   Loss: 20780.1842 | r_Loss: 3363.8112 | g_Loss: 3740.7092 | l_Loss: 220.4191 | 
                                                                                 180		20780.1842		-4.5000
25-09-27 14:16:44.855 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:16:44.856 - INFO: Train epoch 181:   Loss: 27141.8125 | r_Loss: 4614.7463 | g_Loss: 3842.6722 | l_Loss: 225.4086 | 
                                                                                 181		27141.8125		-4.5000
25-09-27 14:16:56.234 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:16:56.235 - INFO: Train epoch 182:   Loss: 21498.5864 | r_Loss: 3473.9163 | g_Loss: 3902.5511 | l_Loss: 226.4535 | 
                                                                                 182		21498.5864		-4.5000
25-09-27 14:17:07.415 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:17:07.417 - INFO: Train epoch 183:   Loss: 19591.0129 | r_Loss: 3123.6053 | g_Loss: 3756.8529 | l_Loss: 216.1332 | 
                                                                                 183		19591.0129		-4.5000
25-09-27 14:17:18.781 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:17:18.782 - INFO: Train epoch 184:   Loss: 19895.6899 | r_Loss: 3192.7924 | g_Loss: 3716.8639 | l_Loss: 214.8644 | 
                                                                                 184		19895.6899		-4.5000
25-09-27 14:17:30.297 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:17:30.299 - INFO: Train epoch 185:   Loss: 19883.5143 | r_Loss: 3193.9510 | g_Loss: 3698.8451 | l_Loss: 214.9141 | 
                                                                                 185		19883.5143		-4.5000
25-09-27 14:17:41.649 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:17:41.650 - INFO: Train epoch 186:   Loss: 36125.8314 | r_Loss: 6405.6080 | g_Loss: 3873.2842 | l_Loss: 224.5070 | 
                                                                                 186		36125.8314		-4.5000
25-09-27 14:17:53.238 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:17:53.240 - INFO: Train epoch 187:   Loss: 21456.5150 | r_Loss: 3460.3289 | g_Loss: 3925.4752 | l_Loss: 229.3952 | 
                                                                                 187		21456.5150		-4.5000
25-09-27 14:18:04.697 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:18:04.698 - INFO: Train epoch 188:   Loss: 19629.3761 | r_Loss: 3111.9047 | g_Loss: 3848.5835 | l_Loss: 221.2692 | 
                                                                                 188		19629.3761		-4.5000
25-09-27 14:18:16.165 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:18:16.166 - INFO: Train epoch 189:   Loss: 19308.7862 | r_Loss: 3065.9577 | g_Loss: 3765.1581 | l_Loss: 213.8392 | 
                                                                                 189		19308.7862		-4.5000
25-09-27 14:18:27.435 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:18:27.437 - INFO: Train epoch 190:   Loss: 20398.4574 | r_Loss: 3300.0945 | g_Loss: 3685.6876 | l_Loss: 212.2972 | 
                                                                                 190		20398.4574		-4.5000
25-09-27 14:18:38.744 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:18:38.746 - INFO: Train epoch 191:   Loss: 24129.1936 | r_Loss: 4035.6685 | g_Loss: 3739.3715 | l_Loss: 211.4801 | 
                                                                                 191		24129.1936		-4.5000
25-09-27 14:18:50.045 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:18:50.046 - INFO: Train epoch 192:   Loss: 21280.8968 | r_Loss: 3477.0058 | g_Loss: 3685.7477 | l_Loss: 210.1204 | 
                                                                                 192		21280.8968		-4.5000
25-09-27 14:19:14.680 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:19:14.682 - INFO: Train epoch 193:   Loss: 19051.0942 | r_Loss: 3045.3354 | g_Loss: 3615.9755 | l_Loss: 208.4419 | 
                                                                                 193		19051.0942		-4.5000
25-09-27 14:19:25.929 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:19:25.931 - INFO: Train epoch 194:   Loss: 19004.8281 | r_Loss: 3042.6009 | g_Loss: 3587.7489 | l_Loss: 204.0751 | 
                                                                                 194		19004.8281		-4.5000
25-09-27 14:19:37.368 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:19:37.369 - INFO: Train epoch 195:   Loss: 24595.3920 | r_Loss: 4155.4398 | g_Loss: 3613.0397 | l_Loss: 205.1535 | 
                                                                                 195		24595.3920		-4.5000
25-09-27 14:19:48.637 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:19:48.639 - INFO: Train epoch 196:   Loss: 18668.9055 | r_Loss: 2978.1890 | g_Loss: 3576.4019 | l_Loss: 201.5587 | 
                                                                                 196		18668.9055		-4.5000
25-09-27 14:19:59.787 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:19:59.789 - INFO: Train epoch 197:   Loss: 19003.6327 | r_Loss: 3055.7600 | g_Loss: 3523.0206 | l_Loss: 201.8119 | 
                                                                                 197		19003.6327		-4.5000
25-09-27 14:20:11.061 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:20:11.062 - INFO: Train epoch 198:   Loss: 18670.9454 | r_Loss: 3010.7303 | g_Loss: 3419.9701 | l_Loss: 197.3239 | 
                                                                                 198		18670.9454		-4.5000
25-09-27 14:20:22.248 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:20:22.249 - INFO: Train epoch 199:   Loss: 20230.5667 | r_Loss: 3329.2338 | g_Loss: 3391.9553 | l_Loss: 192.4425 | 
                                                                                 199		20230.5667		-4.5000
25-09-27 14:25:09.932 - INFO: TEST:   PSNR_S: 23.2215 | PSNR_C: 24.8820 | 
25-09-27 14:25:09.934 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:25:09.935 - INFO: Train epoch 200:   Loss: 20097.3403 | r_Loss: 3294.5307 | g_Loss: 3424.1370 | l_Loss: 200.5498 | 
                                                                                 200		20097.3403		-4.5000
25-09-27 14:25:21.509 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:25:21.511 - INFO: Train epoch 201:   Loss: 23997.7304 | r_Loss: 4080.2731 | g_Loss: 3402.0610 | l_Loss: 194.3036 | 
                                                                                 201		23997.7304		-4.5000
25-09-27 14:25:32.875 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:25:32.876 - INFO: Train epoch 202:   Loss: 19505.1236 | r_Loss: 3165.4787 | g_Loss: 3478.8698 | l_Loss: 198.8602 | 
                                                                                 202		19505.1236		-4.5000
25-09-27 14:25:44.186 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:25:44.188 - INFO: Train epoch 203:   Loss: 20809.6104 | r_Loss: 3430.6657 | g_Loss: 3457.4380 | l_Loss: 198.8432 | 
                                                                                 203		20809.6104		-4.5000
25-09-27 14:25:55.721 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:25:55.723 - INFO: Train epoch 204:   Loss: 18851.0063 | r_Loss: 3046.8646 | g_Loss: 3418.9240 | l_Loss: 197.7593 | 
                                                                                 204		18851.0063		-4.5000
25-09-27 14:26:07.108 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:26:07.110 - INFO: Train epoch 205:   Loss: 18361.3378 | r_Loss: 2958.8619 | g_Loss: 3373.1391 | l_Loss: 193.8893 | 
                                                                                 205		18361.3378		-4.5000
25-09-27 14:26:18.516 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:26:18.518 - INFO: Train epoch 206:   Loss: 18455.7620 | r_Loss: 2991.6972 | g_Loss: 3306.5541 | l_Loss: 190.7221 | 
                                                                                 206		18455.7620		-4.5000
25-09-27 14:26:30.079 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:26:30.081 - INFO: Train epoch 207:   Loss: 18452.8212 | r_Loss: 2997.1665 | g_Loss: 3277.0540 | l_Loss: 189.9344 | 
                                                                                 207		18452.8212		-4.5000
25-09-27 14:26:41.450 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:26:41.451 - INFO: Train epoch 208:   Loss: 19506.1639 | r_Loss: 3218.5739 | g_Loss: 3225.0578 | l_Loss: 188.2366 | 
                                                                                 208		19506.1639		-4.5000
25-09-27 14:26:52.917 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:26:52.919 - INFO: Train epoch 209:   Loss: 22486.0062 | r_Loss: 3811.1522 | g_Loss: 3238.4209 | l_Loss: 191.8239 | 
                                                                                 209		22486.0062		-4.5000
25-09-27 14:27:04.349 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:27:04.350 - INFO: Train epoch 210:   Loss: 18249.3285 | r_Loss: 2955.1593 | g_Loss: 3282.9638 | l_Loss: 190.5680 | 
                                                                                 210		18249.3285		-4.5000
25-09-27 14:27:15.677 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:27:15.679 - INFO: Train epoch 211:   Loss: 18121.5441 | r_Loss: 2934.2749 | g_Loss: 3259.4495 | l_Loss: 190.7199 | 
                                                                                 211		18121.5441		-4.5000
25-09-27 14:27:26.910 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:27:26.912 - INFO: Train epoch 212:   Loss: 18239.3730 | r_Loss: 2969.9887 | g_Loss: 3201.1021 | l_Loss: 188.3274 | 
                                                                                 212		18239.3730		-4.5000
25-09-27 14:27:38.183 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:27:38.185 - INFO: Train epoch 213:   Loss: 18828.7550 | r_Loss: 3088.1633 | g_Loss: 3198.5334 | l_Loss: 189.4050 | 
                                                                                 213		18828.7550		-4.5000
25-09-27 14:27:49.590 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:27:49.592 - INFO: Train epoch 214:   Loss: 26979.0563 | r_Loss: 4683.6763 | g_Loss: 3363.8272 | l_Loss: 196.8478 | 
                                                                                 214		26979.0563		-4.5000
25-09-27 14:28:00.958 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:28:00.960 - INFO: Train epoch 215:   Loss: 17812.6270 | r_Loss: 2852.7827 | g_Loss: 3354.3630 | l_Loss: 194.3508 | 
                                                                                 215		17812.6270		-4.5000
25-09-27 14:28:12.178 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:28:12.179 - INFO: Train epoch 216:   Loss: 17935.1441 | r_Loss: 2885.5075 | g_Loss: 3314.0267 | l_Loss: 193.5800 | 
                                                                                 216		17935.1441		-4.5000
25-09-27 14:28:23.655 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:28:23.657 - INFO: Train epoch 217:   Loss: 17680.7280 | r_Loss: 2849.8735 | g_Loss: 3242.8551 | l_Loss: 188.5059 | 
                                                                                 217		17680.7280		-4.5000
25-09-27 14:28:35.077 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:28:35.079 - INFO: Train epoch 218:   Loss: 17952.3403 | r_Loss: 2901.7569 | g_Loss: 3249.4747 | l_Loss: 194.0815 | 
                                                                                 218		17952.3403		-4.5000
25-09-27 14:28:46.619 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:28:46.620 - INFO: Train epoch 219:   Loss: 34801.3600 | r_Loss: 6261.1623 | g_Loss: 3292.7758 | l_Loss: 202.7731 | 
                                                                                 219		34801.3600		-4.5000
25-09-27 14:28:58.056 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:28:58.057 - INFO: Train epoch 220:   Loss: 21638.8135 | r_Loss: 3570.4320 | g_Loss: 3588.5094 | l_Loss: 198.1443 | 
                                                                                 220		21638.8135		-4.5000
25-09-27 14:29:09.287 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:29:09.288 - INFO: Train epoch 221:   Loss: 16933.5281 | r_Loss: 2664.1142 | g_Loss: 3419.2881 | l_Loss: 193.6693 | 
                                                                                 221		16933.5281		-4.5000
25-09-27 14:29:20.686 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:29:20.688 - INFO: Train epoch 222:   Loss: 16959.7508 | r_Loss: 2665.1298 | g_Loss: 3436.4818 | l_Loss: 197.6199 | 
                                                                                 222		16959.7508		-4.5000
25-09-27 14:29:32.154 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:29:32.157 - INFO: Train epoch 223:   Loss: 16952.9004 | r_Loss: 2697.8172 | g_Loss: 3274.3801 | l_Loss: 189.4341 | 
                                                                                 223		16952.9004		-4.5000
25-09-27 14:29:43.577 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:29:43.579 - INFO: Train epoch 224:   Loss: 16844.1379 | r_Loss: 2672.9671 | g_Loss: 3287.0888 | l_Loss: 192.2136 | 
                                                                                 224		16844.1379		-4.5000
25-09-27 14:29:55.052 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:29:55.053 - INFO: Train epoch 225:   Loss: 17320.5833 | r_Loss: 2784.1720 | g_Loss: 3207.8832 | l_Loss: 191.8396 | 
                                                                                 225		17320.5833		-4.5000
25-09-27 14:30:06.323 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:30:06.324 - INFO: Train epoch 226:   Loss: 16586.9244 | r_Loss: 2651.5021 | g_Loss: 3140.7779 | l_Loss: 188.6359 | 
                                                                                 226		16586.9244		-4.5000
25-09-27 14:30:17.634 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:30:17.635 - INFO: Train epoch 227:   Loss: 16709.3233 | r_Loss: 2689.1725 | g_Loss: 3079.0281 | l_Loss: 184.4327 | 
                                                                                 227		16709.3233		-4.5000
25-09-27 14:30:29.059 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:30:29.061 - INFO: Train epoch 228:   Loss: 16700.3429 | r_Loss: 2695.8649 | g_Loss: 3035.3978 | l_Loss: 185.6201 | 
                                                                                 228		16700.3429		-4.5000
25-09-27 14:30:40.538 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:30:40.539 - INFO: Train epoch 229:   Loss: 17725.9096 | r_Loss: 2914.5154 | g_Loss: 2970.9269 | l_Loss: 182.4057 | 
                                                                                 229		17725.9096		-4.5000
25-09-27 14:30:51.999 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:30:52.001 - INFO: Train epoch 230:   Loss: 16375.3232 | r_Loss: 2638.3219 | g_Loss: 3001.1715 | l_Loss: 182.5420 | 
                                                                                 230		16375.3232		-4.5000
25-09-27 14:31:03.429 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:31:03.431 - INFO: Train epoch 231:   Loss: 16396.3428 | r_Loss: 2650.9297 | g_Loss: 2958.2128 | l_Loss: 183.4813 | 
                                                                                 231		16396.3428		-4.5000
25-09-27 14:31:14.823 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:31:14.824 - INFO: Train epoch 232:   Loss: 16287.0944 | r_Loss: 2637.7732 | g_Loss: 2916.7705 | l_Loss: 181.4581 | 
                                                                                 232		16287.0944		-4.5000
25-09-27 14:31:26.127 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:31:26.129 - INFO: Train epoch 233:   Loss: 72272.8856 | r_Loss: 13714.3143 | g_Loss: 3468.3761 | l_Loss: 232.9384 | 
                                                                                 233		72272.8856		-4.5000
25-09-27 14:31:37.520 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:31:37.521 - INFO: Train epoch 234:   Loss: 26965.9548 | r_Loss: 4329.6645 | g_Loss: 5076.2079 | l_Loss: 241.4240 | 
                                                                                 234		26965.9548		-4.5000
25-09-27 14:31:48.975 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:31:48.977 - INFO: Train epoch 235:   Loss: 20513.4468 | r_Loss: 3135.5435 | g_Loss: 4617.5716 | l_Loss: 218.1578 | 
                                                                                 235		20513.4468		-4.5000
25-09-27 14:32:00.431 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:32:00.432 - INFO: Train epoch 236:   Loss: 18289.2607 | r_Loss: 2766.8202 | g_Loss: 4250.5683 | l_Loss: 204.5910 | 
                                                                                 236		18289.2607		-4.5000
25-09-27 14:32:11.954 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:32:11.956 - INFO: Train epoch 237:   Loss: 17475.8112 | r_Loss: 2669.4609 | g_Loss: 3926.6714 | l_Loss: 201.8355 | 
                                                                                 237		17475.8112		-4.5000
25-09-27 14:32:23.278 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:32:23.279 - INFO: Train epoch 238:   Loss: 17627.6355 | r_Loss: 2685.7001 | g_Loss: 3993.3067 | l_Loss: 205.8281 | 
                                                                                 238		17627.6355		-4.5000
25-09-27 14:32:34.722 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:32:34.724 - INFO: Train epoch 239:   Loss: 17209.6694 | r_Loss: 2639.1821 | g_Loss: 3817.0591 | l_Loss: 196.6993 | 
                                                                                 239		17209.6694		-4.5000
25-09-27 14:32:46.041 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:32:46.043 - INFO: Train epoch 240:   Loss: 16580.0634 | r_Loss: 2553.5657 | g_Loss: 3623.9196 | l_Loss: 188.3156 | 
                                                                                 240		16580.0634		-4.5000
25-09-27 14:32:57.562 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:32:57.563 - INFO: Train epoch 241:   Loss: 16348.5811 | r_Loss: 2535.0565 | g_Loss: 3488.3405 | l_Loss: 184.9583 | 
                                                                                 241		16348.5811		-4.5000
25-09-27 14:33:08.975 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:33:08.977 - INFO: Train epoch 242:   Loss: 16040.3920 | r_Loss: 2483.3290 | g_Loss: 3438.1877 | l_Loss: 185.5593 | 
                                                                                 242		16040.3920		-4.5000
25-09-27 14:33:20.383 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:33:20.385 - INFO: Train epoch 243:   Loss: 16030.7058 | r_Loss: 2510.1688 | g_Loss: 3292.9335 | l_Loss: 186.9282 | 
                                                                                 243		16030.7058		-4.5000
25-09-27 14:33:31.933 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:33:31.934 - INFO: Train epoch 244:   Loss: 16289.3661 | r_Loss: 2573.0274 | g_Loss: 3237.5073 | l_Loss: 186.7218 | 
                                                                                 244		16289.3661		-4.5000
25-09-27 14:33:43.331 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:33:43.332 - INFO: Train epoch 245:   Loss: 15617.8905 | r_Loss: 2442.0027 | g_Loss: 3226.8035 | l_Loss: 181.0733 | 
                                                                                 245		15617.8905		-4.5000
25-09-27 14:33:54.761 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:33:54.762 - INFO: Train epoch 246:   Loss: 15622.2208 | r_Loss: 2449.8960 | g_Loss: 3188.1136 | l_Loss: 184.6273 | 
                                                                                 246		15622.2208		-4.5000
25-09-27 14:34:06.286 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:34:06.287 - INFO: Train epoch 247:   Loss: 16281.9111 | r_Loss: 2586.8576 | g_Loss: 3161.8764 | l_Loss: 185.7465 | 
                                                                                 247		16281.9111		-4.5000
25-09-27 14:34:17.802 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:34:17.805 - INFO: Train epoch 248:   Loss: 15078.8053 | r_Loss: 2380.1717 | g_Loss: 2995.6572 | l_Loss: 182.2900 | 
                                                                                 248		15078.8053		-4.5000
25-09-27 14:34:29.208 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:34:29.210 - INFO: Train epoch 249:   Loss: 15326.6739 | r_Loss: 2438.0576 | g_Loss: 2954.9210 | l_Loss: 181.4648 | 
                                                                                 249		15326.6739		-4.5000
25-09-27 14:37:22.017 - INFO: TEST:   PSNR_S: 27.5571 | PSNR_C: 25.4132 | 
25-09-27 14:37:22.019 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:37:22.022 - INFO: Train epoch 250:   Loss: 16972.7808 | r_Loss: 2759.5140 | g_Loss: 2990.4778 | l_Loss: 184.7326 | 
                                                                                 250		16972.7808		-4.5000
25-09-27 14:37:33.657 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:37:33.658 - INFO: Train epoch 251:   Loss: 14882.3027 | r_Loss: 2347.9383 | g_Loss: 2960.0278 | l_Loss: 182.5833 | 
                                                                                 251		14882.3027		-4.5000
25-09-27 14:37:45.002 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:37:45.004 - INFO: Train epoch 252:   Loss: 16009.7373 | r_Loss: 2567.9472 | g_Loss: 2981.4746 | l_Loss: 188.5270 | 
                                                                                 252		16009.7373		-4.5000
25-09-27 14:37:56.458 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:37:56.460 - INFO: Train epoch 253:   Loss: 15577.0157 | r_Loss: 2484.0562 | g_Loss: 2967.6266 | l_Loss: 189.1083 | 
                                                                                 253		15577.0157		-4.5000
25-09-27 14:38:07.687 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:38:07.688 - INFO: Train epoch 254:   Loss: 15845.6434 | r_Loss: 2548.8474 | g_Loss: 2910.1822 | l_Loss: 191.2241 | 
                                                                                 254		15845.6434		-4.5000
25-09-27 14:38:19.039 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:38:19.041 - INFO: Train epoch 255:   Loss: 14335.9985 | r_Loss: 2243.7959 | g_Loss: 2925.1282 | l_Loss: 191.8912 | 
                                                                                 255		14335.9985		-4.5000
25-09-27 14:38:30.483 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:38:30.484 - INFO: Train epoch 256:   Loss: 15189.1899 | r_Loss: 2414.8176 | g_Loss: 2923.1040 | l_Loss: 191.9982 | 
                                                                                 256		15189.1899		-4.5000
25-09-27 14:38:41.800 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:38:41.802 - INFO: Train epoch 257:   Loss: 15036.5909 | r_Loss: 2391.3273 | g_Loss: 2885.0646 | l_Loss: 194.8895 | 
                                                                                 257		15036.5909		-4.5000
25-09-27 14:38:53.136 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:38:53.138 - INFO: Train epoch 258:   Loss: 14405.2878 | r_Loss: 2283.5421 | g_Loss: 2798.5035 | l_Loss: 189.0736 | 
                                                                                 258		14405.2878		-4.5000
25-09-27 14:39:04.629 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:39:04.630 - INFO: Train epoch 259:   Loss: 25612.7897 | r_Loss: 4477.3197 | g_Loss: 3023.3765 | l_Loss: 202.8149 | 
                                                                                 259		25612.7897		-4.5000
25-09-27 14:39:16.122 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:39:16.124 - INFO: Train epoch 260:   Loss: 14940.6723 | r_Loss: 2312.9308 | g_Loss: 3176.5199 | l_Loss: 199.4986 | 
                                                                                 260		14940.6723		-4.5000
25-09-27 14:39:27.612 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:39:27.613 - INFO: Train epoch 261:   Loss: 14343.5929 | r_Loss: 2202.6524 | g_Loss: 3126.5876 | l_Loss: 203.7433 | 
                                                                                 261		14343.5929		-4.5000
25-09-27 14:39:38.944 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:39:38.946 - INFO: Train epoch 262:   Loss: 13426.0557 | r_Loss: 2041.5237 | g_Loss: 3023.3584 | l_Loss: 195.0789 | 
                                                                                 262		13426.0557		-4.5000
25-09-27 14:39:50.461 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:39:50.463 - INFO: Train epoch 263:   Loss: 14050.5432 | r_Loss: 2149.8030 | g_Loss: 3095.6551 | l_Loss: 205.8729 | 
                                                                                 263		14050.5432		-4.5000
25-09-27 14:40:01.844 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:40:01.846 - INFO: Train epoch 264:   Loss: 13373.6252 | r_Loss: 2031.2640 | g_Loss: 3015.7713 | l_Loss: 201.5338 | 
                                                                                 264		13373.6252		-4.5000
25-09-27 14:40:13.292 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:40:13.295 - INFO: Train epoch 265:   Loss: 13127.5794 | r_Loss: 1981.0143 | g_Loss: 3023.2380 | l_Loss: 199.2698 | 
                                                                                 265		13127.5794		-4.5000
25-09-27 14:40:24.692 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:40:24.694 - INFO: Train epoch 266:   Loss: 13619.0588 | r_Loss: 2083.3249 | g_Loss: 3003.5980 | l_Loss: 198.8363 | 
                                                                                 266		13619.0588		-4.5000
25-09-27 14:40:36.054 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:40:36.056 - INFO: Train epoch 267:   Loss: 12365.3101 | r_Loss: 1837.3109 | g_Loss: 2985.1822 | l_Loss: 193.5729 | 
                                                                                 267		12365.3101		-4.5000
25-09-27 14:40:47.700 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:40:47.704 - INFO: Train epoch 268:   Loss: 13872.1605 | r_Loss: 2124.3629 | g_Loss: 3053.5523 | l_Loss: 196.7937 | 
                                                                                 268		13872.1605		-4.5000
25-09-27 14:40:59.131 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:40:59.132 - INFO: Train epoch 269:   Loss: 14229.3050 | r_Loss: 2206.7139 | g_Loss: 3004.0629 | l_Loss: 191.6724 | 
                                                                                 269		14229.3050		-4.5000
25-09-27 14:41:10.484 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:41:10.484 - INFO: Train epoch 270:   Loss: 14467.2843 | r_Loss: 2253.5660 | g_Loss: 3009.3095 | l_Loss: 190.1449 | 
                                                                                 270		14467.2843		-4.5000
25-09-27 14:41:21.702 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:41:21.704 - INFO: Train epoch 271:   Loss: 12359.0938 | r_Loss: 1813.2988 | g_Loss: 3105.2555 | l_Loss: 187.3443 | 
                                                                                 271		12359.0938		-4.5000
25-09-27 14:41:33.085 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:41:33.087 - INFO: Train epoch 272:   Loss: 12293.8838 | r_Loss: 1801.7363 | g_Loss: 3096.5163 | l_Loss: 188.6858 | 
                                                                                 272		12293.8838		-4.5000
25-09-27 14:41:44.604 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:41:44.606 - INFO: Train epoch 273:   Loss: 13831.2865 | r_Loss: 2118.0250 | g_Loss: 3054.5202 | l_Loss: 186.6414 | 
                                                                                 273		13831.2865		-4.5000
25-09-27 14:41:55.860 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:41:55.862 - INFO: Train epoch 274:   Loss: 13025.9731 | r_Loss: 1954.2873 | g_Loss: 3070.2787 | l_Loss: 184.2578 | 
                                                                                 274		13025.9731		-4.5000
25-09-27 14:42:07.166 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:42:07.168 - INFO: Train epoch 275:   Loss: 11584.2437 | r_Loss: 1657.3611 | g_Loss: 3111.5803 | l_Loss: 185.8577 | 
                                                                                 275		11584.2437		-4.5000
25-09-27 14:42:18.656 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:42:18.657 - INFO: Train epoch 276:   Loss: 11320.8825 | r_Loss: 1618.0935 | g_Loss: 3048.3665 | l_Loss: 182.0482 | 
                                                                                 276		11320.8825		-4.5000
25-09-27 14:42:30.101 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:42:30.102 - INFO: Train epoch 277:   Loss: 12276.2650 | r_Loss: 1824.4314 | g_Loss: 2977.9536 | l_Loss: 176.1545 | 
                                                                                 277		12276.2650		-4.5000
25-09-27 14:42:41.298 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:42:41.300 - INFO: Train epoch 278:   Loss: 13671.8827 | r_Loss: 2096.4196 | g_Loss: 3013.5246 | l_Loss: 176.2601 | 
                                                                                 278		13671.8827		-4.5000
25-09-27 14:42:54.022 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:42:54.024 - INFO: Train epoch 279:   Loss: 13115.4668 | r_Loss: 1989.3295 | g_Loss: 2992.7701 | l_Loss: 176.0494 | 
                                                                                 279		13115.4668		-4.5000
25-09-27 14:43:05.472 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:43:05.474 - INFO: Train epoch 280:   Loss: 11107.3472 | r_Loss: 1594.1328 | g_Loss: 2964.9806 | l_Loss: 171.7028 | 
                                                                                 280		11107.3472		-4.5000
25-09-27 14:43:16.925 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:43:16.926 - INFO: Train epoch 281:   Loss: 10607.7035 | r_Loss: 1497.9185 | g_Loss: 2946.7451 | l_Loss: 171.3662 | 
                                                                                 281		10607.7035		-4.5000
25-09-27 14:43:28.303 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:43:28.304 - INFO: Train epoch 282:   Loss: 11609.9484 | r_Loss: 1704.1991 | g_Loss: 2918.5403 | l_Loss: 170.4126 | 
                                                                                 282		11609.9484		-4.5000
25-09-27 14:43:39.665 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:43:39.668 - INFO: Train epoch 283:   Loss: 12081.9717 | r_Loss: 1801.1749 | g_Loss: 2907.2845 | l_Loss: 168.8127 | 
                                                                                 283		12081.9717		-4.5000
25-09-27 14:43:51.133 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:43:51.135 - INFO: Train epoch 284:   Loss: 11833.8233 | r_Loss: 1754.1585 | g_Loss: 2895.8678 | l_Loss: 167.1631 | 
                                                                                 284		11833.8233		-4.5000
25-09-27 14:44:07.120 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:44:07.122 - INFO: Train epoch 285:   Loss: 10520.4972 | r_Loss: 1502.4337 | g_Loss: 2843.4853 | l_Loss: 164.8433 | 
                                                                                 285		10520.4972		-4.5000
25-09-27 14:44:18.507 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:44:18.509 - INFO: Train epoch 286:   Loss: 11129.7040 | r_Loss: 1617.6186 | g_Loss: 2870.0998 | l_Loss: 171.5112 | 
                                                                                 286		11129.7040		-4.5000
25-09-27 14:44:29.779 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:44:29.781 - INFO: Train epoch 287:   Loss: 17571.4045 | r_Loss: 2909.9002 | g_Loss: 2852.9443 | l_Loss: 168.9590 | 
                                                                                 287		17571.4045		-4.5000
25-09-27 14:44:40.832 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:44:40.833 - INFO: Train epoch 288:   Loss: 12223.8810 | r_Loss: 1812.9666 | g_Loss: 2983.9752 | l_Loss: 175.0726 | 
                                                                                 288		12223.8810		-4.5000
25-09-27 14:44:54.684 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:44:54.687 - INFO: Train epoch 289:   Loss: 10359.8946 | r_Loss: 1447.5097 | g_Loss: 2951.5586 | l_Loss: 170.7872 | 
                                                                                 289		10359.8946		-4.5000
25-09-27 14:45:06.196 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:45:06.198 - INFO: Train epoch 290:   Loss: 10145.2789 | r_Loss: 1418.6436 | g_Loss: 2885.0062 | l_Loss: 167.0546 | 
                                                                                 290		10145.2789		-4.5000
25-09-27 14:45:17.688 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:45:17.690 - INFO: Train epoch 291:   Loss: 10559.8633 | r_Loss: 1509.6017 | g_Loss: 2845.1181 | l_Loss: 166.7366 | 
                                                                                 291		10559.8633		-4.5000
25-09-27 14:45:28.897 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:45:28.899 - INFO: Train epoch 292:   Loss: 10375.5864 | r_Loss: 1473.0254 | g_Loss: 2843.0154 | l_Loss: 167.4439 | 
                                                                                 292		10375.5864		-4.5000
25-09-27 14:45:40.232 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:45:40.235 - INFO: Train epoch 293:   Loss: 10870.4981 | r_Loss: 1590.3263 | g_Loss: 2756.1015 | l_Loss: 162.7653 | 
                                                                                 293		10870.4981		-4.5000
25-09-27 14:45:51.705 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:45:51.706 - INFO: Train epoch 294:   Loss: 12629.5308 | r_Loss: 1937.4264 | g_Loss: 2780.4056 | l_Loss: 161.9932 | 
                                                                                 294		12629.5308		-4.5000
25-09-27 14:46:02.972 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:46:02.974 - INFO: Train epoch 295:   Loss: 9871.2568 | r_Loss: 1395.8696 | g_Loss: 2730.2485 | l_Loss: 161.6603 | 
                                                                                 295		9871.2568		-4.5000
25-09-27 14:46:14.222 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:46:14.224 - INFO: Train epoch 296:   Loss: 9661.1815 | r_Loss: 1358.8344 | g_Loss: 2705.7576 | l_Loss: 161.2519 | 
                                                                                 296		9661.1815		-4.5000
25-09-27 14:46:25.472 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:46:25.473 - INFO: Train epoch 297:   Loss: 10467.8460 | r_Loss: 1520.8557 | g_Loss: 2700.8516 | l_Loss: 162.7157 | 
                                                                                 297		10467.8460		-4.5000
25-09-27 14:46:36.903 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:46:36.904 - INFO: Train epoch 298:   Loss: 11037.4074 | r_Loss: 1627.5232 | g_Loss: 2737.4661 | l_Loss: 162.3248 | 
                                                                                 298		11037.4074		-4.5000
25-09-27 14:46:50.436 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:46:50.438 - INFO: Train epoch 299:   Loss: 11484.5082 | r_Loss: 1733.1809 | g_Loss: 2661.0935 | l_Loss: 157.5102 | 
                                                                                 299		11484.5082		-4.5000
25-09-27 14:48:11.880 - INFO: TEST:   PSNR_S: 30.7868 | PSNR_C: 25.9052 | 
25-09-27 14:48:11.882 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:48:11.883 - INFO: Train epoch 300:   Loss: 11065.7290 | r_Loss: 1632.7323 | g_Loss: 2742.8642 | l_Loss: 159.2036 | 
                                                                                 300		11065.7290		-4.5000
25-09-27 14:48:23.538 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:48:23.540 - INFO: Train epoch 301:   Loss: 10717.3236 | r_Loss: 1569.3107 | g_Loss: 2714.5211 | l_Loss: 156.2493 | 
                                                                                 301		10717.3236		-4.5000
25-09-27 14:48:35.075 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:48:35.077 - INFO: Train epoch 302:   Loss: 10445.4177 | r_Loss: 1513.3801 | g_Loss: 2721.4169 | l_Loss: 157.1006 | 
                                                                                 302		10445.4177		-4.5000
25-09-27 14:48:48.614 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:48:48.616 - INFO: Train epoch 303:   Loss: 9355.2180 | r_Loss: 1314.9022 | g_Loss: 2624.9611 | l_Loss: 155.7459 | 
                                                                                 303		9355.2180		-4.5000
25-09-27 14:48:59.937 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:48:59.938 - INFO: Train epoch 304:   Loss: 9237.7213 | r_Loss: 1292.2804 | g_Loss: 2620.9078 | l_Loss: 155.4115 | 
                                                                                 304		9237.7213		-4.5000
25-09-27 14:49:11.236 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:49:11.238 - INFO: Train epoch 305:   Loss: 12576.2120 | r_Loss: 1964.0269 | g_Loss: 2599.8478 | l_Loss: 156.2296 | 
                                                                                 305		12576.2120		-4.5000
25-09-27 14:49:22.591 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:49:22.592 - INFO: Train epoch 306:   Loss: 9480.0622 | r_Loss: 1336.9782 | g_Loss: 2639.4187 | l_Loss: 155.7527 | 
                                                                                 306		9480.0622		-4.5000
25-09-27 14:49:36.596 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:49:36.598 - INFO: Train epoch 307:   Loss: 10014.6885 | r_Loss: 1447.8243 | g_Loss: 2621.4028 | l_Loss: 154.1642 | 
                                                                                 307		10014.6885		-4.5000
25-09-27 14:49:47.962 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:49:47.964 - INFO: Train epoch 308:   Loss: 52602.8265 | r_Loss: 9859.5935 | g_Loss: 3087.0972 | l_Loss: 217.7593 | 
                                                                                 308		52602.8265		-4.5000
25-09-27 14:49:59.145 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:49:59.147 - INFO: Train epoch 309:   Loss: 93301.3853 | r_Loss: 16893.1233 | g_Loss: 7391.2801 | l_Loss: 1444.4878 | 
                                                                                 309		93301.3853		-4.5000
25-09-27 14:50:10.683 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:50:10.684 - INFO: Train epoch 310:   Loss: 19810.6601 | r_Loss: 2689.2373 | g_Loss: 5680.2448 | l_Loss: 684.2288 | 
                                                                                 310		19810.6601		-4.5000
25-09-27 14:50:22.010 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:50:22.013 - INFO: Train epoch 311:   Loss: 15664.9020 | r_Loss: 2056.3927 | g_Loss: 4916.2983 | l_Loss: 466.6404 | 
                                                                                 311		15664.9020		-4.5000
25-09-27 14:50:33.630 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:50:33.632 - INFO: Train epoch 312:   Loss: 14050.4562 | r_Loss: 1826.5459 | g_Loss: 4555.8478 | l_Loss: 361.8787 | 
                                                                                 312		14050.4562		-4.5000
25-09-27 14:50:44.855 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:50:44.858 - INFO: Train epoch 313:   Loss: 13202.1592 | r_Loss: 1702.4627 | g_Loss: 4385.6228 | l_Loss: 304.2227 | 
                                                                                 313		13202.1592		-4.5000
25-09-27 14:50:56.313 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:50:56.314 - INFO: Train epoch 314:   Loss: 12569.6350 | r_Loss: 1616.8209 | g_Loss: 4221.7905 | l_Loss: 263.7399 | 
                                                                                 314		12569.6350		-4.5000
25-09-27 14:51:09.190 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:51:09.192 - INFO: Train epoch 315:   Loss: 11674.5026 | r_Loss: 1501.5597 | g_Loss: 3936.8210 | l_Loss: 229.8831 | 
                                                                                 315		11674.5026		-4.5000
25-09-27 14:51:20.654 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:51:20.656 - INFO: Train epoch 316:   Loss: 11348.1002 | r_Loss: 1460.1366 | g_Loss: 3829.7213 | l_Loss: 217.6961 | 
                                                                                 316		11348.1002		-4.5000
25-09-27 14:51:32.042 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:51:32.044 - INFO: Train epoch 317:   Loss: 11297.7627 | r_Loss: 1466.5581 | g_Loss: 3764.2735 | l_Loss: 200.6987 | 
                                                                                 317		11297.7627		-4.5000
25-09-27 14:51:43.387 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:51:43.388 - INFO: Train epoch 318:   Loss: 10821.9102 | r_Loss: 1398.4996 | g_Loss: 3639.0988 | l_Loss: 190.3133 | 
                                                                                 318		10821.9102		-4.5000
25-09-27 14:51:54.729 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:51:54.731 - INFO: Train epoch 319:   Loss: 10653.5083 | r_Loss: 1379.5584 | g_Loss: 3570.3999 | l_Loss: 185.3165 | 
                                                                                 319		10653.5083		-4.5000
25-09-27 14:52:06.182 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:52:06.183 - INFO: Train epoch 320:   Loss: 10689.0871 | r_Loss: 1394.3666 | g_Loss: 3535.8919 | l_Loss: 181.3620 | 
                                                                                 320		10689.0871		-4.5000
25-09-27 14:52:17.572 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:52:17.574 - INFO: Train epoch 321:   Loss: 10543.2992 | r_Loss: 1390.2103 | g_Loss: 3417.3712 | l_Loss: 174.8765 | 
                                                                                 321		10543.2992		-4.5000
25-09-27 14:52:28.862 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:52:28.864 - INFO: Train epoch 322:   Loss: 10042.8099 | r_Loss: 1313.2602 | g_Loss: 3308.0433 | l_Loss: 168.4658 | 
                                                                                 322		10042.8099		-4.5000
25-09-27 14:52:40.442 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:52:40.444 - INFO: Train epoch 323:   Loss: 10357.4120 | r_Loss: 1392.8229 | g_Loss: 3225.1983 | l_Loss: 168.0991 | 
                                                                                 323		10357.4120		-4.5000
25-09-27 14:52:51.887 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:52:51.888 - INFO: Train epoch 324:   Loss: 9913.7865 | r_Loss: 1309.2709 | g_Loss: 3202.4667 | l_Loss: 164.9651 | 
                                                                                 324		9913.7865		-4.5000
25-09-27 14:53:03.320 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:53:03.322 - INFO: Train epoch 325:   Loss: 9904.0578 | r_Loss: 1322.9519 | g_Loss: 3128.7508 | l_Loss: 160.5476 | 
                                                                                 325		9904.0578		-4.5000
25-09-27 14:53:14.722 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:53:14.724 - INFO: Train epoch 326:   Loss: 9918.6488 | r_Loss: 1331.1593 | g_Loss: 3099.5783 | l_Loss: 163.2739 | 
                                                                                 326		9918.6488		-4.5000
25-09-27 14:53:26.212 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:53:26.214 - INFO: Train epoch 327:   Loss: 9430.3822 | r_Loss: 1264.9584 | g_Loss: 2949.2467 | l_Loss: 156.3436 | 
                                                                                 327		9430.3822		-4.5000
25-09-27 14:53:37.787 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:53:37.789 - INFO: Train epoch 328:   Loss: 9314.1011 | r_Loss: 1244.3984 | g_Loss: 2937.5876 | l_Loss: 154.5215 | 
                                                                                 328		9314.1011		-4.5000
25-09-27 14:53:49.348 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:53:49.350 - INFO: Train epoch 329:   Loss: 9788.1738 | r_Loss: 1353.6970 | g_Loss: 2868.1898 | l_Loss: 151.4991 | 
                                                                                 329		9788.1738		-4.5000
25-09-27 14:54:00.803 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:54:00.806 - INFO: Train epoch 330:   Loss: 9377.5347 | r_Loss: 1268.3961 | g_Loss: 2881.8674 | l_Loss: 153.6865 | 
                                                                                 330		9377.5347		-4.5000
25-09-27 14:54:12.568 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:54:12.570 - INFO: Train epoch 331:   Loss: 10068.1414 | r_Loss: 1411.4129 | g_Loss: 2857.8337 | l_Loss: 153.2433 | 
                                                                                 331		10068.1414		-4.5000
25-09-27 14:54:23.899 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:54:23.901 - INFO: Train epoch 332:   Loss: 9529.2745 | r_Loss: 1310.2141 | g_Loss: 2825.9718 | l_Loss: 152.2324 | 
                                                                                 332		9529.2745		-4.5000
25-09-27 14:54:35.385 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:54:35.387 - INFO: Train epoch 333:   Loss: 9095.9035 | r_Loss: 1237.2135 | g_Loss: 2760.2815 | l_Loss: 149.5543 | 
                                                                                 333		9095.9035		-4.5000
25-09-27 14:54:46.729 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:54:46.731 - INFO: Train epoch 334:   Loss: 9739.6984 | r_Loss: 1365.3832 | g_Loss: 2762.2233 | l_Loss: 150.5593 | 
                                                                                 334		9739.6984		-4.5000
25-09-27 14:54:58.056 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:54:58.058 - INFO: Train epoch 335:   Loss: 9771.3462 | r_Loss: 1375.4674 | g_Loss: 2743.3622 | l_Loss: 150.6470 | 
                                                                                 335		9771.3462		-4.5000
25-09-27 14:55:09.424 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:55:09.427 - INFO: Train epoch 336:   Loss: 9109.2299 | r_Loss: 1248.9143 | g_Loss: 2718.1599 | l_Loss: 146.4985 | 
                                                                                 336		9109.2299		-4.5000
25-09-27 14:55:20.805 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:55:20.807 - INFO: Train epoch 337:   Loss: 9010.3773 | r_Loss: 1237.9969 | g_Loss: 2673.6060 | l_Loss: 146.7871 | 
                                                                                 337		9010.3773		-4.5000
25-09-27 14:55:32.198 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:55:32.200 - INFO: Train epoch 338:   Loss: 9139.8925 | r_Loss: 1271.2474 | g_Loss: 2638.8905 | l_Loss: 144.7648 | 
                                                                                 338		9139.8925		-4.5000
25-09-27 14:55:43.531 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:55:43.532 - INFO: Train epoch 339:   Loss: 9767.6001 | r_Loss: 1403.7494 | g_Loss: 2604.6772 | l_Loss: 144.1756 | 
                                                                                 339		9767.6001		-4.5000
25-09-27 14:55:54.925 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:55:54.927 - INFO: Train epoch 340:   Loss: 12779.2864 | r_Loss: 1989.0095 | g_Loss: 2684.9341 | l_Loss: 149.3052 | 
                                                                                 340		12779.2864		-4.5000
25-09-27 14:56:06.372 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:56:06.374 - INFO: Train epoch 341:   Loss: 8813.1886 | r_Loss: 1211.9032 | g_Loss: 2607.5109 | l_Loss: 146.1614 | 
                                                                                 341		8813.1886		-4.5000
25-09-27 14:56:17.640 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:56:17.642 - INFO: Train epoch 342:   Loss: 8761.5279 | r_Loss: 1198.3438 | g_Loss: 2625.0967 | l_Loss: 144.7124 | 
                                                                                 342		8761.5279		-4.5000
25-09-27 14:56:28.970 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:56:28.971 - INFO: Train epoch 343:   Loss: 8444.1535 | r_Loss: 1154.0260 | g_Loss: 2535.3401 | l_Loss: 138.6835 | 
                                                                                 343		8444.1535		-4.5000
25-09-27 14:56:40.451 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:56:40.453 - INFO: Train epoch 344:   Loss: 8493.6746 | r_Loss: 1169.2740 | g_Loss: 2507.5823 | l_Loss: 139.7223 | 
                                                                                 344		8493.6746		-4.5000
25-09-27 14:56:52.315 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:56:52.316 - INFO: Train epoch 345:   Loss: 8697.1054 | r_Loss: 1197.6629 | g_Loss: 2565.3239 | l_Loss: 143.4669 | 
                                                                                 345		8697.1054		-4.5000
25-09-27 14:57:03.786 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:57:03.788 - INFO: Train epoch 346:   Loss: 9168.6016 | r_Loss: 1303.1122 | g_Loss: 2512.0957 | l_Loss: 140.9452 | 
                                                                                 346		9168.6016		-4.5000
25-09-27 14:57:15.797 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:57:15.799 - INFO: Train epoch 347:   Loss: 8712.3620 | r_Loss: 1214.5432 | g_Loss: 2500.7388 | l_Loss: 138.9070 | 
                                                                                 347		8712.3620		-4.5000
25-09-27 14:57:27.144 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:57:27.146 - INFO: Train epoch 348:   Loss: 8851.1256 | r_Loss: 1257.7248 | g_Loss: 2426.5209 | l_Loss: 135.9807 | 
                                                                                 348		8851.1256		-4.5000
25-09-27 14:57:38.576 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:57:38.578 - INFO: Train epoch 349:   Loss: 8476.2827 | r_Loss: 1180.3933 | g_Loss: 2437.9270 | l_Loss: 136.3891 | 
                                                                                 349		8476.2827		-4.5000
25-09-27 14:59:59.248 - INFO: TEST:   PSNR_S: 33.3724 | PSNR_C: 26.5477 | 
25-09-27 14:59:59.250 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 14:59:59.251 - INFO: Train epoch 350:   Loss: 8837.1653 | r_Loss: 1260.1373 | g_Loss: 2403.3364 | l_Loss: 133.1427 | 
                                                                                 350		8837.1653		-4.5000
25-09-27 15:00:11.597 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:00:11.599 - INFO: Train epoch 351:   Loss: 8128.8108 | r_Loss: 1119.2113 | g_Loss: 2399.5425 | l_Loss: 133.2119 | 
                                                                                 351		8128.8108		-4.5000
25-09-27 15:00:27.961 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:00:27.963 - INFO: Train epoch 352:   Loss: 8409.8214 | r_Loss: 1187.1856 | g_Loss: 2341.9438 | l_Loss: 131.9495 | 
                                                                                 352		8409.8214		-4.5000
25-09-27 15:00:39.824 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:00:39.826 - INFO: Train epoch 353:   Loss: 12182.6154 | r_Loss: 1929.7162 | g_Loss: 2398.7358 | l_Loss: 135.2989 | 
                                                                                 353		12182.6154		-4.5000
25-09-27 15:00:51.094 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:00:51.097 - INFO: Train epoch 354:   Loss: 10531.9719 | r_Loss: 1550.6543 | g_Loss: 2634.0689 | l_Loss: 144.6314 | 
                                                                                 354		10531.9719		-4.5000
25-09-27 15:01:04.396 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:01:04.396 - INFO: Train epoch 355:   Loss: 8464.3381 | r_Loss: 1163.1326 | g_Loss: 2511.9746 | l_Loss: 136.7006 | 
                                                                                 355		8464.3381		-4.5000
25-09-27 15:01:22.204 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:01:22.206 - INFO: Train epoch 356:   Loss: 8116.0663 | r_Loss: 1110.5679 | g_Loss: 2431.1826 | l_Loss: 132.0446 | 
                                                                                 356		8116.0663		-4.5000
25-09-27 15:01:33.424 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:01:33.426 - INFO: Train epoch 357:   Loss: 8217.1527 | r_Loss: 1131.6893 | g_Loss: 2424.4293 | l_Loss: 134.2768 | 
                                                                                 357		8217.1527		-4.5000
25-09-27 15:01:50.076 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:01:50.078 - INFO: Train epoch 358:   Loss: 8124.7130 | r_Loss: 1123.3036 | g_Loss: 2377.1951 | l_Loss: 130.9999 | 
                                                                                 358		8124.7130		-4.5000
25-09-27 15:02:01.460 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:02:01.462 - INFO: Train epoch 359:   Loss: 8067.1625 | r_Loss: 1119.0619 | g_Loss: 2340.2842 | l_Loss: 131.5686 | 
                                                                                 359		8067.1625		-4.5000
25-09-27 15:02:12.980 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:02:12.982 - INFO: Train epoch 360:   Loss: 8604.1884 | r_Loss: 1224.6180 | g_Loss: 2351.2008 | l_Loss: 129.8979 | 
                                                                                 360		8604.1884		-4.5000
25-09-27 15:02:24.306 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:02:24.308 - INFO: Train epoch 361:   Loss: 8227.0040 | r_Loss: 1158.9826 | g_Loss: 2301.6541 | l_Loss: 130.4368 | 
                                                                                 361		8227.0040		-4.5000
25-09-27 15:02:40.191 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:02:40.193 - INFO: Train epoch 362:   Loss: 7881.5226 | r_Loss: 1088.8978 | g_Loss: 2309.6823 | l_Loss: 127.3515 | 
                                                                                 362		7881.5226		-4.5000
25-09-27 15:02:51.883 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:02:51.885 - INFO: Train epoch 363:   Loss: 9731.7834 | r_Loss: 1468.9718 | g_Loss: 2258.2511 | l_Loss: 128.6731 | 
                                                                                 363		9731.7834		-4.5000
25-09-27 15:03:03.157 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:03:03.159 - INFO: Train epoch 364:   Loss: 8217.2154 | r_Loss: 1151.5982 | g_Loss: 2330.9979 | l_Loss: 128.2265 | 
                                                                                 364		8217.2154		-4.5000
25-09-27 15:03:14.641 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:03:14.643 - INFO: Train epoch 365:   Loss: 7937.6711 | r_Loss: 1106.4839 | g_Loss: 2278.3404 | l_Loss: 126.9113 | 
                                                                                 365		7937.6711		-4.5000
25-09-27 15:03:26.237 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:03:26.238 - INFO: Train epoch 366:   Loss: 8142.7609 | r_Loss: 1143.4600 | g_Loss: 2295.5100 | l_Loss: 129.9507 | 
                                                                                 366		8142.7609		-4.5000
25-09-27 15:03:37.716 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:03:37.718 - INFO: Train epoch 367:   Loss: 8998.0043 | r_Loss: 1319.2704 | g_Loss: 2275.6249 | l_Loss: 126.0278 | 
                                                                                 367		8998.0043		-4.5000
25-09-27 15:03:50.692 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:03:50.694 - INFO: Train epoch 368:   Loss: 8002.1097 | r_Loss: 1127.4819 | g_Loss: 2241.0546 | l_Loss: 123.6456 | 
                                                                                 368		8002.1097		-4.5000
25-09-27 15:04:02.077 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:04:02.079 - INFO: Train epoch 369:   Loss: 7692.1074 | r_Loss: 1065.5568 | g_Loss: 2242.0929 | l_Loss: 122.2303 | 
                                                                                 369		7692.1074		-4.5000
25-09-27 15:04:13.443 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:04:13.445 - INFO: Train epoch 370:   Loss: 7556.5446 | r_Loss: 1049.4606 | g_Loss: 2187.0997 | l_Loss: 122.1418 | 
                                                                                 370		7556.5446		-4.5000
25-09-27 15:04:24.789 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:04:24.791 - INFO: Train epoch 371:   Loss: 8001.5082 | r_Loss: 1137.4541 | g_Loss: 2192.2786 | l_Loss: 121.9590 | 
                                                                                 371		8001.5082		-4.5000
25-09-27 15:04:40.822 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:04:40.824 - INFO: Train epoch 372:   Loss: 10700.1039 | r_Loss: 1666.7987 | g_Loss: 2245.0542 | l_Loss: 121.0565 | 
                                                                                 372		10700.1039		-4.5000
25-09-27 15:04:52.167 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:04:52.169 - INFO: Train epoch 373:   Loss: 7452.3617 | r_Loss: 1028.8897 | g_Loss: 2191.4845 | l_Loss: 116.4288 | 
                                                                                 373		7452.3617		-4.5000
25-09-27 15:05:03.658 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:05:03.659 - INFO: Train epoch 374:   Loss: 7745.9076 | r_Loss: 1069.6225 | g_Loss: 2273.3943 | l_Loss: 124.4008 | 
                                                                                 374		7745.9076		-4.5000
25-09-27 15:05:15.300 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:05:15.302 - INFO: Train epoch 375:   Loss: 7592.9003 | r_Loss: 1055.7775 | g_Loss: 2194.8989 | l_Loss: 119.1140 | 
                                                                                 375		7592.9003		-4.5000
25-09-27 15:05:26.713 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:05:26.716 - INFO: Train epoch 376:   Loss: 7356.9304 | r_Loss: 1024.4567 | g_Loss: 2119.6938 | l_Loss: 114.9533 | 
                                                                                 376		7356.9304		-4.5000
25-09-27 15:05:41.228 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:05:41.230 - INFO: Train epoch 377:   Loss: 7593.6029 | r_Loss: 1062.7656 | g_Loss: 2161.7465 | l_Loss: 118.0285 | 
                                                                                 377		7593.6029		-4.5000
25-09-27 15:05:52.551 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:05:52.553 - INFO: Train epoch 378:   Loss: 8629.1448 | r_Loss: 1270.7746 | g_Loss: 2158.2254 | l_Loss: 117.0463 | 
                                                                                 378		8629.1448		-4.5000
25-09-27 15:06:05.356 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:06:05.358 - INFO: Train epoch 379:   Loss: 7279.5843 | r_Loss: 1004.9216 | g_Loss: 2137.6178 | l_Loss: 117.3589 | 
                                                                                 379		7279.5843		-4.5000
25-09-27 15:06:16.617 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:06:16.619 - INFO: Train epoch 380:   Loss: 7443.3025 | r_Loss: 1032.7326 | g_Loss: 2164.0251 | l_Loss: 115.6145 | 
                                                                                 380		7443.3025		-4.5000
25-09-27 15:06:27.994 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:06:27.996 - INFO: Train epoch 381:   Loss: 7189.1296 | r_Loss: 999.2262 | g_Loss: 2081.3096 | l_Loss: 111.6892 | 
                                                                                 381		7189.1296		-4.5000
25-09-27 15:06:45.718 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:06:45.720 - INFO: Train epoch 382:   Loss: 7553.7714 | r_Loss: 1060.7256 | g_Loss: 2135.4228 | l_Loss: 114.7204 | 
                                                                                 382		7553.7714		-4.5000
25-09-27 15:06:57.063 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:06:57.065 - INFO: Train epoch 383:   Loss: 8442.0177 | r_Loss: 1244.1086 | g_Loss: 2107.4530 | l_Loss: 114.0216 | 
                                                                                 383		8442.0177		-4.5000
25-09-27 15:07:12.215 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:07:12.216 - INFO: Train epoch 384:   Loss: 270600.7301 | r_Loss: 49707.6028 | g_Loss: 16008.4386 | l_Loss: 6054.2790 | 
                                                                                 384		270600.7301		-4.5000
25-09-27 15:07:28.009 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:07:28.011 - INFO: Train epoch 385:   Loss: 79687.8200 | r_Loss: 12022.5676 | g_Loss: 16120.0881 | l_Loss: 3454.8950 | 
                                                                                 385		79687.8200		-4.5000
25-09-27 15:07:39.532 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:07:39.534 - INFO: Train epoch 386:   Loss: 31178.4661 | r_Loss: 3092.7619 | g_Loss: 13167.4075 | l_Loss: 2547.2496 | 
                                                                                 386		31178.4661		-4.5000
25-09-27 15:07:50.828 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:07:50.830 - INFO: Train epoch 387:   Loss: 23494.2842 | r_Loss: 2348.6794 | g_Loss: 10447.2008 | l_Loss: 1303.6863 | 
                                                                                 387		23494.2842		-4.5000
25-09-27 15:08:09.073 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:08:09.074 - INFO: Train epoch 388:   Loss: 18623.6172 | r_Loss: 1806.6924 | g_Loss: 8795.3131 | l_Loss: 794.8425 | 
                                                                                 388		18623.6172		-4.5000
25-09-27 15:08:20.566 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:08:20.568 - INFO: Train epoch 389:   Loss: 16714.1281 | r_Loss: 1663.3158 | g_Loss: 7845.9427 | l_Loss: 551.6062 | 
                                                                                 389		16714.1281		-4.5000
25-09-27 15:08:31.888 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:08:31.890 - INFO: Train epoch 390:   Loss: 15352.4292 | r_Loss: 1558.9416 | g_Loss: 7128.6328 | l_Loss: 429.0883 | 
                                                                                 390		15352.4292		-4.5000
25-09-27 15:08:45.838 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:08:45.840 - INFO: Train epoch 391:   Loss: 14362.5269 | r_Loss: 1479.3109 | g_Loss: 6611.3983 | l_Loss: 354.5736 | 
                                                                                 391		14362.5269		-4.5000
25-09-27 15:08:57.354 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:08:57.355 - INFO: Train epoch 392:   Loss: 14643.1523 | r_Loss: 1629.4174 | g_Loss: 6194.1276 | l_Loss: 301.9375 | 
                                                                                 392		14643.1523		-4.5000
25-09-27 15:09:08.473 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:09:08.475 - INFO: Train epoch 393:   Loss: 13087.4114 | r_Loss: 1392.0133 | g_Loss: 5862.0745 | l_Loss: 265.2703 | 
                                                                                 393		13087.4114		-4.5000
25-09-27 15:09:19.815 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:09:19.816 - INFO: Train epoch 394:   Loss: 12475.9234 | r_Loss: 1372.7157 | g_Loss: 5379.6438 | l_Loss: 232.7012 | 
                                                                                 394		12475.9234		-4.5000
25-09-27 15:09:34.114 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:09:34.116 - INFO: Train epoch 395:   Loss: 12284.4685 | r_Loss: 1362.4512 | g_Loss: 5258.1110 | l_Loss: 214.1016 | 
                                                                                 395		12284.4685		-4.5000
25-09-27 15:09:45.656 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:09:45.658 - INFO: Train epoch 396:   Loss: 12011.0789 | r_Loss: 1389.5957 | g_Loss: 4864.4796 | l_Loss: 198.6209 | 
                                                                                 396		12011.0789		-4.5000
25-09-27 15:09:57.032 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:09:57.034 - INFO: Train epoch 397:   Loss: 12423.4162 | r_Loss: 1518.9046 | g_Loss: 4639.4773 | l_Loss: 189.4156 | 
                                                                                 397		12423.4162		-4.5000
25-09-27 15:10:20.077 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:10:20.079 - INFO: Train epoch 398:   Loss: 13304.8580 | r_Loss: 1686.4939 | g_Loss: 4689.7170 | l_Loss: 182.6713 | 
                                                                                 398		13304.8580		-4.5000
25-09-27 15:10:31.327 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:10:31.329 - INFO: Train epoch 399:   Loss: 11016.0024 | r_Loss: 1272.2591 | g_Loss: 4484.4495 | l_Loss: 170.2573 | 
                                                                                 399		11016.0024		-4.5000
25-09-27 15:12:05.860 - INFO: TEST:   PSNR_S: 33.0418 | PSNR_C: 23.6975 | 
25-09-27 15:12:05.861 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:12:05.863 - INFO: Train epoch 400:   Loss: 10535.8584 | r_Loss: 1205.0365 | g_Loss: 4346.5191 | l_Loss: 164.1569 | 
                                                                                 400		10535.8584		-4.5000
25-09-27 15:12:17.497 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:12:17.498 - INFO: Train epoch 401:   Loss: 10265.7000 | r_Loss: 1186.3047 | g_Loss: 4176.2796 | l_Loss: 157.8968 | 
                                                                                 401		10265.7000		-4.5000
25-09-27 15:12:28.775 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:12:28.776 - INFO: Train epoch 402:   Loss: 11143.2560 | r_Loss: 1404.0525 | g_Loss: 3969.5042 | l_Loss: 153.4893 | 
                                                                                 402		11143.2560		-4.5000
25-09-27 15:12:40.232 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:12:40.234 - INFO: Train epoch 403:   Loss: 10572.4930 | r_Loss: 1288.8320 | g_Loss: 3975.2910 | l_Loss: 153.0418 | 
                                                                                 403		10572.4930		-4.5000
25-09-27 15:12:51.712 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:12:51.713 - INFO: Train epoch 404:   Loss: 9794.1927 | r_Loss: 1165.7476 | g_Loss: 3818.5498 | l_Loss: 146.9049 | 
                                                                                 404		9794.1927		-4.5000
25-09-27 15:13:03.323 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:13:03.325 - INFO: Train epoch 405:   Loss: 10483.9986 | r_Loss: 1322.1402 | g_Loss: 3730.0356 | l_Loss: 143.2622 | 
                                                                                 405		10483.9986		-4.5000
25-09-27 15:13:14.674 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:13:14.675 - INFO: Train epoch 406:   Loss: 10926.6606 | r_Loss: 1416.4981 | g_Loss: 3702.8543 | l_Loss: 141.3156 | 
                                                                                 406		10926.6606		-4.5000
25-09-27 15:13:26.136 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:13:26.137 - INFO: Train epoch 407:   Loss: 9734.9689 | r_Loss: 1194.6779 | g_Loss: 3626.6727 | l_Loss: 134.9064 | 
                                                                                 407		9734.9689		-4.5000
25-09-27 15:13:37.672 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:13:37.674 - INFO: Train epoch 408:   Loss: 10219.3757 | r_Loss: 1291.0414 | g_Loss: 3626.0836 | l_Loss: 138.0853 | 
                                                                                 408		10219.3757		-4.5000
25-09-27 15:13:49.230 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:13:49.231 - INFO: Train epoch 409:   Loss: 11055.6420 | r_Loss: 1468.4044 | g_Loss: 3579.3762 | l_Loss: 134.2436 | 
                                                                                 409		11055.6420		-4.5000
25-09-27 15:14:00.728 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:14:00.729 - INFO: Train epoch 410:   Loss: 9265.8179 | r_Loss: 1132.3122 | g_Loss: 3472.4865 | l_Loss: 131.7703 | 
                                                                                 410		9265.8179		-4.5000
25-09-27 15:14:12.479 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:14:12.480 - INFO: Train epoch 411:   Loss: 9513.0651 | r_Loss: 1186.7487 | g_Loss: 3449.0651 | l_Loss: 130.2562 | 
                                                                                 411		9513.0651		-4.5000
25-09-27 15:14:24.011 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:14:24.014 - INFO: Train epoch 412:   Loss: 9051.1365 | r_Loss: 1101.2510 | g_Loss: 3416.5351 | l_Loss: 128.3465 | 
                                                                                 412		9051.1365		-4.5000
25-09-27 15:14:35.425 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:14:35.427 - INFO: Train epoch 413:   Loss: 9269.3484 | r_Loss: 1169.7551 | g_Loss: 3295.8957 | l_Loss: 124.6774 | 
                                                                                 413		9269.3484		-4.5000
25-09-27 15:14:46.846 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:14:46.848 - INFO: Train epoch 414:   Loss: 12205.3439 | r_Loss: 1757.0616 | g_Loss: 3292.0648 | l_Loss: 127.9712 | 
                                                                                 414		12205.3439		-4.5000
25-09-27 15:14:58.335 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:14:58.336 - INFO: Train epoch 415:   Loss: 8873.4728 | r_Loss: 1069.8345 | g_Loss: 3399.2381 | l_Loss: 125.0624 | 
                                                                                 415		8873.4728		-4.5000
25-09-27 15:15:09.764 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:15:09.766 - INFO: Train epoch 416:   Loss: 8870.8112 | r_Loss: 1088.4596 | g_Loss: 3303.0154 | l_Loss: 125.4981 | 
                                                                                 416		8870.8112		-4.5000
25-09-27 15:15:21.367 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:15:21.368 - INFO: Train epoch 417:   Loss: 9459.9299 | r_Loss: 1230.2232 | g_Loss: 3187.7443 | l_Loss: 121.0696 | 
                                                                                 417		9459.9299		-4.5000
25-09-27 15:15:32.762 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:15:32.764 - INFO: Train epoch 418:   Loss: 8445.4779 | r_Loss: 1046.8498 | g_Loss: 3092.5978 | l_Loss: 118.6313 | 
                                                                                 418		8445.4779		-4.5000
25-09-27 15:15:44.161 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:15:44.162 - INFO: Train epoch 419:   Loss: 9150.5227 | r_Loss: 1182.6091 | g_Loss: 3116.3597 | l_Loss: 121.1177 | 
                                                                                 419		9150.5227		-4.5000
25-09-27 15:15:55.616 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:15:55.618 - INFO: Train epoch 420:   Loss: 9390.6929 | r_Loss: 1241.5668 | g_Loss: 3064.4323 | l_Loss: 118.4268 | 
                                                                                 420		9390.6929		-4.5000
25-09-27 15:16:06.991 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:16:06.993 - INFO: Train epoch 421:   Loss: 9056.4418 | r_Loss: 1179.1323 | g_Loss: 3043.5108 | l_Loss: 117.2693 | 
                                                                                 421		9056.4418		-4.5000
25-09-27 15:16:18.465 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:16:18.467 - INFO: Train epoch 422:   Loss: 10023.2177 | r_Loss: 1372.9937 | g_Loss: 3039.7613 | l_Loss: 118.4878 | 
                                                                                 422		10023.2177		-4.5000
25-09-27 15:16:29.892 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:16:29.894 - INFO: Train epoch 423:   Loss: 8102.4132 | r_Loss: 999.5794 | g_Loss: 2992.5716 | l_Loss: 111.9443 | 
                                                                                 423		8102.4132		-4.5000
25-09-27 15:16:41.392 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:16:41.393 - INFO: Train epoch 424:   Loss: 8241.3662 | r_Loss: 1035.9517 | g_Loss: 2947.7284 | l_Loss: 113.8792 | 
                                                                                 424		8241.3662		-4.5000
25-09-27 15:16:52.897 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:16:52.899 - INFO: Train epoch 425:   Loss: 8068.4999 | r_Loss: 1020.9469 | g_Loss: 2852.1831 | l_Loss: 111.5822 | 
                                                                                 425		8068.4999		-4.5000
25-09-27 15:17:04.429 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:17:04.430 - INFO: Train epoch 426:   Loss: 8674.7448 | r_Loss: 1146.4141 | g_Loss: 2831.9544 | l_Loss: 110.7198 | 
                                                                                 426		8674.7448		-4.5000
25-09-27 15:17:16.495 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:17:16.497 - INFO: Train epoch 427:   Loss: 9868.6498 | r_Loss: 1374.6215 | g_Loss: 2880.9011 | l_Loss: 114.6413 | 
                                                                                 427		9868.6498		-4.5000
25-09-27 15:17:27.747 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:17:27.749 - INFO: Train epoch 428:   Loss: 8218.3877 | r_Loss: 1040.0080 | g_Loss: 2906.3743 | l_Loss: 111.9732 | 
                                                                                 428		8218.3877		-4.5000
25-09-27 15:17:39.263 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:17:39.265 - INFO: Train epoch 429:   Loss: 7993.3275 | r_Loss: 1014.6044 | g_Loss: 2811.9454 | l_Loss: 108.3602 | 
                                                                                 429		7993.3275		-4.5000
25-09-27 15:17:50.723 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:17:50.725 - INFO: Train epoch 430:   Loss: 7669.1987 | r_Loss: 970.2588 | g_Loss: 2711.7365 | l_Loss: 106.1680 | 
                                                                                 430		7669.1987		-4.5000
25-09-27 15:18:02.155 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:18:02.156 - INFO: Train epoch 431:   Loss: 11929.6008 | r_Loss: 1822.8855 | g_Loss: 2707.3892 | l_Loss: 107.7838 | 
                                                                                 431		11929.6008		-4.5000
25-09-27 15:18:13.827 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:18:13.828 - INFO: Train epoch 432:   Loss: 8868.6182 | r_Loss: 1166.3111 | g_Loss: 2922.9871 | l_Loss: 114.0759 | 
                                                                                 432		8868.6182		-4.5000
25-09-27 15:18:25.371 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:18:25.372 - INFO: Train epoch 433:   Loss: 7573.0378 | r_Loss: 926.5489 | g_Loss: 2835.8775 | l_Loss: 104.4156 | 
                                                                                 433		7573.0378		-4.5000
25-09-27 15:18:36.632 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:18:36.634 - INFO: Train epoch 434:   Loss: 7873.1915 | r_Loss: 982.7418 | g_Loss: 2852.1035 | l_Loss: 107.3791 | 
                                                                                 434		7873.1915		-4.5000
25-09-27 15:18:47.980 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:18:47.982 - INFO: Train epoch 435:   Loss: 7728.4884 | r_Loss: 977.4958 | g_Loss: 2735.3324 | l_Loss: 105.6770 | 
                                                                                 435		7728.4884		-4.5000
25-09-27 15:18:59.507 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:18:59.508 - INFO: Train epoch 436:   Loss: 7809.4346 | r_Loss: 997.1673 | g_Loss: 2719.0067 | l_Loss: 104.5914 | 
                                                                                 436		7809.4346		-4.5000
25-09-27 15:19:10.950 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:19:10.951 - INFO: Train epoch 437:   Loss: 7544.0545 | r_Loss: 967.4501 | g_Loss: 2605.7031 | l_Loss: 101.1013 | 
                                                                                 437		7544.0545		-4.5000
25-09-27 15:19:22.403 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:19:22.404 - INFO: Train epoch 438:   Loss: 8679.6496 | r_Loss: 1222.0505 | g_Loss: 2472.9133 | l_Loss: 96.4839 | 
                                                                                 438		8679.6496		-4.5000
25-09-27 15:19:33.752 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:19:33.754 - INFO: Train epoch 439:   Loss: 7862.4124 | r_Loss: 1033.5874 | g_Loss: 2592.2824 | l_Loss: 102.1928 | 
                                                                                 439		7862.4124		-4.5000
25-09-27 15:19:45.247 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:19:45.249 - INFO: Train epoch 440:   Loss: 8203.5326 | r_Loss: 1100.3197 | g_Loss: 2601.5602 | l_Loss: 100.3738 | 
                                                                                 440		8203.5326		-4.5000
25-09-27 15:19:56.551 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:19:56.553 - INFO: Train epoch 441:   Loss: 8305.4834 | r_Loss: 1109.0956 | g_Loss: 2658.3133 | l_Loss: 101.6922 | 
                                                                                 441		8305.4834		-4.5000
25-09-27 15:20:07.950 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:20:07.952 - INFO: Train epoch 442:   Loss: 7365.7889 | r_Loss: 936.8025 | g_Loss: 2582.9617 | l_Loss: 98.8146 | 
                                                                                 442		7365.7889		-4.5000
25-09-27 15:20:19.523 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:20:19.525 - INFO: Train epoch 443:   Loss: 7408.7869 | r_Loss: 960.6787 | g_Loss: 2508.2420 | l_Loss: 97.1514 | 
                                                                                 443		7408.7869		-4.5000
25-09-27 15:20:30.865 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:20:30.867 - INFO: Train epoch 444:   Loss: 7408.0137 | r_Loss: 969.6869 | g_Loss: 2464.0057 | l_Loss: 95.5734 | 
                                                                                 444		7408.0137		-4.5000
25-09-27 15:20:42.352 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:20:42.355 - INFO: Train epoch 445:   Loss: 7707.2634 | r_Loss: 1039.3472 | g_Loss: 2415.4502 | l_Loss: 95.0771 | 
                                                                                 445		7707.2634		-4.5000
25-09-27 15:20:53.711 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:20:53.713 - INFO: Train epoch 446:   Loss: 12118.4433 | r_Loss: 1887.3427 | g_Loss: 2576.0287 | l_Loss: 105.7013 | 
                                                                                 446		12118.4433		-4.5000
25-09-27 15:21:05.127 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:21:05.129 - INFO: Train epoch 447:   Loss: 7621.9805 | r_Loss: 946.3196 | g_Loss: 2787.4432 | l_Loss: 102.9392 | 
                                                                                 447		7621.9805		-4.5000
25-09-27 15:21:16.497 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:21:16.498 - INFO: Train epoch 448:   Loss: 7329.4631 | r_Loss: 916.3066 | g_Loss: 2649.1892 | l_Loss: 98.7410 | 
                                                                                 448		7329.4631		-4.5000
25-09-27 15:21:27.878 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:21:27.880 - INFO: Train epoch 449:   Loss: 7115.8144 | r_Loss: 896.1711 | g_Loss: 2539.5832 | l_Loss: 95.3756 | 
                                                                                 449		7115.8144		-4.5000
25-09-27 15:23:31.460 - INFO: TEST:   PSNR_S: 35.0196 | PSNR_C: 26.5783 | 
25-09-27 15:23:31.461 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:23:31.462 - INFO: Train epoch 450:   Loss: 7300.1796 | r_Loss: 932.7561 | g_Loss: 2540.1370 | l_Loss: 96.2620 | 
                                                                                 450		7300.1796		-4.5000
25-09-27 15:23:43.152 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:23:43.153 - INFO: Train epoch 451:   Loss: 6932.1122 | r_Loss: 886.3779 | g_Loss: 2408.8192 | l_Loss: 91.4035 | 
                                                                                 451		6932.1122		-4.5000
25-09-27 15:23:54.555 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:23:54.557 - INFO: Train epoch 452:   Loss: 7084.8001 | r_Loss: 920.4603 | g_Loss: 2390.0722 | l_Loss: 92.4264 | 
                                                                                 452		7084.8001		-4.5000
25-09-27 15:24:05.880 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:24:05.882 - INFO: Train epoch 453:   Loss: 7035.3370 | r_Loss: 916.0364 | g_Loss: 2363.8804 | l_Loss: 91.2747 | 
                                                                                 453		7035.3370		-4.5000
25-09-27 15:24:17.102 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:24:17.103 - INFO: Train epoch 454:   Loss: 7952.4309 | r_Loss: 1107.6175 | g_Loss: 2323.9773 | l_Loss: 90.3662 | 
                                                                                 454		7952.4309		-4.5000
25-09-27 15:24:30.114 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:24:30.116 - INFO: Train epoch 455:   Loss: 6864.1912 | r_Loss: 889.4018 | g_Loss: 2328.7149 | l_Loss: 88.4675 | 
                                                                                 455		6864.1912		-4.5000
25-09-27 15:24:41.415 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:24:41.417 - INFO: Train epoch 456:   Loss: 7109.3279 | r_Loss: 941.9161 | g_Loss: 2310.7719 | l_Loss: 88.9754 | 
                                                                                 456		7109.3279		-4.5000
25-09-27 15:24:58.666 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:24:58.668 - INFO: Train epoch 457:   Loss: 12453.4459 | r_Loss: 1948.9774 | g_Loss: 2603.4878 | l_Loss: 105.0709 | 
                                                                                 457		12453.4459		-4.5000
25-09-27 15:25:09.963 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:25:09.965 - INFO: Train epoch 458:   Loss: 7223.0192 | r_Loss: 900.3230 | g_Loss: 2625.9747 | l_Loss: 95.4297 | 
                                                                                 458		7223.0192		-4.5000
25-09-27 15:25:21.264 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:25:21.266 - INFO: Train epoch 459:   Loss: 7041.7664 | r_Loss: 885.0815 | g_Loss: 2523.0981 | l_Loss: 93.2608 | 
                                                                                 459		7041.7664		-4.5000
25-09-27 15:25:32.460 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:25:32.462 - INFO: Train epoch 460:   Loss: 6766.7952 | r_Loss: 858.4831 | g_Loss: 2385.7419 | l_Loss: 88.6379 | 
                                                                                 460		6766.7952		-4.5000
25-09-27 15:25:53.139 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:25:53.140 - INFO: Train epoch 461:   Loss: 6879.5272 | r_Loss: 886.7020 | g_Loss: 2357.3191 | l_Loss: 88.6982 | 
                                                                                 461		6879.5272		-4.5000
25-09-27 15:26:04.276 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:26:04.278 - INFO: Train epoch 462:   Loss: 6923.8679 | r_Loss: 899.4143 | g_Loss: 2337.9436 | l_Loss: 88.8527 | 
                                                                                 462		6923.8679		-4.5000
25-09-27 15:26:21.263 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:26:21.265 - INFO: Train epoch 463:   Loss: 6789.9818 | r_Loss: 890.0305 | g_Loss: 2253.9985 | l_Loss: 85.8309 | 
                                                                                 463		6789.9818		-4.5000
25-09-27 15:26:32.413 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:26:32.414 - INFO: Train epoch 464:   Loss: 6792.7600 | r_Loss: 890.9036 | g_Loss: 2252.6250 | l_Loss: 85.6171 | 
                                                                                 464		6792.7600		-4.5000
25-09-27 15:26:43.693 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:26:43.694 - INFO: Train epoch 465:   Loss: 9154.6498 | r_Loss: 1358.9136 | g_Loss: 2272.1473 | l_Loss: 87.9343 | 
                                                                                 465		9154.6498		-4.5000
25-09-27 15:26:54.970 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:26:54.971 - INFO: Train epoch 466:   Loss: 6877.6368 | r_Loss: 885.6158 | g_Loss: 2362.1925 | l_Loss: 87.3654 | 
                                                                                 466		6877.6368		-4.5000
25-09-27 15:27:06.267 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:27:06.269 - INFO: Train epoch 467:   Loss: 6811.6982 | r_Loss: 888.0198 | g_Loss: 2285.1442 | l_Loss: 86.4551 | 
                                                                                 467		6811.6982		-4.5000
25-09-27 15:27:18.579 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:27:18.580 - INFO: Train epoch 468:   Loss: 6593.8867 | r_Loss: 858.4324 | g_Loss: 2216.5774 | l_Loss: 85.1475 | 
                                                                                 468		6593.8867		-4.5000
25-09-27 15:27:29.919 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:27:29.921 - INFO: Train epoch 469:   Loss: 7211.6175 | r_Loss: 976.6705 | g_Loss: 2242.7311 | l_Loss: 85.5338 | 
                                                                                 469		7211.6175		-4.5000
25-09-27 15:27:43.648 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:27:43.649 - INFO: Train epoch 470:   Loss: 7363.7218 | r_Loss: 1020.7015 | g_Loss: 2177.3337 | l_Loss: 82.8805 | 
                                                                                 470		7363.7218		-4.5000
25-09-27 15:27:55.005 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:27:55.007 - INFO: Train epoch 471:   Loss: 6612.9960 | r_Loss: 863.3851 | g_Loss: 2214.0166 | l_Loss: 82.0538 | 
                                                                                 471		6612.9960		-4.5000
25-09-27 15:28:12.431 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:28:12.433 - INFO: Train epoch 472:   Loss: 6308.3262 | r_Loss: 821.1273 | g_Loss: 2124.2641 | l_Loss: 78.4259 | 
                                                                                 472		6308.3262		-4.5000
25-09-27 15:28:23.680 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:28:23.681 - INFO: Train epoch 473:   Loss: 7158.9797 | r_Loss: 983.0095 | g_Loss: 2161.8851 | l_Loss: 82.0471 | 
                                                                                 473		7158.9797		-4.5000
25-09-27 15:28:34.767 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:28:34.769 - INFO: Train epoch 474:   Loss: 7224.1320 | r_Loss: 994.9947 | g_Loss: 2166.9734 | l_Loss: 82.1851 | 
                                                                                 474		7224.1320		-4.5000
25-09-27 15:28:49.065 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:28:49.067 - INFO: Train epoch 475:   Loss: 6609.8288 | r_Loss: 866.4466 | g_Loss: 2195.5717 | l_Loss: 82.0243 | 
                                                                                 475		6609.8288		-4.5000
25-09-27 15:29:00.275 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:29:00.276 - INFO: Train epoch 476:   Loss: 6508.2675 | r_Loss: 851.7063 | g_Loss: 2168.5780 | l_Loss: 81.1579 | 
                                                                                 476		6508.2675		-4.5000
25-09-27 15:29:21.202 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:29:21.203 - INFO: Train epoch 477:   Loss: 7688.2832 | r_Loss: 1093.9227 | g_Loss: 2137.9325 | l_Loss: 80.7373 | 
                                                                                 477		7688.2832		-4.5000
25-09-27 15:29:32.381 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:29:32.383 - INFO: Train epoch 478:   Loss: 7682.5717 | r_Loss: 1079.7131 | g_Loss: 2203.3093 | l_Loss: 80.6966 | 
                                                                                 478		7682.5717		-4.5000
25-09-27 15:29:43.624 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:29:43.626 - INFO: Train epoch 479:   Loss: 6385.2776 | r_Loss: 825.5632 | g_Loss: 2176.9846 | l_Loss: 80.4772 | 
                                                                                 479		6385.2776		-4.5000
25-09-27 15:29:57.331 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:29:57.333 - INFO: Train epoch 480:   Loss: 6335.3984 | r_Loss: 821.6799 | g_Loss: 2148.5192 | l_Loss: 78.4798 | 
                                                                                 480		6335.3984		-4.5000
25-09-27 15:30:08.781 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:30:08.783 - INFO: Train epoch 481:   Loss: 6460.1466 | r_Loss: 847.2355 | g_Loss: 2144.2606 | l_Loss: 79.7086 | 
                                                                                 481		6460.1466		-4.5000
25-09-27 15:30:20.119 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:30:20.122 - INFO: Train epoch 482:   Loss: 6207.6679 | r_Loss: 819.4786 | g_Loss: 2033.6789 | l_Loss: 76.5962 | 
                                                                                 482		6207.6679		-4.5000
25-09-27 15:30:40.487 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:30:40.488 - INFO: Train epoch 483:   Loss: 6484.8684 | r_Loss: 870.8786 | g_Loss: 2054.0462 | l_Loss: 76.4292 | 
                                                                                 483		6484.8684		-4.5000
25-09-27 15:30:51.773 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:30:51.774 - INFO: Train epoch 484:   Loss: 8619.9377 | r_Loss: 1283.2850 | g_Loss: 2123.0042 | l_Loss: 80.5081 | 
                                                                                 484		8619.9377		-4.5000
25-09-27 15:31:15.397 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:31:15.399 - INFO: Train epoch 485:   Loss: 6490.5652 | r_Loss: 844.1260 | g_Loss: 2189.6901 | l_Loss: 80.2449 | 
                                                                                 485		6490.5652		-4.5000
25-09-27 15:31:26.792 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:31:26.794 - INFO: Train epoch 486:   Loss: 6240.0850 | r_Loss: 807.1528 | g_Loss: 2127.4446 | l_Loss: 76.8761 | 
                                                                                 486		6240.0850		-4.5000
25-09-27 15:31:37.875 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:31:37.876 - INFO: Train epoch 487:   Loss: 6226.3972 | r_Loss: 813.8839 | g_Loss: 2080.6108 | l_Loss: 76.3671 | 
                                                                                 487		6226.3972		-4.5000
25-09-27 15:31:57.018 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:31:57.019 - INFO: Train epoch 488:   Loss: 6174.2217 | r_Loss: 812.2693 | g_Loss: 2037.2044 | l_Loss: 75.6712 | 
                                                                                 488		6174.2217		-4.5000
25-09-27 15:32:08.175 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:32:08.176 - INFO: Train epoch 489:   Loss: 6731.7896 | r_Loss: 925.0226 | g_Loss: 2031.5475 | l_Loss: 75.1291 | 
                                                                                 489		6731.7896		-4.5000
25-09-27 15:32:19.474 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:32:19.476 - INFO: Train epoch 490:   Loss: 6564.4918 | r_Loss: 883.2648 | g_Loss: 2072.3598 | l_Loss: 75.8076 | 
                                                                                 490		6564.4918		-4.5000
25-09-27 15:32:39.001 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:32:39.002 - INFO: Train epoch 491:   Loss: 6063.0426 | r_Loss: 801.5283 | g_Loss: 1982.4004 | l_Loss: 73.0009 | 
                                                                                 491		6063.0426		-4.5000
25-09-27 15:32:50.231 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:32:50.232 - INFO: Train epoch 492:   Loss: 6137.5780 | r_Loss: 823.0303 | g_Loss: 1950.2542 | l_Loss: 72.1724 | 
                                                                                 492		6137.5780		-4.5000
25-09-27 15:33:01.589 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:33:01.590 - INFO: Train epoch 493:   Loss: 9179.1097 | r_Loss: 1385.1721 | g_Loss: 2173.1894 | l_Loss: 80.0598 | 
                                                                                 493		9179.1097		-4.5000
25-09-27 15:33:19.319 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:33:19.320 - INFO: Train epoch 494:   Loss: 6112.7594 | r_Loss: 782.9137 | g_Loss: 2122.2371 | l_Loss: 75.9539 | 
                                                                                 494		6112.7594		-4.5000
25-09-27 15:33:30.653 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:33:30.655 - INFO: Train epoch 495:   Loss: 6137.0422 | r_Loss: 791.8341 | g_Loss: 2103.8459 | l_Loss: 74.0259 | 
                                                                                 495		6137.0422		-4.5000
25-09-27 15:33:41.866 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:33:41.868 - INFO: Train epoch 496:   Loss: 6141.1321 | r_Loss: 802.8984 | g_Loss: 2052.3370 | l_Loss: 74.3034 | 
                                                                                 496		6141.1321		-4.5000
25-09-27 15:33:53.057 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:33:53.058 - INFO: Train epoch 497:   Loss: 5908.2900 | r_Loss: 773.2561 | g_Loss: 1971.5171 | l_Loss: 70.4924 | 
                                                                                 497		5908.2900		-4.5000
25-09-27 15:34:15.421 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:34:15.423 - INFO: Train epoch 498:   Loss: 6058.9402 | r_Loss: 807.0223 | g_Loss: 1953.4167 | l_Loss: 70.4118 | 
                                                                                 498		6058.9402		-4.5000
25-09-27 15:34:26.617 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:34:26.618 - INFO: Train epoch 499:   Loss: 5979.9657 | r_Loss: 795.4407 | g_Loss: 1932.8652 | l_Loss: 69.8968 | 
                                                                                 499		5979.9657		-4.5000
25-09-27 15:38:51.121 - INFO: TEST:   PSNR_S: 32.8317 | PSNR_C: 28.0925 | 
25-09-27 15:38:51.123 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:38:51.123 - INFO: Train epoch 500:   Loss: 6026.0704 | r_Loss: 816.9166 | g_Loss: 1873.8197 | l_Loss: 67.6678 | 
                                                                                 500		6026.0704		-4.5000
25-09-27 15:39:04.675 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:39:04.676 - INFO: Train epoch 501:   Loss: 7138.0691 | r_Loss: 1013.3249 | g_Loss: 2000.0886 | l_Loss: 71.3558 | 
                                                                                 501		7138.0691		-4.5000
25-09-27 15:39:18.928 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:39:18.930 - INFO: Train epoch 502:   Loss: 5938.9791 | r_Loss: 779.1685 | g_Loss: 1972.7862 | l_Loss: 70.3502 | 
                                                                                 502		5938.9791		-4.5000
25-09-27 15:39:30.210 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:39:30.212 - INFO: Train epoch 503:   Loss: 5755.7415 | r_Loss: 758.0143 | g_Loss: 1898.0598 | l_Loss: 67.6105 | 
                                                                                 503		5755.7415		-4.5000
25-09-27 15:39:41.596 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:39:41.598 - INFO: Train epoch 504:   Loss: 5994.2749 | r_Loss: 813.5032 | g_Loss: 1859.7868 | l_Loss: 66.9721 | 
                                                                                 504		5994.2749		-4.5000
25-09-27 15:39:52.986 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:39:52.988 - INFO: Train epoch 505:   Loss: 6254.5603 | r_Loss: 859.8547 | g_Loss: 1887.8317 | l_Loss: 67.4549 | 
                                                                                 505		6254.5603		-4.5000
25-09-27 15:40:05.248 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:40:05.249 - INFO: Train epoch 506:   Loss: 5853.3648 | r_Loss: 776.5882 | g_Loss: 1903.1863 | l_Loss: 67.2375 | 
                                                                                 506		5853.3648		-4.5000
25-09-27 15:40:18.191 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:40:18.192 - INFO: Train epoch 507:   Loss: 5721.4476 | r_Loss: 762.8394 | g_Loss: 1841.3780 | l_Loss: 65.8726 | 
                                                                                 507		5721.4476		-4.5000
25-09-27 15:40:35.266 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:40:35.268 - INFO: Train epoch 508:   Loss: 6809.2876 | r_Loss: 973.3124 | g_Loss: 1874.6796 | l_Loss: 68.0462 | 
                                                                                 508		6809.2876		-4.5000
25-09-27 15:40:46.657 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:40:46.659 - INFO: Train epoch 509:   Loss: 7251.9524 | r_Loss: 1023.2489 | g_Loss: 2063.6694 | l_Loss: 72.0387 | 
                                                                                 509		7251.9524		-4.5000
25-09-27 15:40:59.685 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:40:59.687 - INFO: Train epoch 510:   Loss: 5901.7925 | r_Loss: 767.4981 | g_Loss: 1994.9244 | l_Loss: 69.3775 | 
                                                                                 510		5901.7925		-4.5000
25-09-27 15:41:17.567 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:41:17.569 - INFO: Train epoch 511:   Loss: 5807.0164 | r_Loss: 759.2467 | g_Loss: 1942.8570 | l_Loss: 67.9260 | 
                                                                                 511		5807.0164		-4.5000
25-09-27 15:41:28.823 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:41:28.824 - INFO: Train epoch 512:   Loss: 5695.3651 | r_Loss: 747.9791 | g_Loss: 1889.8265 | l_Loss: 65.6432 | 
                                                                                 512		5695.3651		-4.5000
25-09-27 15:41:40.860 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:41:40.862 - INFO: Train epoch 513:   Loss: 5623.1014 | r_Loss: 740.8971 | g_Loss: 1853.3322 | l_Loss: 65.2835 | 
                                                                                 513		5623.1014		-4.5000
25-09-27 15:41:52.081 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:41:52.083 - INFO: Train epoch 514:   Loss: 10080.5003 | r_Loss: 1565.3316 | g_Loss: 2176.4584 | l_Loss: 77.3843 | 
                                                                                 514		10080.5003		-4.5000
25-09-27 15:42:03.443 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:42:03.444 - INFO: Train epoch 515:   Loss: 6078.3787 | r_Loss: 759.0528 | g_Loss: 2209.2666 | l_Loss: 73.8480 | 
                                                                                 515		6078.3787		-4.5000
25-09-27 15:42:31.569 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:42:31.571 - INFO: Train epoch 516:   Loss: 5682.0948 | r_Loss: 716.9852 | g_Loss: 2029.4505 | l_Loss: 67.7184 | 
                                                                                 516		5682.0948		-4.5000
25-09-27 15:42:51.056 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:42:51.057 - INFO: Train epoch 517:   Loss: 5768.0090 | r_Loss: 739.2072 | g_Loss: 2003.8369 | l_Loss: 68.1361 | 
                                                                                 517		5768.0090		-4.5000
25-09-27 15:43:02.184 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:43:02.186 - INFO: Train epoch 518:   Loss: 5509.0781 | r_Loss: 713.2565 | g_Loss: 1878.9471 | l_Loss: 63.8486 | 
                                                                                 518		5509.0781		-4.5000
25-09-27 15:43:17.696 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:43:17.698 - INFO: Train epoch 519:   Loss: 5615.4322 | r_Loss: 732.8890 | g_Loss: 1887.0742 | l_Loss: 63.9131 | 
                                                                                 519		5615.4322		-4.5000
25-09-27 15:43:34.255 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:43:34.257 - INFO: Train epoch 520:   Loss: 5620.7934 | r_Loss: 740.6699 | g_Loss: 1854.7496 | l_Loss: 62.6943 | 
                                                                                 520		5620.7934		-4.5000
25-09-27 15:43:45.650 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:43:45.653 - INFO: Train epoch 521:   Loss: 5586.5945 | r_Loss: 738.5932 | g_Loss: 1831.5233 | l_Loss: 62.1054 | 
                                                                                 521		5586.5945		-4.5000
25-09-27 15:43:56.974 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:43:56.976 - INFO: Train epoch 522:   Loss: 5484.8955 | r_Loss: 726.2417 | g_Loss: 1792.5417 | l_Loss: 61.1452 | 
                                                                                 522		5484.8955		-4.5000
25-09-27 15:44:08.244 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:44:08.246 - INFO: Train epoch 523:   Loss: 5476.0302 | r_Loss: 732.4406 | g_Loss: 1754.0887 | l_Loss: 59.7387 | 
                                                                                 523		5476.0302		-4.5000
25-09-27 15:44:19.502 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:44:19.503 - INFO: Train epoch 524:   Loss: 6646.7629 | r_Loss: 941.4341 | g_Loss: 1875.2769 | l_Loss: 64.3155 | 
                                                                                 524		6646.7629		-4.5000
25-09-27 15:44:34.769 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:44:34.771 - INFO: Train epoch 525:   Loss: 5552.6613 | r_Loss: 727.3383 | g_Loss: 1853.5325 | l_Loss: 62.4373 | 
                                                                                 525		5552.6613		-4.5000
25-09-27 15:44:45.947 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:44:45.949 - INFO: Train epoch 526:   Loss: 5474.0738 | r_Loss: 719.5037 | g_Loss: 1814.9238 | l_Loss: 61.6315 | 
                                                                                 526		5474.0738		-4.5000
25-09-27 15:45:00.066 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:45:00.067 - INFO: Train epoch 527:   Loss: 5418.9603 | r_Loss: 721.0753 | g_Loss: 1753.9536 | l_Loss: 59.6303 | 
                                                                                 527		5418.9603		-4.5000
25-09-27 15:45:24.957 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:45:24.959 - INFO: Train epoch 528:   Loss: 6992.5581 | r_Loss: 1021.3829 | g_Loss: 1823.4465 | l_Loss: 62.1970 | 
                                                                                 528		6992.5581		-4.5000
25-09-27 15:45:36.299 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:45:36.301 - INFO: Train epoch 529:   Loss: 5446.9840 | r_Loss: 702.2771 | g_Loss: 1873.0811 | l_Loss: 62.5174 | 
                                                                                 529		5446.9840		-4.5000
25-09-27 15:45:55.195 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:45:55.197 - INFO: Train epoch 530:   Loss: 5204.6085 | r_Loss: 676.2251 | g_Loss: 1764.2537 | l_Loss: 59.2295 | 
                                                                                 530		5204.6085		-4.5000
25-09-27 15:46:06.476 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:46:06.478 - INFO: Train epoch 531:   Loss: 5425.4812 | r_Loss: 714.3013 | g_Loss: 1793.3930 | l_Loss: 60.5817 | 
                                                                                 531		5425.4812		-4.5000
25-09-27 15:46:20.227 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:46:20.229 - INFO: Train epoch 532:   Loss: 5359.7250 | r_Loss: 708.0503 | g_Loss: 1760.3292 | l_Loss: 59.1441 | 
                                                                                 532		5359.7250		-4.5000
25-09-27 15:46:31.486 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:46:31.487 - INFO: Train epoch 533:   Loss: 5388.8055 | r_Loss: 717.3281 | g_Loss: 1742.7940 | l_Loss: 59.3711 | 
                                                                                 533		5388.8055		-4.5000
25-09-27 15:46:43.450 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:46:43.452 - INFO: Train epoch 534:   Loss: 5313.3718 | r_Loss: 711.7855 | g_Loss: 1696.9218 | l_Loss: 57.5225 | 
                                                                                 534		5313.3718		-4.5000
25-09-27 15:46:57.304 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:46:57.305 - INFO: Train epoch 535:   Loss: 7685.9304 | r_Loss: 1148.4402 | g_Loss: 1882.2648 | l_Loss: 61.4645 | 
                                                                                 535		7685.9304		-4.5000
25-09-27 15:47:08.420 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:47:08.422 - INFO: Train epoch 536:   Loss: 5412.3075 | r_Loss: 693.8805 | g_Loss: 1881.2078 | l_Loss: 61.6972 | 
                                                                                 536		5412.3075		-4.5000
25-09-27 15:47:30.324 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:47:30.326 - INFO: Train epoch 537:   Loss: 5366.9474 | r_Loss: 695.3760 | g_Loss: 1829.5853 | l_Loss: 60.4820 | 
                                                                                 537		5366.9474		-4.5000
25-09-27 15:47:41.583 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:47:41.584 - INFO: Train epoch 538:   Loss: 5341.2226 | r_Loss: 700.4262 | g_Loss: 1780.1255 | l_Loss: 58.9661 | 
                                                                                 538		5341.2226		-4.5000
25-09-27 15:47:53.273 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:47:53.274 - INFO: Train epoch 539:   Loss: 5292.1158 | r_Loss: 697.8347 | g_Loss: 1745.2357 | l_Loss: 57.7067 | 
                                                                                 539		5292.1158		-4.5000
25-09-27 15:48:12.352 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:48:12.353 - INFO: Train epoch 540:   Loss: 5165.3810 | r_Loss: 680.5470 | g_Loss: 1705.9339 | l_Loss: 56.7121 | 
                                                                                 540		5165.3810		-4.5000
25-09-27 15:48:23.532 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:48:23.534 - INFO: Train epoch 541:   Loss: 5252.3522 | r_Loss: 699.8283 | g_Loss: 1696.6382 | l_Loss: 56.5722 | 
                                                                                 541		5252.3522		-4.5000
25-09-27 15:48:40.828 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:48:40.830 - INFO: Train epoch 542:   Loss: 5782.6378 | r_Loss: 810.0507 | g_Loss: 1677.2863 | l_Loss: 55.0981 | 
                                                                                 542		5782.6378		-4.5000
25-09-27 15:48:52.094 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:48:52.095 - INFO: Train epoch 543:   Loss: 5265.9681 | r_Loss: 695.6758 | g_Loss: 1731.1313 | l_Loss: 56.4577 | 
                                                                                 543		5265.9681		-4.5000
25-09-27 15:49:13.369 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:49:13.371 - INFO: Train epoch 544:   Loss: 5218.7882 | r_Loss: 690.2746 | g_Loss: 1710.4490 | l_Loss: 56.9663 | 
                                                                                 544		5218.7882		-4.5000
25-09-27 15:49:24.768 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:49:24.769 - INFO: Train epoch 545:   Loss: 5154.7582 | r_Loss: 694.2968 | g_Loss: 1630.1316 | l_Loss: 53.1423 | 
                                                                                 545		5154.7582		-4.5000
25-09-27 15:49:38.552 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:49:38.553 - INFO: Train epoch 546:   Loss: 5132.7332 | r_Loss: 682.7518 | g_Loss: 1664.3031 | l_Loss: 54.6710 | 
                                                                                 546		5132.7332		-4.5000
25-09-27 15:49:49.665 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:49:49.667 - INFO: Train epoch 547:   Loss: 5332.2544 | r_Loss: 721.9697 | g_Loss: 1667.7071 | l_Loss: 54.6989 | 
                                                                                 547		5332.2544		-4.5000
25-09-27 15:50:00.899 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:50:00.901 - INFO: Train epoch 548:   Loss: 5341.0530 | r_Loss: 727.4362 | g_Loss: 1650.1093 | l_Loss: 53.7627 | 
                                                                                 548		5341.0530		-4.5000
25-09-27 15:50:12.038 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:50:12.040 - INFO: Train epoch 549:   Loss: 5099.3993 | r_Loss: 677.1224 | g_Loss: 1659.5396 | l_Loss: 54.2477 | 
                                                                                 549		5099.3993		-4.5000
25-09-27 15:58:08.513 - INFO: TEST:   PSNR_S: 36.8635 | PSNR_C: 29.1612 | 
25-09-27 15:58:08.515 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:58:08.516 - INFO: Train epoch 550:   Loss: 5103.2862 | r_Loss: 682.5798 | g_Loss: 1636.5822 | l_Loss: 53.8052 | 
                                                                                 550		5103.2862		-4.5000
25-09-27 15:58:27.987 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:58:27.989 - INFO: Train epoch 551:   Loss: 5062.7010 | r_Loss: 678.1603 | g_Loss: 1619.2404 | l_Loss: 52.6592 | 
                                                                                 551		5062.7010		-4.5000
25-09-27 15:58:39.176 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:58:39.178 - INFO: Train epoch 552:   Loss: 5670.2702 | r_Loss: 780.6715 | g_Loss: 1712.1108 | l_Loss: 54.8018 | 
                                                                                 552		5670.2702		-4.5000
25-09-27 15:58:50.410 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:58:50.411 - INFO: Train epoch 553:   Loss: 4997.7352 | r_Loss: 653.8555 | g_Loss: 1674.2978 | l_Loss: 54.1599 | 
                                                                                 553		4997.7352		-4.5000
25-09-27 15:59:07.307 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:59:07.309 - INFO: Train epoch 554:   Loss: 5135.6240 | r_Loss: 684.6118 | g_Loss: 1658.8175 | l_Loss: 53.7476 | 
                                                                                 554		5135.6240		-4.5000
25-09-27 15:59:18.960 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:59:18.961 - INFO: Train epoch 555:   Loss: 5484.1650 | r_Loss: 753.9502 | g_Loss: 1660.9836 | l_Loss: 53.4303 | 
                                                                                 555		5484.1650		-4.5000
25-09-27 15:59:30.191 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:59:30.192 - INFO: Train epoch 556:   Loss: 4917.7288 | r_Loss: 646.8764 | g_Loss: 1631.2100 | l_Loss: 52.1367 | 
                                                                                 556		4917.7288		-4.5000
25-09-27 15:59:43.358 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:59:43.359 - INFO: Train epoch 557:   Loss: 5009.9188 | r_Loss: 662.1624 | g_Loss: 1645.9671 | l_Loss: 53.1395 | 
                                                                                 557		5009.9188		-4.5000
25-09-27 15:59:54.631 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 15:59:54.632 - INFO: Train epoch 558:   Loss: 5535.9108 | r_Loss: 764.7672 | g_Loss: 1659.2903 | l_Loss: 52.7841 | 
                                                                                 558		5535.9108		-4.5000
25-09-27 16:00:12.324 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:00:12.326 - INFO: Train epoch 559:   Loss: 4985.0178 | r_Loss: 655.3250 | g_Loss: 1655.3069 | l_Loss: 53.0857 | 
                                                                                 559		4985.0178		-4.5000
25-09-27 16:00:24.392 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:00:24.393 - INFO: Train epoch 560:   Loss: 4819.6702 | r_Loss: 633.6299 | g_Loss: 1600.2011 | l_Loss: 51.3197 | 
                                                                                 560		4819.6702		-4.5000
25-09-27 16:00:35.501 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:00:35.502 - INFO: Train epoch 561:   Loss: 5597.6483 | r_Loss: 781.0672 | g_Loss: 1640.0090 | l_Loss: 52.3033 | 
                                                                                 561		5597.6483		-4.5000
25-09-27 16:00:46.751 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:00:46.752 - INFO: Train epoch 562:   Loss: 5161.9367 | r_Loss: 697.1157 | g_Loss: 1625.1443 | l_Loss: 51.2141 | 
                                                                                 562		5161.9367		-4.5000
25-09-27 16:00:58.253 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:00:58.255 - INFO: Train epoch 563:   Loss: 4949.3483 | r_Loss: 648.8660 | g_Loss: 1652.5694 | l_Loss: 52.4488 | 
                                                                                 563		4949.3483		-4.5000
25-09-27 16:01:09.563 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:01:09.565 - INFO: Train epoch 564:   Loss: 4717.6892 | r_Loss: 622.1554 | g_Loss: 1557.7675 | l_Loss: 49.1446 | 
                                                                                 564		4717.6892		-4.5000
25-09-27 16:01:27.704 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:01:27.706 - INFO: Train epoch 565:   Loss: 4838.4565 | r_Loss: 637.1255 | g_Loss: 1601.9384 | l_Loss: 50.8908 | 
                                                                                 565		4838.4565		-4.5000
25-09-27 16:01:42.469 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:01:42.470 - INFO: Train epoch 566:   Loss: 4839.8376 | r_Loss: 640.6635 | g_Loss: 1586.4902 | l_Loss: 50.0301 | 
                                                                                 566		4839.8376		-4.5000
25-09-27 16:01:53.700 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:01:53.701 - INFO: Train epoch 567:   Loss: 4621.7415 | r_Loss: 615.1915 | g_Loss: 1498.4835 | l_Loss: 47.3007 | 
                                                                                 567		4621.7415		-4.5000
25-09-27 16:02:08.141 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:02:08.142 - INFO: Train epoch 568:   Loss: 5388.7293 | r_Loss: 745.1505 | g_Loss: 1612.7866 | l_Loss: 50.1903 | 
                                                                                 568		5388.7293		-4.5000
25-09-27 16:02:19.437 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:02:19.438 - INFO: Train epoch 569:   Loss: 4683.9792 | r_Loss: 609.1655 | g_Loss: 1588.4753 | l_Loss: 49.6763 | 
                                                                                 569		4683.9792		-4.5000
25-09-27 16:02:32.128 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:02:32.129 - INFO: Train epoch 570:   Loss: 4686.5932 | r_Loss: 617.4953 | g_Loss: 1550.0594 | l_Loss: 49.0573 | 
                                                                                 570		4686.5932		-4.5000
25-09-27 16:02:43.460 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:02:43.462 - INFO: Train epoch 571:   Loss: 5285.3703 | r_Loss: 736.7936 | g_Loss: 1552.8377 | l_Loss: 48.5647 | 
                                                                                 571		5285.3703		-4.5000
25-09-27 16:02:58.985 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:02:58.986 - INFO: Train epoch 572:   Loss: 5265.4038 | r_Loss: 713.8645 | g_Loss: 1644.6658 | l_Loss: 51.4153 | 
                                                                                 572		5265.4038		-4.5000
25-09-27 16:03:10.200 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:03:10.201 - INFO: Train epoch 573:   Loss: 4724.6682 | r_Loss: 618.9398 | g_Loss: 1581.2052 | l_Loss: 48.7642 | 
                                                                                 573		4724.6682		-4.5000
25-09-27 16:03:26.648 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:03:26.649 - INFO: Train epoch 574:   Loss: 4559.6413 | r_Loss: 592.6551 | g_Loss: 1548.3890 | l_Loss: 47.9766 | 
                                                                                 574		4559.6413		-4.5000
25-09-27 16:03:37.923 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:03:37.924 - INFO: Train epoch 575:   Loss: 4671.7123 | r_Loss: 616.7193 | g_Loss: 1540.6010 | l_Loss: 47.5150 | 
                                                                                 575		4671.7123		-4.5000
25-09-27 16:03:49.665 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:03:49.667 - INFO: Train epoch 576:   Loss: 4621.7869 | r_Loss: 611.8712 | g_Loss: 1515.6811 | l_Loss: 46.7495 | 
                                                                                 576		4621.7869		-4.5000
25-09-27 16:04:09.489 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:04:09.491 - INFO: Train epoch 577:   Loss: 6279.8820 | r_Loss: 905.4003 | g_Loss: 1700.1624 | l_Loss: 52.7183 | 
                                                                                 577		6279.8820		-4.5000
25-09-27 16:04:20.745 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:04:20.746 - INFO: Train epoch 578:   Loss: 4708.0938 | r_Loss: 604.6011 | g_Loss: 1635.2786 | l_Loss: 49.8099 | 
                                                                                 578		4708.0938		-4.5000
25-09-27 16:04:32.098 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:04:32.100 - INFO: Train epoch 579:   Loss: 4724.4704 | r_Loss: 613.2196 | g_Loss: 1609.4242 | l_Loss: 48.9481 | 
                                                                                 579		4724.4704		-4.5000
25-09-27 16:04:43.296 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:04:43.297 - INFO: Train epoch 580:   Loss: 4678.3720 | r_Loss: 616.1011 | g_Loss: 1550.5430 | l_Loss: 47.3237 | 
                                                                                 580		4678.3720		-4.5000
25-09-27 16:04:56.670 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:04:56.672 - INFO: Train epoch 581:   Loss: 4618.2082 | r_Loss: 604.3869 | g_Loss: 1549.3804 | l_Loss: 46.8932 | 
                                                                                 581		4618.2082		-4.5000
25-09-27 16:05:14.839 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:05:14.841 - INFO: Train epoch 582:   Loss: 4487.2141 | r_Loss: 585.5539 | g_Loss: 1513.2018 | l_Loss: 46.2429 | 
                                                                                 582		4487.2141		-4.5000
25-09-27 16:05:26.176 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:05:26.178 - INFO: Train epoch 583:   Loss: 4505.7442 | r_Loss: 597.9397 | g_Loss: 1471.5650 | l_Loss: 44.4810 | 
                                                                                 583		4505.7442		-4.5000
25-09-27 16:05:40.123 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:05:40.125 - INFO: Train epoch 584:   Loss: 5256.2763 | r_Loss: 735.8018 | g_Loss: 1530.9786 | l_Loss: 46.2885 | 
                                                                                 584		5256.2763		-4.5000
25-09-27 16:05:51.464 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:05:51.466 - INFO: Train epoch 585:   Loss: 4717.2099 | r_Loss: 612.8218 | g_Loss: 1605.6649 | l_Loss: 47.4361 | 
                                                                                 585		4717.2099		-4.5000
25-09-27 16:06:02.809 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:06:02.811 - INFO: Train epoch 586:   Loss: 4457.3847 | r_Loss: 580.9970 | g_Loss: 1506.9741 | l_Loss: 45.4256 | 
                                                                                 586		4457.3847		-4.5000
25-09-27 16:06:23.659 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:06:23.660 - INFO: Train epoch 587:   Loss: 4684.0332 | r_Loss: 620.1112 | g_Loss: 1537.4394 | l_Loss: 46.0378 | 
                                                                                 587		4684.0332		-4.5000
25-09-27 16:06:34.750 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:06:34.751 - INFO: Train epoch 588:   Loss: 4469.9961 | r_Loss: 583.6752 | g_Loss: 1506.3463 | l_Loss: 45.2737 | 
                                                                                 588		4469.9961		-4.5000
25-09-27 16:06:45.896 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:06:45.898 - INFO: Train epoch 589:   Loss: 4625.6107 | r_Loss: 611.2649 | g_Loss: 1523.5417 | l_Loss: 45.7447 | 
                                                                                 589		4625.6107		-4.5000
25-09-27 16:06:57.217 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:06:57.219 - INFO: Train epoch 590:   Loss: 4624.0355 | r_Loss: 619.1636 | g_Loss: 1483.8697 | l_Loss: 44.3477 | 
                                                                                 590		4624.0355		-4.5000
25-09-27 16:07:13.017 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:07:13.019 - INFO: Train epoch 591:   Loss: 4457.8878 | r_Loss: 592.6268 | g_Loss: 1451.2717 | l_Loss: 43.4821 | 
                                                                                 591		4457.8878		-4.5000
25-09-27 16:07:24.227 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:07:24.229 - INFO: Train epoch 592:   Loss: 4452.8883 | r_Loss: 587.0909 | g_Loss: 1473.3874 | l_Loss: 44.0463 | 
                                                                                 592		4452.8883		-4.5000
25-09-27 16:07:35.393 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:07:35.395 - INFO: Train epoch 593:   Loss: 5395.5144 | r_Loss: 756.2802 | g_Loss: 1566.5953 | l_Loss: 47.5179 | 
                                                                                 593		5395.5144		-4.5000
25-09-27 16:07:52.558 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:07:52.560 - INFO: Train epoch 594:   Loss: 4504.5658 | r_Loss: 580.8991 | g_Loss: 1554.5505 | l_Loss: 45.5198 | 
                                                                                 594		4504.5658		-4.5000
25-09-27 16:08:03.745 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:08:03.746 - INFO: Train epoch 595:   Loss: 4381.9807 | r_Loss: 565.5342 | g_Loss: 1509.7257 | l_Loss: 44.5839 | 
                                                                                 595		4381.9807		-4.5000
25-09-27 16:08:17.303 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:08:17.305 - INFO: Train epoch 596:   Loss: 4373.0282 | r_Loss: 572.4031 | g_Loss: 1467.5539 | l_Loss: 43.4589 | 
                                                                                 596		4373.0282		-4.5000
25-09-27 16:08:28.573 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:08:28.574 - INFO: Train epoch 597:   Loss: 5272.2698 | r_Loss: 726.6560 | g_Loss: 1591.8925 | l_Loss: 47.0972 | 
                                                                                 597		5272.2698		-4.5000
25-09-27 16:08:43.687 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:08:43.688 - INFO: Train epoch 598:   Loss: 4297.8421 | r_Loss: 552.7857 | g_Loss: 1490.6518 | l_Loss: 43.2619 | 
                                                                                 598		4297.8421		-4.5000
25-09-27 16:08:54.928 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:08:54.928 - INFO: Train epoch 599:   Loss: 4377.2654 | r_Loss: 568.3359 | g_Loss: 1492.2239 | l_Loss: 43.3620 | 
                                                                                 599		4377.2654		-4.5000
25-09-27 16:13:05.135 - INFO: TEST:   PSNR_S: 36.0017 | PSNR_C: 30.1378 | 
25-09-27 16:13:05.137 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:13:05.137 - INFO: Train epoch 600:   Loss: 4369.6156 | r_Loss: 571.1271 | g_Loss: 1471.0029 | l_Loss: 42.9771 | 
                                                                                 600		4369.6156		-4.5000
25-09-27 16:13:16.954 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:13:16.956 - INFO: Train epoch 601:   Loss: 4637.1000 | r_Loss: 621.4177 | g_Loss: 1486.9767 | l_Loss: 43.0349 | 
                                                                                 601		4637.1000		-4.5000
25-09-27 16:13:28.071 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:13:28.073 - INFO: Train epoch 602:   Loss: 4278.6776 | r_Loss: 554.6925 | g_Loss: 1462.5975 | l_Loss: 42.6174 | 
                                                                                 602		4278.6776		-4.5000
25-09-27 16:13:39.356 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:13:39.358 - INFO: Train epoch 603:   Loss: 4730.6403 | r_Loss: 645.8414 | g_Loss: 1458.6529 | l_Loss: 42.7805 | 
                                                                                 603		4730.6403		-4.5000
25-09-27 16:13:50.624 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:13:50.626 - INFO: Train epoch 604:   Loss: 4391.1410 | r_Loss: 571.3367 | g_Loss: 1491.6814 | l_Loss: 42.7760 | 
                                                                                 604		4391.1410		-4.5000
25-09-27 16:14:01.757 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:14:01.758 - INFO: Train epoch 605:   Loss: 4286.3237 | r_Loss: 556.2188 | g_Loss: 1463.1249 | l_Loss: 42.1045 | 
                                                                                 605		4286.3237		-4.5000
25-09-27 16:14:12.964 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:14:12.966 - INFO: Train epoch 606:   Loss: 4302.2464 | r_Loss: 564.6909 | g_Loss: 1437.6307 | l_Loss: 41.1611 | 
                                                                                 606		4302.2464		-4.5000
25-09-27 16:14:24.198 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:14:24.199 - INFO: Train epoch 607:   Loss: 4388.4397 | r_Loss: 580.1652 | g_Loss: 1445.4815 | l_Loss: 42.1321 | 
                                                                                 607		4388.4397		-4.5000
25-09-27 16:14:35.452 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:14:35.453 - INFO: Train epoch 608:   Loss: 4424.3801 | r_Loss: 588.6565 | g_Loss: 1439.7935 | l_Loss: 41.3040 | 
                                                                                 608		4424.3801		-4.5000
25-09-27 16:14:46.753 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:14:46.754 - INFO: Train epoch 609:   Loss: 3981.9409 | r_Loss: 514.2212 | g_Loss: 1371.7575 | l_Loss: 39.0773 | 
                                                                                 609		3981.9409		-4.5000
25-09-27 16:14:57.962 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:14:57.964 - INFO: Train epoch 610:   Loss: 4277.2523 | r_Loss: 561.1095 | g_Loss: 1430.9405 | l_Loss: 40.7644 | 
                                                                                 610		4277.2523		-4.5000
25-09-27 16:15:09.217 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:15:09.219 - INFO: Train epoch 611:   Loss: 4837.5569 | r_Loss: 673.3918 | g_Loss: 1429.6412 | l_Loss: 40.9566 | 
                                                                                 611		4837.5569		-4.5000
25-09-27 16:15:20.394 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:15:20.395 - INFO: Train epoch 612:   Loss: 5151.5683 | r_Loss: 697.2901 | g_Loss: 1617.1617 | l_Loss: 47.9563 | 
                                                                                 612		5151.5683		-4.5000
25-09-27 16:15:31.659 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:15:31.660 - INFO: Train epoch 613:   Loss: 4101.5910 | r_Loss: 519.1830 | g_Loss: 1465.4697 | l_Loss: 40.2063 | 
                                                                                 613		4101.5910		-4.5000
25-09-27 16:15:42.943 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:15:42.945 - INFO: Train epoch 614:   Loss: 4045.3681 | r_Loss: 515.7843 | g_Loss: 1426.8385 | l_Loss: 39.6082 | 
                                                                                 614		4045.3681		-4.5000
25-09-27 16:15:54.283 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:15:54.284 - INFO: Train epoch 615:   Loss: 4258.6398 | r_Loss: 554.5678 | g_Loss: 1445.5517 | l_Loss: 40.2491 | 
                                                                                 615		4258.6398		-4.5000
25-09-27 16:16:05.403 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:16:05.405 - INFO: Train epoch 616:   Loss: 3939.8229 | r_Loss: 501.8459 | g_Loss: 1391.7407 | l_Loss: 38.8528 | 
                                                                                 616		3939.8229		-4.5000
25-09-27 16:16:16.660 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:16:16.661 - INFO: Train epoch 617:   Loss: 4267.3941 | r_Loss: 569.2416 | g_Loss: 1382.1744 | l_Loss: 39.0118 | 
                                                                                 617		4267.3941		-4.5000
25-09-27 16:16:27.923 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:16:27.925 - INFO: Train epoch 618:   Loss: 3972.0064 | r_Loss: 507.0224 | g_Loss: 1397.7115 | l_Loss: 39.1830 | 
                                                                                 618		3972.0064		-4.5000
25-09-27 16:16:39.206 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:16:39.207 - INFO: Train epoch 619:   Loss: 4293.5381 | r_Loss: 568.8211 | g_Loss: 1409.3580 | l_Loss: 40.0748 | 
                                                                                 619		4293.5381		-4.5000
25-09-27 16:16:50.512 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:16:50.514 - INFO: Train epoch 620:   Loss: 4063.0176 | r_Loss: 525.5161 | g_Loss: 1396.0428 | l_Loss: 39.3944 | 
                                                                                 620		4063.0176		-4.5000
25-09-27 16:17:01.842 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:17:01.843 - INFO: Train epoch 621:   Loss: 3997.1832 | r_Loss: 524.5363 | g_Loss: 1337.0633 | l_Loss: 37.4382 | 
                                                                                 621		3997.1832		-4.5000
25-09-27 16:17:13.275 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:17:13.276 - INFO: Train epoch 622:   Loss: 4094.5531 | r_Loss: 532.7618 | g_Loss: 1391.7813 | l_Loss: 38.9628 | 
                                                                                 622		4094.5531		-4.5000
25-09-27 16:17:24.412 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:17:24.413 - INFO: Train epoch 623:   Loss: 4042.4892 | r_Loss: 533.8885 | g_Loss: 1335.8017 | l_Loss: 37.2450 | 
                                                                                 623		4042.4892		-4.5000
25-09-27 16:17:35.563 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:17:35.564 - INFO: Train epoch 624:   Loss: 3837.3281 | r_Loss: 495.3190 | g_Loss: 1323.4066 | l_Loss: 37.3264 | 
                                                                                 624		3837.3281		-4.5000
25-09-27 16:17:46.872 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:17:46.874 - INFO: Train epoch 625:   Loss: 4100.5342 | r_Loss: 545.9236 | g_Loss: 1333.2837 | l_Loss: 37.6324 | 
                                                                                 625		4100.5342		-4.5000
25-09-27 16:17:58.032 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:17:58.033 - INFO: Train epoch 626:   Loss: 4309.9050 | r_Loss: 582.5436 | g_Loss: 1359.2427 | l_Loss: 37.9444 | 
                                                                                 626		4309.9050		-4.5000
25-09-27 16:18:09.362 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:18:09.364 - INFO: Train epoch 627:   Loss: 4204.1177 | r_Loss: 547.7559 | g_Loss: 1425.5657 | l_Loss: 39.7725 | 
                                                                                 627		4204.1177		-4.5000
25-09-27 16:18:20.768 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:18:20.769 - INFO: Train epoch 628:   Loss: 3948.5243 | r_Loss: 504.3314 | g_Loss: 1388.5274 | l_Loss: 38.3401 | 
                                                                                 628		3948.5243		-4.5000
25-09-27 16:18:32.056 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:18:32.058 - INFO: Train epoch 629:   Loss: 3765.7363 | r_Loss: 483.1182 | g_Loss: 1313.7271 | l_Loss: 36.4183 | 
                                                                                 629		3765.7363		-4.5000
25-09-27 16:18:43.313 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:18:43.315 - INFO: Train epoch 630:   Loss: 4083.6395 | r_Loss: 538.9685 | g_Loss: 1351.1177 | l_Loss: 37.6792 | 
                                                                                 630		4083.6395		-4.5000
25-09-27 16:18:54.556 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:18:54.558 - INFO: Train epoch 631:   Loss: 3875.6627 | r_Loss: 496.7615 | g_Loss: 1353.9700 | l_Loss: 37.8854 | 
                                                                                 631		3875.6627		-4.5000
25-09-27 16:19:05.861 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:19:05.863 - INFO: Train epoch 632:   Loss: 3894.2281 | r_Loss: 509.6492 | g_Loss: 1309.5522 | l_Loss: 36.4296 | 
                                                                                 632		3894.2281		-4.5000
25-09-27 16:19:17.160 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:19:17.162 - INFO: Train epoch 633:   Loss: 4202.5819 | r_Loss: 560.1294 | g_Loss: 1362.9248 | l_Loss: 39.0102 | 
                                                                                 633		4202.5819		-4.5000
25-09-27 16:19:28.390 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:19:28.392 - INFO: Train epoch 634:   Loss: 3803.5667 | r_Loss: 486.7468 | g_Loss: 1333.1662 | l_Loss: 36.6665 | 
                                                                                 634		3803.5667		-4.5000
25-09-27 16:19:39.849 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:19:39.850 - INFO: Train epoch 635:   Loss: 3972.2042 | r_Loss: 515.7114 | g_Loss: 1356.1134 | l_Loss: 37.5338 | 
                                                                                 635		3972.2042		-4.5000
25-09-27 16:19:51.189 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:19:51.190 - INFO: Train epoch 636:   Loss: 3784.9387 | r_Loss: 489.0609 | g_Loss: 1303.6359 | l_Loss: 35.9982 | 
                                                                                 636		3784.9387		-4.5000
25-09-27 16:20:02.544 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:20:02.545 - INFO: Train epoch 637:   Loss: 4578.5817 | r_Loss: 618.6175 | g_Loss: 1443.7995 | l_Loss: 41.6946 | 
                                                                                 637		4578.5817		-4.5000
25-09-27 16:20:14.044 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:20:14.045 - INFO: Train epoch 638:   Loss: 3674.2046 | r_Loss: 459.1260 | g_Loss: 1342.2700 | l_Loss: 36.3047 | 
                                                                                 638		3674.2046		-4.5000
25-09-27 16:20:25.270 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:20:25.271 - INFO: Train epoch 639:   Loss: 3808.1447 | r_Loss: 486.6713 | g_Loss: 1338.3852 | l_Loss: 36.4032 | 
                                                                                 639		3808.1447		-4.5000
25-09-27 16:20:36.641 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:20:36.643 - INFO: Train epoch 640:   Loss: 4341.1921 | r_Loss: 583.5203 | g_Loss: 1385.0597 | l_Loss: 38.5310 | 
                                                                                 640		4341.1921		-4.5000
25-09-27 16:20:47.985 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:20:47.987 - INFO: Train epoch 641:   Loss: 3875.2595 | r_Loss: 495.7261 | g_Loss: 1359.4291 | l_Loss: 37.1998 | 
                                                                                 641		3875.2595		-4.5000
25-09-27 16:20:59.559 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:20:59.561 - INFO: Train epoch 642:   Loss: 3773.7041 | r_Loss: 480.6685 | g_Loss: 1334.0946 | l_Loss: 36.2670 | 
                                                                                 642		3773.7041		-4.5000
25-09-27 16:21:10.720 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:21:10.722 - INFO: Train epoch 643:   Loss: 3777.8192 | r_Loss: 488.9016 | g_Loss: 1297.7778 | l_Loss: 35.5336 | 
                                                                                 643		3777.8192		-4.5000
25-09-27 16:21:22.103 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:21:22.105 - INFO: Train epoch 644:   Loss: 3941.0518 | r_Loss: 511.7401 | g_Loss: 1345.3273 | l_Loss: 37.0241 | 
                                                                                 644		3941.0518		-4.5000
25-09-27 16:21:33.501 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:21:33.502 - INFO: Train epoch 645:   Loss: 3711.4053 | r_Loss: 477.0888 | g_Loss: 1290.9708 | l_Loss: 34.9904 | 
                                                                                 645		3711.4053		-4.5000
25-09-27 16:21:44.848 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:21:44.850 - INFO: Train epoch 646:   Loss: 3686.8697 | r_Loss: 474.0661 | g_Loss: 1281.5031 | l_Loss: 35.0360 | 
                                                                                 646		3686.8697		-4.5000
25-09-27 16:21:56.217 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:21:56.218 - INFO: Train epoch 647:   Loss: 4264.7284 | r_Loss: 568.8189 | g_Loss: 1382.5669 | l_Loss: 38.0667 | 
                                                                                 647		4264.7284		-4.5000
25-09-27 16:22:07.547 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:22:07.549 - INFO: Train epoch 648:   Loss: 3787.2588 | r_Loss: 483.6707 | g_Loss: 1332.3337 | l_Loss: 36.5715 | 
                                                                                 648		3787.2588		-4.5000
25-09-27 16:22:18.867 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:22:18.869 - INFO: Train epoch 649:   Loss: 3648.0126 | r_Loss: 464.7003 | g_Loss: 1289.5403 | l_Loss: 34.9708 | 
                                                                                 649		3648.0126		-4.5000
25-09-27 16:26:22.993 - INFO: TEST:   PSNR_S: 36.3264 | PSNR_C: 31.1069 | 
25-09-27 16:26:22.994 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:26:22.995 - INFO: Train epoch 650:   Loss: 3685.9540 | r_Loss: 474.4034 | g_Loss: 1279.2516 | l_Loss: 34.6854 | 
                                                                                 650		3685.9540		-4.5000
25-09-27 16:26:34.343 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:26:34.345 - INFO: Train epoch 651:   Loss: 3780.7255 | r_Loss: 491.7437 | g_Loss: 1286.6913 | l_Loss: 35.3159 | 
                                                                                 651		3780.7255		-4.5000
25-09-27 16:26:45.596 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:26:45.597 - INFO: Train epoch 652:   Loss: 3618.1219 | r_Loss: 460.4159 | g_Loss: 1281.2014 | l_Loss: 34.8412 | 
                                                                                 652		3618.1219		-4.5000
25-09-27 16:26:58.001 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:26:58.002 - INFO: Train epoch 653:   Loss: 3819.5502 | r_Loss: 501.4069 | g_Loss: 1277.7785 | l_Loss: 34.7372 | 
                                                                                 653		3819.5502		-4.5000
25-09-27 16:27:09.218 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:27:09.219 - INFO: Train epoch 654:   Loss: 3847.0765 | r_Loss: 497.4132 | g_Loss: 1324.4060 | l_Loss: 35.6047 | 
                                                                                 654		3847.0765		-4.5000
25-09-27 16:27:21.470 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:27:21.471 - INFO: Train epoch 655:   Loss: 510352.8154 | r_Loss: 95615.1194 | g_Loss: 30989.8549 | l_Loss: 1287.3404 | 
                                                                                 655		510352.8154		-4.5000
25-09-27 16:27:32.759 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:27:32.761 - INFO: Train epoch 656:   Loss: 189491.0475 | r_Loss: 23916.3479 | g_Loss: 66665.3389 | l_Loss: 3243.9680 | 
                                                                                 656		189491.0475		-4.5000
25-09-27 16:27:44.171 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:27:44.172 - INFO: Train epoch 657:   Loss: 53785.1895 | r_Loss: 6170.3468 | g_Loss: 21904.1485 | l_Loss: 1029.3070 | 
                                                                                 657		53785.1895		-4.5000
25-09-27 16:27:55.329 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:27:55.331 - INFO: Train epoch 658:   Loss: 40344.5007 | r_Loss: 4671.8580 | g_Loss: 16260.0984 | l_Loss: 725.1127 | 
                                                                                 658		40344.5007		-4.5000
25-09-27 16:28:06.497 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:28:06.498 - INFO: Train epoch 659:   Loss: 30792.9826 | r_Loss: 3336.6036 | g_Loss: 13483.8360 | l_Loss: 626.1279 | 
                                                                                 659		30792.9826		-4.5000
25-09-27 16:28:17.826 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:28:17.828 - INFO: Train epoch 660:   Loss: 29101.9401 | r_Loss: 3376.3569 | g_Loss: 11627.4274 | l_Loss: 592.7290 | 
                                                                                 660		29101.9401		-4.5000
25-09-27 16:28:37.130 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:28:37.132 - INFO: Train epoch 661:   Loss: 23688.6217 | r_Loss: 2485.8150 | g_Loss: 10764.9166 | l_Loss: 494.6302 | 
                                                                                 661		23688.6217		-4.5000
25-09-27 16:28:48.366 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:28:48.367 - INFO: Train epoch 662:   Loss: 21472.1102 | r_Loss: 2293.4858 | g_Loss: 9557.2612 | l_Loss: 447.4203 | 
                                                                                 662		21472.1102		-4.5000
25-09-27 16:28:59.499 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:28:59.500 - INFO: Train epoch 663:   Loss: 19754.9346 | r_Loss: 2193.3972 | g_Loss: 8400.2626 | l_Loss: 387.6864 | 
                                                                                 663		19754.9346		-4.5000
25-09-27 16:29:14.855 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:29:14.856 - INFO: Train epoch 664:   Loss: 18481.8810 | r_Loss: 2053.9680 | g_Loss: 7855.8302 | l_Loss: 356.2110 | 
                                                                                 664		18481.8810		-4.5000
25-09-27 16:29:25.992 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:29:25.994 - INFO: Train epoch 665:   Loss: 20565.4482 | r_Loss: 2628.0484 | g_Loss: 7095.1172 | l_Loss: 330.0887 | 
                                                                                 665		20565.4482		-4.5000
25-09-27 16:29:37.887 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:29:37.889 - INFO: Train epoch 666:   Loss: 16940.7944 | r_Loss: 1913.9893 | g_Loss: 7033.9119 | l_Loss: 336.9362 | 
                                                                                 666		16940.7944		-4.5000
25-09-27 16:29:49.118 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:29:49.119 - INFO: Train epoch 667:   Loss: 15593.1852 | r_Loss: 1735.3625 | g_Loss: 6624.8180 | l_Loss: 291.5550 | 
                                                                                 667		15593.1852		-4.5000
25-09-27 16:30:02.965 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:30:02.967 - INFO: Train epoch 668:   Loss: 14854.9858 | r_Loss: 1661.9078 | g_Loss: 6276.4082 | l_Loss: 269.0382 | 
                                                                                 668		14854.9858		-4.5000
25-09-27 16:30:14.293 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:30:14.295 - INFO: Train epoch 669:   Loss: 14281.5407 | r_Loss: 1630.0086 | g_Loss: 5881.1721 | l_Loss: 250.3256 | 
                                                                                 669		14281.5407		-4.5000
25-09-27 16:30:32.681 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:30:32.682 - INFO: Train epoch 670:   Loss: 13852.0033 | r_Loss: 1593.1044 | g_Loss: 5644.6840 | l_Loss: 241.7973 | 
                                                                                 670		13852.0033		-4.5000
25-09-27 16:30:44.061 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:30:44.062 - INFO: Train epoch 671:   Loss: 12954.6427 | r_Loss: 1475.1269 | g_Loss: 5351.3660 | l_Loss: 227.6418 | 
                                                                                 671		12954.6427		-4.5000
25-09-27 16:31:00.779 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:31:00.781 - INFO: Train epoch 672:   Loss: 12907.7220 | r_Loss: 1515.0907 | g_Loss: 5113.3443 | l_Loss: 218.9241 | 
                                                                                 672		12907.7220		-4.5000
25-09-27 16:31:18.950 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:31:18.951 - INFO: Train epoch 673:   Loss: 12788.3562 | r_Loss: 1525.5781 | g_Loss: 4946.7784 | l_Loss: 213.6874 | 
                                                                                 673		12788.3562		-4.5000
25-09-27 16:31:30.146 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:31:30.148 - INFO: Train epoch 674:   Loss: 12870.9165 | r_Loss: 1575.5209 | g_Loss: 4786.6616 | l_Loss: 206.6504 | 
                                                                                 674		12870.9165		-4.5000
25-09-27 16:31:57.313 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:31:57.315 - INFO: Train epoch 675:   Loss: 11625.0843 | r_Loss: 1353.6693 | g_Loss: 4661.7740 | l_Loss: 194.9638 | 
                                                                                 675		11625.0843		-4.5000
25-09-27 16:32:08.544 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:32:08.546 - INFO: Train epoch 676:   Loss: 11545.6978 | r_Loss: 1364.9751 | g_Loss: 4530.1870 | l_Loss: 190.6355 | 
                                                                                 676		11545.6978		-4.5000
25-09-27 16:32:25.278 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:32:25.279 - INFO: Train epoch 677:   Loss: 11897.0265 | r_Loss: 1450.4116 | g_Loss: 4458.8215 | l_Loss: 186.1472 | 
                                                                                 677		11897.0265		-4.5000
25-09-27 16:32:36.585 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:32:36.587 - INFO: Train epoch 678:   Loss: 11554.7814 | r_Loss: 1408.1997 | g_Loss: 4330.2237 | l_Loss: 183.5593 | 
                                                                                 678		11554.7814		-4.5000
25-09-27 16:32:48.992 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:32:48.994 - INFO: Train epoch 679:   Loss: 10334.4233 | r_Loss: 1217.1242 | g_Loss: 4079.9979 | l_Loss: 168.8045 | 
                                                                                 679		10334.4233		-4.5000
25-09-27 16:33:00.288 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:33:00.289 - INFO: Train epoch 680:   Loss: 11409.2276 | r_Loss: 1431.3856 | g_Loss: 4079.1649 | l_Loss: 173.1349 | 
                                                                                 680		11409.2276		-4.5000
25-09-27 16:33:16.090 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:33:16.091 - INFO: Train epoch 681:   Loss: 10485.8944 | r_Loss: 1273.4818 | g_Loss: 3951.4057 | l_Loss: 167.0795 | 
                                                                                 681		10485.8944		-4.5000
25-09-27 16:33:27.411 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:33:27.412 - INFO: Train epoch 682:   Loss: 10041.7215 | r_Loss: 1200.7652 | g_Loss: 3878.9604 | l_Loss: 158.9354 | 
                                                                                 682		10041.7215		-4.5000
25-09-27 16:33:46.802 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:33:46.804 - INFO: Train epoch 683:   Loss: 10909.8411 | r_Loss: 1390.5075 | g_Loss: 3797.0014 | l_Loss: 160.3021 | 
                                                                                 683		10909.8411		-4.5000
25-09-27 16:33:57.933 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:33:57.934 - INFO: Train epoch 684:   Loss: 10241.0824 | r_Loss: 1272.7944 | g_Loss: 3724.5873 | l_Loss: 152.5228 | 
                                                                                 684		10241.0824		-4.5000
25-09-27 16:34:21.972 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:34:21.974 - INFO: Train epoch 685:   Loss: 9243.7376 | r_Loss: 1093.8330 | g_Loss: 3626.8533 | l_Loss: 147.7191 | 
                                                                                 685		9243.7376		-4.5000
25-09-27 16:34:33.296 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:34:33.297 - INFO: Train epoch 686:   Loss: 9187.4317 | r_Loss: 1093.1372 | g_Loss: 3576.2621 | l_Loss: 145.4833 | 
                                                                                 686		9187.4317		-4.5000
25-09-27 16:34:51.159 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:34:51.160 - INFO: Train epoch 687:   Loss: 9520.7384 | r_Loss: 1177.1870 | g_Loss: 3493.4071 | l_Loss: 141.3966 | 
                                                                                 687		9520.7384		-4.5000
25-09-27 16:35:02.457 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:35:02.458 - INFO: Train epoch 688:   Loss: 9145.5010 | r_Loss: 1116.2506 | g_Loss: 3427.1579 | l_Loss: 137.0902 | 
                                                                                 688		9145.5010		-4.5000
25-09-27 16:35:25.603 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:35:25.604 - INFO: Train epoch 689:   Loss: 8958.6353 | r_Loss: 1086.6368 | g_Loss: 3390.4176 | l_Loss: 135.0336 | 
                                                                                 689		8958.6353		-4.5000
25-09-27 16:35:36.797 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:35:36.799 - INFO: Train epoch 690:   Loss: 10724.9737 | r_Loss: 1459.4209 | g_Loss: 3290.9390 | l_Loss: 136.9302 | 
                                                                                 690		10724.9737		-4.5000
25-09-27 16:35:54.975 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:35:54.977 - INFO: Train epoch 691:   Loss: 8450.7971 | r_Loss: 1009.5691 | g_Loss: 3271.8781 | l_Loss: 131.0734 | 
                                                                                 691		8450.7971		-4.5000
25-09-27 16:36:06.191 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:36:06.193 - INFO: Train epoch 692:   Loss: 8384.4311 | r_Loss: 1018.2226 | g_Loss: 3169.5061 | l_Loss: 123.8116 | 
                                                                                 692		8384.4311		-4.5000
25-09-27 16:36:36.413 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:36:36.415 - INFO: Train epoch 693:   Loss: 8366.6231 | r_Loss: 1000.1624 | g_Loss: 3239.4016 | l_Loss: 126.4093 | 
                                                                                 693		8366.6231		-4.5000
25-09-27 16:36:47.929 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:36:47.931 - INFO: Train epoch 694:   Loss: 8174.9427 | r_Loss: 985.2237 | g_Loss: 3126.3611 | l_Loss: 122.4631 | 
                                                                                 694		8174.9427		-4.5000
25-09-27 16:36:59.188 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:36:59.189 - INFO: Train epoch 695:   Loss: 8594.8569 | r_Loss: 1078.4874 | g_Loss: 3081.4370 | l_Loss: 120.9825 | 
                                                                                 695		8594.8569		-4.5000
25-09-27 16:37:20.689 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:37:20.691 - INFO: Train epoch 696:   Loss: 8126.4530 | r_Loss: 993.0213 | g_Loss: 3041.4751 | l_Loss: 119.8716 | 
                                                                                 696		8126.4530		-4.5000
25-09-27 16:37:31.825 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:37:31.826 - INFO: Train epoch 697:   Loss: 8095.9672 | r_Loss: 994.3641 | g_Loss: 3005.9079 | l_Loss: 118.2387 | 
                                                                                 697		8095.9672		-4.5000
25-09-27 16:37:46.170 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:37:46.172 - INFO: Train epoch 698:   Loss: 7981.0070 | r_Loss: 984.8114 | g_Loss: 2939.6625 | l_Loss: 117.2875 | 
                                                                                 698		7981.0070		-4.5000
25-09-27 16:38:00.614 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:38:00.616 - INFO: Train epoch 699:   Loss: 9481.0758 | r_Loss: 1285.6970 | g_Loss: 2933.2069 | l_Loss: 119.3837 | 
                                                                                 699		9481.0758		-4.5000
25-09-27 16:48:00.274 - INFO: TEST:   PSNR_S: 33.1930 | PSNR_C: 26.1102 | 
25-09-27 16:48:00.276 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:48:00.277 - INFO: Train epoch 700:   Loss: 7630.1097 | r_Loss: 926.5177 | g_Loss: 2887.0846 | l_Loss: 110.4367 | 
                                                                                 700		7630.1097		-4.5000
25-09-27 16:48:16.415 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:48:16.416 - INFO: Train epoch 701:   Loss: 7544.7412 | r_Loss: 929.6568 | g_Loss: 2788.7460 | l_Loss: 107.7113 | 
                                                                                 701		7544.7412		-4.5000
25-09-27 16:48:27.631 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:48:27.632 - INFO: Train epoch 702:   Loss: 7364.3029 | r_Loss: 893.3749 | g_Loss: 2790.5132 | l_Loss: 106.9150 | 
                                                                                 702		7364.3029		-4.5000
25-09-27 16:48:43.496 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:48:43.497 - INFO: Train epoch 703:   Loss: 7285.8436 | r_Loss: 887.7241 | g_Loss: 2742.4199 | l_Loss: 104.8031 | 
                                                                                 703		7285.8436		-4.5000
25-09-27 16:48:54.741 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:48:54.742 - INFO: Train epoch 704:   Loss: 10291.9321 | r_Loss: 1478.2941 | g_Loss: 2784.2764 | l_Loss: 116.1855 | 
                                                                                 704		10291.9321		-4.5000
25-09-27 16:49:14.916 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:49:14.917 - INFO: Train epoch 705:   Loss: 7306.5592 | r_Loss: 888.8000 | g_Loss: 2758.0338 | l_Loss: 104.5255 | 
                                                                                 705		7306.5592		-4.5000
25-09-27 16:49:26.061 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:49:26.063 - INFO: Train epoch 706:   Loss: 6963.4695 | r_Loss: 834.9790 | g_Loss: 2690.2622 | l_Loss: 98.3124 | 
                                                                                 706		6963.4695		-4.5000
25-09-27 16:49:41.203 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:49:41.205 - INFO: Train epoch 707:   Loss: 6905.5589 | r_Loss: 838.4081 | g_Loss: 2615.5715 | l_Loss: 97.9471 | 
                                                                                 707		6905.5589		-4.5000
25-09-27 16:49:52.296 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:49:52.297 - INFO: Train epoch 708:   Loss: 6852.1115 | r_Loss: 840.4592 | g_Loss: 2554.8683 | l_Loss: 94.9472 | 
                                                                                 708		6852.1115		-4.5000
25-09-27 16:50:09.339 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:50:09.340 - INFO: Train epoch 709:   Loss: 7130.4943 | r_Loss: 892.8897 | g_Loss: 2568.9671 | l_Loss: 97.0787 | 
                                                                                 709		7130.4943		-4.5000
25-09-27 16:50:25.687 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:50:25.688 - INFO: Train epoch 710:   Loss: 6972.3938 | r_Loss: 874.4976 | g_Loss: 2506.0471 | l_Loss: 93.8591 | 
                                                                                 710		6972.3938		-4.5000
25-09-27 16:50:36.825 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:50:36.827 - INFO: Train epoch 711:   Loss: 6882.3531 | r_Loss: 851.9903 | g_Loss: 2527.7636 | l_Loss: 94.6378 | 
                                                                                 711		6882.3531		-4.5000
25-09-27 16:51:04.744 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:51:04.745 - INFO: Train epoch 712:   Loss: 7279.0610 | r_Loss: 940.7149 | g_Loss: 2482.2172 | l_Loss: 93.2693 | 
                                                                                 712		7279.0610		-4.5000
25-09-27 16:51:15.921 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:51:15.923 - INFO: Train epoch 713:   Loss: 7053.0356 | r_Loss: 908.6073 | g_Loss: 2419.0176 | l_Loss: 90.9815 | 
                                                                                 713		7053.0356		-4.5000
25-09-27 16:51:33.233 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:51:33.234 - INFO: Train epoch 714:   Loss: 6638.6065 | r_Loss: 826.9675 | g_Loss: 2414.5821 | l_Loss: 89.1867 | 
                                                                                 714		6638.6065		-4.5000
25-09-27 16:51:44.929 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:51:44.931 - INFO: Train epoch 715:   Loss: 7925.4769 | r_Loss: 1076.6731 | g_Loss: 2451.8008 | l_Loss: 90.3104 | 
                                                                                 715		7925.4769		-4.5000
25-09-27 16:51:56.197 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:51:56.199 - INFO: Train epoch 716:   Loss: 6441.9447 | r_Loss: 792.4478 | g_Loss: 2391.8963 | l_Loss: 87.8093 | 
                                                                                 716		6441.9447		-4.5000
25-09-27 16:52:12.103 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:52:12.104 - INFO: Train epoch 717:   Loss: 6421.5547 | r_Loss: 795.9696 | g_Loss: 2355.5805 | l_Loss: 86.1263 | 
                                                                                 717		6421.5547		-4.5000
25-09-27 16:52:23.324 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:52:23.326 - INFO: Train epoch 718:   Loss: 6260.2599 | r_Loss: 771.2759 | g_Loss: 2319.7714 | l_Loss: 84.1091 | 
                                                                                 718		6260.2599		-4.5000
25-09-27 16:52:41.909 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:52:41.911 - INFO: Train epoch 719:   Loss: 6327.0825 | r_Loss: 792.5214 | g_Loss: 2280.1831 | l_Loss: 84.2924 | 
                                                                                 719		6327.0825		-4.5000
25-09-27 16:52:53.182 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:52:53.184 - INFO: Train epoch 720:   Loss: 9265.4653 | r_Loss: 1379.7400 | g_Loss: 2279.3043 | l_Loss: 87.4611 | 
                                                                                 720		9265.4653		-4.5000
25-09-27 16:53:04.672 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:53:04.674 - INFO: Train epoch 721:   Loss: 6298.8781 | r_Loss: 770.8920 | g_Loss: 2362.2212 | l_Loss: 82.1970 | 
                                                                                 721		6298.8781		-4.5000
25-09-27 16:53:16.071 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:53:16.073 - INFO: Train epoch 722:   Loss: 6093.1221 | r_Loss: 746.9698 | g_Loss: 2278.2086 | l_Loss: 80.0644 | 
                                                                                 722		6093.1221		-4.5000
25-09-27 16:53:28.651 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:53:28.653 - INFO: Train epoch 723:   Loss: 6225.7616 | r_Loss: 773.0588 | g_Loss: 2279.9140 | l_Loss: 80.5537 | 
                                                                                 723		6225.7616		-4.5000
25-09-27 16:53:39.987 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:53:39.989 - INFO: Train epoch 724:   Loss: 6137.1027 | r_Loss: 770.6351 | g_Loss: 2206.2036 | l_Loss: 77.7236 | 
                                                                                 724		6137.1027		-4.5000
25-09-27 16:54:01.675 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:54:01.677 - INFO: Train epoch 725:   Loss: 6074.1419 | r_Loss: 755.9659 | g_Loss: 2215.6314 | l_Loss: 78.6807 | 
                                                                                 725		6074.1419		-4.5000
25-09-27 16:54:13.526 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:54:13.528 - INFO: Train epoch 726:   Loss: 6074.4799 | r_Loss: 769.8303 | g_Loss: 2148.0885 | l_Loss: 77.2397 | 
                                                                                 726		6074.4799		-4.5000
25-09-27 16:54:24.661 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:54:24.661 - INFO: Train epoch 727:   Loss: 6218.8503 | r_Loss: 798.3673 | g_Loss: 2150.7717 | l_Loss: 76.2422 | 
                                                                                 727		6218.8503		-4.5000
25-09-27 16:54:41.079 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:54:41.081 - INFO: Train epoch 728:   Loss: 5918.8274 | r_Loss: 739.6587 | g_Loss: 2144.9827 | l_Loss: 75.5512 | 
                                                                                 728		5918.8274		-4.5000
25-09-27 16:54:52.277 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:54:52.279 - INFO: Train epoch 729:   Loss: 6020.2185 | r_Loss: 765.0364 | g_Loss: 2119.9604 | l_Loss: 75.0757 | 
                                                                                 729		6020.2185		-4.5000
25-09-27 16:55:10.366 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:55:10.367 - INFO: Train epoch 730:   Loss: 5934.1905 | r_Loss: 746.9026 | g_Loss: 2124.4940 | l_Loss: 75.1836 | 
                                                                                 730		5934.1905		-4.5000
25-09-27 16:55:21.695 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:55:21.696 - INFO: Train epoch 731:   Loss: 5928.0656 | r_Loss: 761.9851 | g_Loss: 2045.6289 | l_Loss: 72.5111 | 
                                                                                 731		5928.0656		-4.5000
25-09-27 16:55:37.627 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:55:37.629 - INFO: Train epoch 732:   Loss: 6826.8931 | r_Loss: 931.2361 | g_Loss: 2097.9176 | l_Loss: 72.7951 | 
                                                                                 732		6826.8931		-4.5000
25-09-27 16:55:49.088 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:55:49.090 - INFO: Train epoch 733:   Loss: 5735.7790 | r_Loss: 717.6632 | g_Loss: 2076.5108 | l_Loss: 70.9523 | 
                                                                                 733		5735.7790		-4.5000
25-09-27 16:56:00.285 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:56:00.286 - INFO: Train epoch 734:   Loss: 5552.0578 | r_Loss: 695.1715 | g_Loss: 2006.3162 | l_Loss: 69.8841 | 
                                                                                 734		5552.0578		-4.5000
25-09-27 16:56:11.485 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:56:11.487 - INFO: Train epoch 735:   Loss: 5610.1027 | r_Loss: 704.0867 | g_Loss: 2019.8434 | l_Loss: 69.8256 | 
                                                                                 735		5610.1027		-4.5000
25-09-27 16:56:22.920 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:56:22.922 - INFO: Train epoch 736:   Loss: 6326.7211 | r_Loss: 848.5435 | g_Loss: 2014.4246 | l_Loss: 69.5789 | 
                                                                                 736		6326.7211		-4.5000
25-09-27 16:56:34.408 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:56:34.409 - INFO: Train epoch 737:   Loss: 5853.8438 | r_Loss: 753.9673 | g_Loss: 2015.3725 | l_Loss: 68.6349 | 
                                                                                 737		5853.8438		-4.5000
25-09-27 16:56:56.198 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:56:56.200 - INFO: Train epoch 738:   Loss: 6176.2339 | r_Loss: 830.9621 | g_Loss: 1954.0835 | l_Loss: 67.3399 | 
                                                                                 738		6176.2339		-4.5000
25-09-27 16:57:07.527 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:57:07.529 - INFO: Train epoch 739:   Loss: 5675.6479 | r_Loss: 721.1475 | g_Loss: 2002.3235 | l_Loss: 67.5870 | 
                                                                                 739		5675.6479		-4.5000
25-09-27 16:57:18.918 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:57:18.920 - INFO: Train epoch 740:   Loss: 5623.5860 | r_Loss: 711.2716 | g_Loss: 1999.4157 | l_Loss: 67.8122 | 
                                                                                 740		5623.5860		-4.5000
25-09-27 16:57:30.370 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:57:30.372 - INFO: Train epoch 741:   Loss: 5427.1264 | r_Loss: 683.8713 | g_Loss: 1941.8619 | l_Loss: 65.9080 | 
                                                                                 741		5427.1264		-4.5000
25-09-27 16:57:50.346 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:57:50.348 - INFO: Train epoch 742:   Loss: 5741.3938 | r_Loss: 752.5664 | g_Loss: 1913.6492 | l_Loss: 64.9127 | 
                                                                                 742		5741.3938		-4.5000
25-09-27 16:58:01.726 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:58:01.727 - INFO: Train epoch 743:   Loss: 6040.1503 | r_Loss: 804.8149 | g_Loss: 1950.4810 | l_Loss: 65.5949 | 
                                                                                 743		6040.1503		-4.5000
25-09-27 16:58:12.970 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:58:12.972 - INFO: Train epoch 744:   Loss: 5406.6830 | r_Loss: 678.7557 | g_Loss: 1948.0015 | l_Loss: 64.9029 | 
                                                                                 744		5406.6830		-4.5000
25-09-27 16:58:24.248 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:58:24.250 - INFO: Train epoch 745:   Loss: 5455.6198 | r_Loss: 692.1013 | g_Loss: 1930.6883 | l_Loss: 64.4251 | 
                                                                                 745		5455.6198		-4.5000
25-09-27 16:58:38.896 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:58:38.898 - INFO: Train epoch 746:   Loss: 5656.3968 | r_Loss: 737.7315 | g_Loss: 1903.6187 | l_Loss: 64.1208 | 
                                                                                 746		5656.3968		-4.5000
25-09-27 16:58:50.139 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:58:50.141 - INFO: Train epoch 747:   Loss: 5499.7894 | r_Loss: 706.0663 | g_Loss: 1905.7742 | l_Loss: 63.6836 | 
                                                                                 747		5499.7894		-4.5000
25-09-27 16:59:01.426 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:59:01.428 - INFO: Train epoch 748:   Loss: 5770.7716 | r_Loss: 758.9479 | g_Loss: 1912.4769 | l_Loss: 63.5553 | 
                                                                                 748		5770.7716		-4.5000
25-09-27 16:59:15.434 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 16:59:15.436 - INFO: Train epoch 749:   Loss: 5210.9352 | r_Loss: 654.3882 | g_Loss: 1876.3195 | l_Loss: 62.6749 | 
                                                                                 749		5210.9352		-4.5000
25-09-27 17:05:45.246 - INFO: TEST:   PSNR_S: 35.4150 | PSNR_C: 28.3488 | 
25-09-27 17:05:45.247 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:05:45.248 - INFO: Train epoch 750:   Loss: 6501.7225 | r_Loss: 906.3229 | g_Loss: 1906.5678 | l_Loss: 63.5404 | 
                                                                                 750		6501.7225		-4.5000
25-09-27 17:06:08.079 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:06:08.081 - INFO: Train epoch 751:   Loss: 5254.0977 | r_Loss: 659.7046 | g_Loss: 1893.7437 | l_Loss: 61.8307 | 
                                                                                 751		5254.0977		-4.5000
25-09-27 17:06:19.434 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:06:19.435 - INFO: Train epoch 752:   Loss: 5202.6451 | r_Loss: 653.0170 | g_Loss: 1876.3282 | l_Loss: 61.2320 | 
                                                                                 752		5202.6451		-4.5000
25-09-27 17:07:04.006 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:07:04.008 - INFO: Train epoch 753:   Loss: 5122.6148 | r_Loss: 639.1774 | g_Loss: 1865.9633 | l_Loss: 60.7643 | 
                                                                                 753		5122.6148		-4.5000
25-09-27 17:07:15.291 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:07:15.292 - INFO: Train epoch 754:   Loss: 5516.3695 | r_Loss: 730.5128 | g_Loss: 1804.0947 | l_Loss: 59.7110 | 
                                                                                 754		5516.3695		-4.5000
25-09-27 17:07:29.455 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:07:29.456 - INFO: Train epoch 755:   Loss: 5758.8932 | r_Loss: 775.1273 | g_Loss: 1823.3867 | l_Loss: 59.8701 | 
                                                                                 755		5758.8932		-4.5000
25-09-27 17:07:44.055 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:07:44.057 - INFO: Train epoch 756:   Loss: 5089.8014 | r_Loss: 639.8561 | g_Loss: 1831.1183 | l_Loss: 59.4026 | 
                                                                                 756		5089.8014		-4.5000
25-09-27 17:07:55.876 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:07:55.878 - INFO: Train epoch 757:   Loss: 4837.8728 | r_Loss: 602.4562 | g_Loss: 1768.2942 | l_Loss: 57.2977 | 
                                                                                 757		4837.8728		-4.5000
25-09-27 17:08:12.301 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:08:12.302 - INFO: Train epoch 758:   Loss: 4976.6295 | r_Loss: 624.3147 | g_Loss: 1797.0050 | l_Loss: 58.0512 | 
                                                                                 758		4976.6295		-4.5000
25-09-27 17:08:23.427 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:08:23.428 - INFO: Train epoch 759:   Loss: 4925.7260 | r_Loss: 617.5172 | g_Loss: 1780.0610 | l_Loss: 58.0791 | 
                                                                                 759		4925.7260		-4.5000
25-09-27 17:08:39.426 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:08:39.428 - INFO: Train epoch 760:   Loss: 5013.2865 | r_Loss: 634.9888 | g_Loss: 1780.1572 | l_Loss: 58.1852 | 
                                                                                 760		5013.2865		-4.5000
25-09-27 17:08:53.677 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:08:53.678 - INFO: Train epoch 761:   Loss: 5592.9149 | r_Loss: 757.0278 | g_Loss: 1750.4255 | l_Loss: 57.3505 | 
                                                                                 761		5592.9149		-4.5000
25-09-27 17:09:05.099 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:09:05.100 - INFO: Train epoch 762:   Loss: 6439.7908 | r_Loss: 921.2820 | g_Loss: 1774.7985 | l_Loss: 58.5825 | 
                                                                                 762		6439.7908		-4.5000
25-09-27 17:09:16.392 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:09:16.394 - INFO: Train epoch 763:   Loss: 5002.7977 | r_Loss: 627.2859 | g_Loss: 1809.8197 | l_Loss: 56.5484 | 
                                                                                 763		5002.7977		-4.5000
25-09-27 17:09:31.171 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:09:31.175 - INFO: Train epoch 764:   Loss: 4878.3733 | r_Loss: 609.3003 | g_Loss: 1776.2272 | l_Loss: 55.6447 | 
                                                                                 764		4878.3733		-4.5000
25-09-27 17:09:42.434 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:09:42.436 - INFO: Train epoch 765:   Loss: 4942.6700 | r_Loss: 625.5298 | g_Loss: 1759.8753 | l_Loss: 55.1457 | 
                                                                                 765		4942.6700		-4.5000
25-09-27 17:09:54.387 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:09:54.388 - INFO: Train epoch 766:   Loss: 4719.0890 | r_Loss: 583.5102 | g_Loss: 1746.2461 | l_Loss: 55.2922 | 
                                                                                 766		4719.0890		-4.5000
25-09-27 17:10:09.919 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:10:09.920 - INFO: Train epoch 767:   Loss: 4829.6297 | r_Loss: 604.6159 | g_Loss: 1750.8204 | l_Loss: 55.7298 | 
                                                                                 767		4829.6297		-4.5000
25-09-27 17:10:21.632 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:10:21.633 - INFO: Train epoch 768:   Loss: 4687.4334 | r_Loss: 586.9941 | g_Loss: 1697.6390 | l_Loss: 54.8237 | 
                                                                                 768		4687.4334		-4.5000
25-09-27 17:10:35.384 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:10:35.386 - INFO: Train epoch 769:   Loss: 4766.9018 | r_Loss: 599.1320 | g_Loss: 1716.3234 | l_Loss: 54.9187 | 
                                                                                 769		4766.9018		-4.5000
25-09-27 17:10:47.136 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:10:47.137 - INFO: Train epoch 770:   Loss: 4790.8309 | r_Loss: 610.3002 | g_Loss: 1685.0603 | l_Loss: 54.2698 | 
                                                                                 770		4790.8309		-4.5000
25-09-27 17:11:27.509 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:11:27.510 - INFO: Train epoch 771:   Loss: 5921.8700 | r_Loss: 836.3254 | g_Loss: 1683.8537 | l_Loss: 56.3891 | 
                                                                                 771		5921.8700		-4.5000
25-09-27 17:11:45.620 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:11:45.620 - INFO: Train epoch 772:   Loss: 4699.2985 | r_Loss: 593.9275 | g_Loss: 1675.9175 | l_Loss: 53.7437 | 
                                                                                 772		4699.2985		-4.5000
25-09-27 17:11:56.879 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:11:56.880 - INFO: Train epoch 773:   Loss: 4742.9478 | r_Loss: 596.7087 | g_Loss: 1705.7107 | l_Loss: 53.6939 | 
                                                                                 773		4742.9478		-4.5000
25-09-27 17:12:08.706 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:12:08.707 - INFO: Train epoch 774:   Loss: 4643.3375 | r_Loss: 586.5765 | g_Loss: 1657.9685 | l_Loss: 52.4867 | 
                                                                                 774		4643.3375		-4.5000
25-09-27 17:12:19.997 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:12:19.998 - INFO: Train epoch 775:   Loss: 4710.6410 | r_Loss: 592.1691 | g_Loss: 1696.4465 | l_Loss: 53.3490 | 
                                                                                 775		4710.6410		-4.5000
25-09-27 17:12:41.182 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:12:41.183 - INFO: Train epoch 776:   Loss: 4655.5850 | r_Loss: 588.0042 | g_Loss: 1663.0567 | l_Loss: 52.5071 | 
                                                                                 776		4655.5850		-4.5000
25-09-27 17:12:52.463 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:12:52.465 - INFO: Train epoch 777:   Loss: 5520.1202 | r_Loss: 760.1177 | g_Loss: 1667.0738 | l_Loss: 52.4579 | 
                                                                                 777		5520.1202		-4.5000
25-09-27 17:13:08.554 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:13:08.556 - INFO: Train epoch 778:   Loss: 4548.0462 | r_Loss: 567.5930 | g_Loss: 1658.6623 | l_Loss: 51.4191 | 
                                                                                 778		4548.0462		-4.5000
25-09-27 17:13:19.674 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:13:19.675 - INFO: Train epoch 779:   Loss: 4584.8628 | r_Loss: 575.9167 | g_Loss: 1653.8842 | l_Loss: 51.3952 | 
                                                                                 779		4584.8628		-4.5000
25-09-27 17:13:30.967 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:13:30.969 - INFO: Train epoch 780:   Loss: 4833.0359 | r_Loss: 627.0271 | g_Loss: 1646.4872 | l_Loss: 51.4133 | 
                                                                                 780		4833.0359		-4.5000
25-09-27 17:13:46.064 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:13:46.066 - INFO: Train epoch 781:   Loss: 4592.3217 | r_Loss: 578.4463 | g_Loss: 1648.5132 | l_Loss: 51.5770 | 
                                                                                 781		4592.3217		-4.5000
25-09-27 17:13:57.187 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:13:57.188 - INFO: Train epoch 782:   Loss: 4495.4958 | r_Loss: 561.8320 | g_Loss: 1635.2712 | l_Loss: 51.0647 | 
                                                                                 782		4495.4958		-4.5000
25-09-27 17:14:22.511 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:14:22.513 - INFO: Train epoch 783:   Loss: 5294.5856 | r_Loss: 719.4001 | g_Loss: 1645.1653 | l_Loss: 52.4199 | 
                                                                                 783		5294.5856		-4.5000
25-09-27 17:14:35.444 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:14:35.446 - INFO: Train epoch 784:   Loss: 4638.4511 | r_Loss: 593.9876 | g_Loss: 1617.5225 | l_Loss: 50.9908 | 
                                                                                 784		4638.4511		-4.5000
25-09-27 17:14:46.619 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:14:46.620 - INFO: Train epoch 785:   Loss: 4447.4432 | r_Loss: 558.5473 | g_Loss: 1604.7210 | l_Loss: 49.9859 | 
                                                                                 785		4447.4432		-4.5000
25-09-27 17:15:10.403 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:15:10.405 - INFO: Train epoch 786:   Loss: 4360.4982 | r_Loss: 543.2126 | g_Loss: 1594.9480 | l_Loss: 49.4871 | 
                                                                                 786		4360.4982		-4.5000
25-09-27 17:15:44.606 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:15:44.608 - INFO: Train epoch 787:   Loss: 4435.4887 | r_Loss: 553.9311 | g_Loss: 1615.6713 | l_Loss: 50.1621 | 
                                                                                 787		4435.4887		-4.5000
25-09-27 17:15:55.812 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:15:55.814 - INFO: Train epoch 788:   Loss: 4661.6522 | r_Loss: 599.4460 | g_Loss: 1613.7209 | l_Loss: 50.7014 | 
                                                                                 788		4661.6522		-4.5000
25-09-27 17:16:07.105 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:16:07.106 - INFO: Train epoch 789:   Loss: 4466.6176 | r_Loss: 565.8840 | g_Loss: 1587.9241 | l_Loss: 49.2733 | 
                                                                                 789		4466.6176		-4.5000
25-09-27 17:16:29.838 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:16:29.839 - INFO: Train epoch 790:   Loss: 4346.9114 | r_Loss: 546.6348 | g_Loss: 1565.2620 | l_Loss: 48.4754 | 
                                                                                 790		4346.9114		-4.5000
25-09-27 17:16:41.010 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:16:41.011 - INFO: Train epoch 791:   Loss: 5008.2402 | r_Loss: 681.4528 | g_Loss: 1548.5181 | l_Loss: 52.4584 | 
                                                                                 791		5008.2402		-4.5000
25-09-27 17:16:59.269 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:16:59.270 - INFO: Train epoch 792:   Loss: 4331.2080 | r_Loss: 541.2725 | g_Loss: 1576.1889 | l_Loss: 48.6567 | 
                                                                                 792		4331.2080		-4.5000
25-09-27 17:17:11.151 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:17:11.153 - INFO: Train epoch 793:   Loss: 4176.8332 | r_Loss: 522.2105 | g_Loss: 1519.2414 | l_Loss: 46.5394 | 
                                                                                 793		4176.8332		-4.5000
25-09-27 17:17:22.515 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:17:22.517 - INFO: Train epoch 794:   Loss: 4262.8621 | r_Loss: 531.4599 | g_Loss: 1557.4405 | l_Loss: 48.1220 | 
                                                                                 794		4262.8621		-4.5000
25-09-27 17:17:35.882 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:17:35.883 - INFO: Train epoch 795:   Loss: 4173.3254 | r_Loss: 527.6609 | g_Loss: 1487.8976 | l_Loss: 47.1232 | 
                                                                                 795		4173.3254		-4.5000
25-09-27 17:17:54.797 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:17:54.799 - INFO: Train epoch 796:   Loss: 4697.7237 | r_Loss: 620.8682 | g_Loss: 1543.8915 | l_Loss: 49.4912 | 
                                                                                 796		4697.7237		-4.5000
25-09-27 17:18:05.961 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:18:05.962 - INFO: Train epoch 797:   Loss: 4288.0589 | r_Loss: 539.0353 | g_Loss: 1544.9912 | l_Loss: 47.8911 | 
                                                                                 797		4288.0589		-4.5000
25-09-27 17:18:46.482 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:18:46.483 - INFO: Train epoch 798:   Loss: 4727.2503 | r_Loss: 624.9343 | g_Loss: 1551.5642 | l_Loss: 51.0146 | 
                                                                                 798		4727.2503		-4.5000
25-09-27 17:18:57.784 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:18:57.785 - INFO: Train epoch 799:   Loss: 4203.9400 | r_Loss: 526.4396 | g_Loss: 1524.5967 | l_Loss: 47.1454 | 
                                                                                 799		4203.9400		-4.5000
25-09-27 17:33:41.397 - INFO: TEST:   PSNR_S: 37.2377 | PSNR_C: 29.7772 | 
25-09-27 17:33:41.398 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:33:41.399 - INFO: Train epoch 800:   Loss: 4438.6979 | r_Loss: 568.8961 | g_Loss: 1545.9852 | l_Loss: 48.2323 | 
                                                                                 800		4438.6979		-4.5000
25-09-27 17:33:54.884 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:33:54.885 - INFO: Train epoch 801:   Loss: 3965.3125 | r_Loss: 488.8690 | g_Loss: 1475.7334 | l_Loss: 45.2339 | 
                                                                                 801		3965.3125		-4.5000
25-09-27 17:34:05.952 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:34:05.953 - INFO: Train epoch 802:   Loss: 4703.4224 | r_Loss: 625.9133 | g_Loss: 1524.8695 | l_Loss: 48.9867 | 
                                                                                 802		4703.4224		-4.5000
25-09-27 17:34:36.858 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:34:36.860 - INFO: Train epoch 803:   Loss: 4162.6897 | r_Loss: 521.3585 | g_Loss: 1509.7436 | l_Loss: 46.1538 | 
                                                                                 803		4162.6897		-4.5000
25-09-27 17:34:48.066 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:34:48.068 - INFO: Train epoch 804:   Loss: 4128.1563 | r_Loss: 516.6285 | g_Loss: 1498.8857 | l_Loss: 46.1280 | 
                                                                                 804		4128.1563		-4.5000
25-09-27 17:34:59.364 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:34:59.365 - INFO: Train epoch 805:   Loss: 4416.0170 | r_Loss: 574.5903 | g_Loss: 1496.8360 | l_Loss: 46.2297 | 
                                                                                 805		4416.0170		-4.5000
25-09-27 17:35:12.103 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:35:12.105 - INFO: Train epoch 806:   Loss: 4088.8651 | r_Loss: 513.3604 | g_Loss: 1476.3909 | l_Loss: 45.6721 | 
                                                                                 806		4088.8651		-4.5000
25-09-27 17:35:23.247 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:35:23.248 - INFO: Train epoch 807:   Loss: 6042.9884 | r_Loss: 887.2072 | g_Loss: 1540.0038 | l_Loss: 66.9491 | 
                                                                                 807		6042.9884		-4.5000
25-09-27 17:35:48.424 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:35:48.425 - INFO: Train epoch 808:   Loss: 4324.2890 | r_Loss: 544.0420 | g_Loss: 1556.8393 | l_Loss: 47.2395 | 
                                                                                 808		4324.2890		-4.5000
25-09-27 17:35:59.655 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:35:59.657 - INFO: Train epoch 809:   Loss: 4112.8701 | r_Loss: 509.5694 | g_Loss: 1520.3227 | l_Loss: 44.7006 | 
                                                                                 809		4112.8701		-4.5000
25-09-27 17:36:23.329 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:36:23.330 - INFO: Train epoch 810:   Loss: 4046.5299 | r_Loss: 501.1579 | g_Loss: 1496.6437 | l_Loss: 44.0969 | 
                                                                                 810		4046.5299		-4.5000
25-09-27 17:36:34.406 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:36:34.407 - INFO: Train epoch 811:   Loss: 4044.0014 | r_Loss: 499.2393 | g_Loss: 1502.3606 | l_Loss: 45.4443 | 
                                                                                 811		4044.0014		-4.5000
25-09-27 17:36:45.653 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:36:45.654 - INFO: Train epoch 812:   Loss: 3984.9212 | r_Loss: 493.7618 | g_Loss: 1472.1007 | l_Loss: 44.0115 | 
                                                                                 812		3984.9212		-4.5000
25-09-27 17:37:21.817 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:37:21.818 - INFO: Train epoch 813:   Loss: 4049.7939 | r_Loss: 507.1695 | g_Loss: 1469.5080 | l_Loss: 44.4385 | 
                                                                                 813		4049.7939		-4.5000
25-09-27 17:37:32.893 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:37:32.894 - INFO: Train epoch 814:   Loss: 4344.3559 | r_Loss: 568.7970 | g_Loss: 1456.1405 | l_Loss: 44.2305 | 
                                                                                 814		4344.3559		-4.5000
25-09-27 17:37:44.130 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:37:44.131 - INFO: Train epoch 815:   Loss: 4364.5999 | r_Loss: 567.3691 | g_Loss: 1479.8079 | l_Loss: 47.9466 | 
                                                                                 815		4364.5999		-4.5000
25-09-27 17:37:55.383 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:37:55.385 - INFO: Train epoch 816:   Loss: 3991.0480 | r_Loss: 497.0559 | g_Loss: 1461.5171 | l_Loss: 44.2516 | 
                                                                                 816		3991.0480		-4.5000
25-09-27 17:38:06.565 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:38:06.567 - INFO: Train epoch 817:   Loss: 3903.7762 | r_Loss: 483.3526 | g_Loss: 1443.2062 | l_Loss: 43.8067 | 
                                                                                 817		3903.7762		-4.5000
25-09-27 17:38:28.548 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:38:28.550 - INFO: Train epoch 818:   Loss: 3909.3806 | r_Loss: 489.3407 | g_Loss: 1418.8543 | l_Loss: 43.8228 | 
                                                                                 818		3909.3806		-4.5000
25-09-27 17:38:39.648 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:38:39.650 - INFO: Train epoch 819:   Loss: 5490.5309 | r_Loss: 789.6582 | g_Loss: 1478.5270 | l_Loss: 63.7129 | 
                                                                                 819		5490.5309		-4.5000
25-09-27 17:38:51.737 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:38:51.739 - INFO: Train epoch 820:   Loss: 5139.3593 | r_Loss: 707.8164 | g_Loss: 1529.1587 | l_Loss: 71.1186 | 
                                                                                 820		5139.3593		-4.5000
25-09-27 17:39:02.999 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:39:03.001 - INFO: Train epoch 821:   Loss: 4028.8375 | r_Loss: 495.3347 | g_Loss: 1509.7384 | l_Loss: 42.4256 | 
                                                                                 821		4028.8375		-4.5000
25-09-27 17:39:14.056 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:39:14.058 - INFO: Train epoch 822:   Loss: 3989.2833 | r_Loss: 489.7213 | g_Loss: 1497.8187 | l_Loss: 42.8579 | 
                                                                                 822		3989.2833		-4.5000
25-09-27 17:39:39.177 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:39:39.178 - INFO: Train epoch 823:   Loss: 3688.7971 | r_Loss: 448.8623 | g_Loss: 1404.0478 | l_Loss: 40.4379 | 
                                                                                 823		3688.7971		-4.5000
25-09-27 17:39:50.247 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:39:50.248 - INFO: Train epoch 824:   Loss: 3932.6527 | r_Loss: 485.6968 | g_Loss: 1461.0914 | l_Loss: 43.0771 | 
                                                                                 824		3932.6527		-4.5000
25-09-27 17:40:02.131 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:40:02.132 - INFO: Train epoch 825:   Loss: 3873.7087 | r_Loss: 476.0342 | g_Loss: 1450.5760 | l_Loss: 42.9619 | 
                                                                                 825		3873.7087		-4.5000
25-09-27 17:40:13.273 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:40:13.275 - INFO: Train epoch 826:   Loss: 3609.6901 | r_Loss: 440.9376 | g_Loss: 1364.7304 | l_Loss: 40.2719 | 
                                                                                 826		3609.6901		-4.5000
25-09-27 17:40:24.502 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:40:24.503 - INFO: Train epoch 827:   Loss: 3816.1043 | r_Loss: 472.3876 | g_Loss: 1411.8098 | l_Loss: 42.3562 | 
                                                                                 827		3816.1043		-4.5000
25-09-27 17:40:42.076 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:40:42.077 - INFO: Train epoch 828:   Loss: 3788.2428 | r_Loss: 470.2140 | g_Loss: 1394.5223 | l_Loss: 42.6503 | 
                                                                                 828		3788.2428		-4.5000
25-09-27 17:40:53.441 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:40:53.442 - INFO: Train epoch 829:   Loss: 3992.2595 | r_Loss: 506.4286 | g_Loss: 1417.8221 | l_Loss: 42.2944 | 
                                                                                 829		3992.2595		-4.5000
25-09-27 17:41:04.586 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:41:04.588 - INFO: Train epoch 830:   Loss: 4110.3916 | r_Loss: 525.5727 | g_Loss: 1435.6543 | l_Loss: 46.8737 | 
                                                                                 830		4110.3916		-4.5000
25-09-27 17:41:31.784 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:41:31.786 - INFO: Train epoch 831:   Loss: 3661.8025 | r_Loss: 449.6502 | g_Loss: 1372.9866 | l_Loss: 40.5651 | 
                                                                                 831		3661.8025		-4.5000
25-09-27 17:41:43.140 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:41:43.141 - INFO: Train epoch 832:   Loss: 3850.5495 | r_Loss: 481.7497 | g_Loss: 1399.6997 | l_Loss: 42.1013 | 
                                                                                 832		3850.5495		-4.5000
25-09-27 17:41:57.795 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:41:57.796 - INFO: Train epoch 833:   Loss: 3849.4263 | r_Loss: 477.7820 | g_Loss: 1417.9139 | l_Loss: 42.6021 | 
                                                                                 833		3849.4263		-4.5000
25-09-27 17:42:22.551 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:42:22.553 - INFO: Train epoch 834:   Loss: 3798.0521 | r_Loss: 475.1280 | g_Loss: 1380.6073 | l_Loss: 41.8050 | 
                                                                                 834		3798.0521		-4.5000
25-09-27 17:42:34.376 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:42:34.378 - INFO: Train epoch 835:   Loss: 3954.4298 | r_Loss: 505.9825 | g_Loss: 1382.0996 | l_Loss: 42.4176 | 
                                                                                 835		3954.4298		-4.5000
25-09-27 17:42:45.530 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:42:45.531 - INFO: Train epoch 836:   Loss: 3736.7404 | r_Loss: 471.1997 | g_Loss: 1339.6697 | l_Loss: 41.0720 | 
                                                                                 836		3736.7404		-4.5000
25-09-27 17:43:00.646 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:43:00.648 - INFO: Train epoch 837:   Loss: 3716.3561 | r_Loss: 465.7397 | g_Loss: 1347.0382 | l_Loss: 40.6192 | 
                                                                                 837		3716.3561		-4.5000
25-09-27 17:43:11.858 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:43:11.859 - INFO: Train epoch 838:   Loss: 3878.4832 | r_Loss: 493.8921 | g_Loss: 1365.6258 | l_Loss: 43.3968 | 
                                                                                 838		3878.4832		-4.5000
25-09-27 17:43:25.669 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:43:25.671 - INFO: Train epoch 839:   Loss: 3816.7685 | r_Loss: 481.8441 | g_Loss: 1365.3011 | l_Loss: 42.2472 | 
                                                                                 839		3816.7685		-4.5000
25-09-27 17:43:37.184 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:43:37.185 - INFO: Train epoch 840:   Loss: 4051.8753 | r_Loss: 526.8031 | g_Loss: 1372.6593 | l_Loss: 45.2005 | 
                                                                                 840		4051.8753		-4.5000
25-09-27 17:43:48.337 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:43:48.338 - INFO: Train epoch 841:   Loss: 3765.4137 | r_Loss: 470.6179 | g_Loss: 1371.1737 | l_Loss: 41.1506 | 
                                                                                 841		3765.4137		-4.5000
25-09-27 17:44:16.893 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:44:16.895 - INFO: Train epoch 842:   Loss: 4454.4374 | r_Loss: 603.1902 | g_Loss: 1388.9448 | l_Loss: 49.5413 | 
                                                                                 842		4454.4374		-4.5000
25-09-27 17:44:27.943 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:44:27.945 - INFO: Train epoch 843:   Loss: 3741.7488 | r_Loss: 467.3017 | g_Loss: 1364.6561 | l_Loss: 40.5841 | 
                                                                                 843		3741.7488		-4.5000
25-09-27 17:44:45.998 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:44:45.999 - INFO: Train epoch 844:   Loss: 3619.3171 | r_Loss: 446.5718 | g_Loss: 1346.1091 | l_Loss: 40.3491 | 
                                                                                 844		3619.3171		-4.5000
25-09-27 17:44:57.210 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:44:57.212 - INFO: Train epoch 845:   Loss: 3735.6693 | r_Loss: 463.9799 | g_Loss: 1374.8040 | l_Loss: 40.9658 | 
                                                                                 845		3735.6693		-4.5000
25-09-27 17:45:21.462 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:45:21.463 - INFO: Train epoch 846:   Loss: 3732.1305 | r_Loss: 470.1420 | g_Loss: 1341.2646 | l_Loss: 40.1562 | 
                                                                                 846		3732.1305		-4.5000
25-09-27 17:45:32.538 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:45:32.539 - INFO: Train epoch 847:   Loss: 3739.1809 | r_Loss: 469.9132 | g_Loss: 1348.1636 | l_Loss: 41.4512 | 
                                                                                 847		3739.1809		-4.5000
25-09-27 17:46:06.527 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:46:06.528 - INFO: Train epoch 848:   Loss: 3551.9779 | r_Loss: 436.5491 | g_Loss: 1329.1700 | l_Loss: 40.0624 | 
                                                                                 848		3551.9779		-4.5000
25-09-27 17:46:17.697 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 17:46:17.698 - INFO: Train epoch 849:   Loss: 4108.0326 | r_Loss: 549.4299 | g_Loss: 1320.5765 | l_Loss: 40.3065 | 
                                                                                 849		4108.0326		-4.5000
25-09-27 18:00:24.929 - INFO: TEST:   PSNR_S: 38.9352 | PSNR_C: 30.6500 | 
25-09-27 18:00:24.935 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:00:24.936 - INFO: Train epoch 850:   Loss: 3620.1985 | r_Loss: 443.5692 | g_Loss: 1361.7149 | l_Loss: 40.6374 | 
                                                                                 850		3620.1985		-4.5000
25-09-27 18:01:01.028 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:01:01.030 - INFO: Train epoch 851:   Loss: 3584.0370 | r_Loss: 442.9836 | g_Loss: 1328.9554 | l_Loss: 40.1634 | 
                                                                                 851		3584.0370		-4.5000
25-09-27 18:01:12.104 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:01:12.106 - INFO: Train epoch 852:   Loss: 3858.7746 | r_Loss: 490.0111 | g_Loss: 1356.9002 | l_Loss: 51.8192 | 
                                                                                 852		3858.7746		-4.5000
25-09-27 18:01:40.033 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:01:40.034 - INFO: Train epoch 853:   Loss: 3625.3531 | r_Loss: 456.7624 | g_Loss: 1299.4417 | l_Loss: 42.0996 | 
                                                                                 853		3625.3531		-4.5000
25-09-27 18:01:51.192 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:01:51.193 - INFO: Train epoch 854:   Loss: 3642.8181 | r_Loss: 451.8752 | g_Loss: 1342.9694 | l_Loss: 40.4730 | 
                                                                                 854		3642.8181		-4.5000
25-09-27 18:02:02.267 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:02:02.268 - INFO: Train epoch 855:   Loss: 3495.5465 | r_Loss: 435.0946 | g_Loss: 1282.0384 | l_Loss: 38.0352 | 
                                                                                 855		3495.5465		-4.5000
25-09-27 18:02:13.553 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:02:13.555 - INFO: Train epoch 856:   Loss: 3639.3943 | r_Loss: 456.7017 | g_Loss: 1316.1738 | l_Loss: 39.7120 | 
                                                                                 856		3639.3943		-4.5000
25-09-27 18:02:24.699 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:02:24.701 - INFO: Train epoch 857:   Loss: 3600.3103 | r_Loss: 454.7813 | g_Loss: 1286.9918 | l_Loss: 39.4123 | 
                                                                                 857		3600.3103		-4.5000
25-09-27 18:03:17.568 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:03:17.570 - INFO: Train epoch 858:   Loss: 3663.7840 | r_Loss: 461.5383 | g_Loss: 1315.7336 | l_Loss: 40.3590 | 
                                                                                 858		3663.7840		-4.5000
25-09-27 18:03:28.842 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:03:28.844 - INFO: Train epoch 859:   Loss: 3586.2744 | r_Loss: 452.5381 | g_Loss: 1282.8358 | l_Loss: 40.7481 | 
                                                                                 859		3586.2744		-4.5000
25-09-27 18:04:04.031 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:04:04.033 - INFO: Train epoch 860:   Loss: 4321.4783 | r_Loss: 583.5673 | g_Loss: 1344.1037 | l_Loss: 59.5383 | 
                                                                                 860		4321.4783		-4.5000
25-09-27 18:04:23.576 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:04:23.577 - INFO: Train epoch 861:   Loss: 3579.3669 | r_Loss: 443.2876 | g_Loss: 1323.1559 | l_Loss: 39.7730 | 
                                                                                 861		3579.3669		-4.5000
25-09-27 18:04:34.702 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:04:34.704 - INFO: Train epoch 862:   Loss: 3503.5510 | r_Loss: 429.9201 | g_Loss: 1314.4598 | l_Loss: 39.4905 | 
                                                                                 862		3503.5510		-4.5000
25-09-27 18:04:45.945 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:04:45.947 - INFO: Train epoch 863:   Loss: 3468.3394 | r_Loss: 427.1030 | g_Loss: 1293.1679 | l_Loss: 39.6564 | 
                                                                                 863		3468.3394		-4.5000
25-09-27 18:05:10.641 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:05:10.642 - INFO: Train epoch 864:   Loss: 3672.5093 | r_Loss: 467.8720 | g_Loss: 1290.9442 | l_Loss: 42.2050 | 
                                                                                 864		3672.5093		-4.5000
25-09-27 18:05:21.897 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:05:21.899 - INFO: Train epoch 865:   Loss: 3649.9105 | r_Loss: 463.3248 | g_Loss: 1290.5231 | l_Loss: 42.7636 | 
                                                                                 865		3649.9105		-4.5000
25-09-27 18:05:33.115 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:05:33.116 - INFO: Train epoch 866:   Loss: 3542.5035 | r_Loss: 438.0713 | g_Loss: 1312.8239 | l_Loss: 39.3235 | 
                                                                                 866		3542.5035		-4.5000
25-09-27 18:06:12.322 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:06:12.324 - INFO: Train epoch 867:   Loss: 3495.5658 | r_Loss: 438.0346 | g_Loss: 1265.8512 | l_Loss: 39.5416 | 
                                                                                 867		3495.5658		-4.5000
25-09-27 18:06:23.556 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:06:23.557 - INFO: Train epoch 868:   Loss: 3424.3265 | r_Loss: 425.2294 | g_Loss: 1259.0719 | l_Loss: 39.1075 | 
                                                                                 868		3424.3265		-4.5000
25-09-27 18:06:48.276 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:06:48.277 - INFO: Train epoch 869:   Loss: 3510.4312 | r_Loss: 439.4159 | g_Loss: 1273.7159 | l_Loss: 39.6358 | 
                                                                                 869		3510.4312		-4.5000
25-09-27 18:06:59.400 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:06:59.402 - INFO: Train epoch 870:   Loss: 4424.3186 | r_Loss: 598.0359 | g_Loss: 1356.3658 | l_Loss: 77.7733 | 
                                                                                 870		4424.3186		-4.5000
25-09-27 18:07:10.626 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:07:10.628 - INFO: Train epoch 871:   Loss: 3413.5530 | r_Loss: 419.0756 | g_Loss: 1279.1316 | l_Loss: 39.0436 | 
                                                                                 871		3413.5530		-4.5000
25-09-27 18:07:21.958 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:07:21.960 - INFO: Train epoch 872:   Loss: 3486.6416 | r_Loss: 429.6723 | g_Loss: 1299.6544 | l_Loss: 38.6259 | 
                                                                                 872		3486.6416		-4.5000
25-09-27 18:07:33.152 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:07:33.154 - INFO: Train epoch 873:   Loss: 3347.2071 | r_Loss: 410.8111 | g_Loss: 1256.2993 | l_Loss: 36.8522 | 
                                                                                 873		3347.2071		-4.5000
25-09-27 18:07:44.560 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:07:44.562 - INFO: Train epoch 874:   Loss: 3362.7938 | r_Loss: 416.0865 | g_Loss: 1244.6620 | l_Loss: 37.6994 | 
                                                                                 874		3362.7938		-4.5000
25-09-27 18:08:09.646 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:08:09.648 - INFO: Train epoch 875:   Loss: 3435.7373 | r_Loss: 425.2836 | g_Loss: 1270.0612 | l_Loss: 39.2580 | 
                                                                                 875		3435.7373		-4.5000
25-09-27 18:08:20.869 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:08:20.871 - INFO: Train epoch 876:   Loss: 3633.2780 | r_Loss: 463.9055 | g_Loss: 1273.7210 | l_Loss: 40.0295 | 
                                                                                 876		3633.2780		-4.5000
25-09-27 18:08:32.033 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:08:32.034 - INFO: Train epoch 877:   Loss: 3421.1377 | r_Loss: 426.5326 | g_Loss: 1249.3891 | l_Loss: 39.0853 | 
                                                                                 877		3421.1377		-4.5000
25-09-27 18:08:57.481 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:08:57.483 - INFO: Train epoch 878:   Loss: 3616.4655 | r_Loss: 455.6655 | g_Loss: 1290.0285 | l_Loss: 48.1095 | 
                                                                                 878		3616.4655		-4.5000
25-09-27 18:09:08.617 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:09:08.618 - INFO: Train epoch 879:   Loss: 3391.3074 | r_Loss: 419.7894 | g_Loss: 1253.7340 | l_Loss: 38.6261 | 
                                                                                 879		3391.3074		-4.5000
25-09-27 18:09:30.478 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:09:30.479 - INFO: Train epoch 880:   Loss: 3469.1116 | r_Loss: 435.5888 | g_Loss: 1252.5155 | l_Loss: 38.6523 | 
                                                                                 880		3469.1116		-4.5000
25-09-27 18:09:42.741 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:09:42.743 - INFO: Train epoch 881:   Loss: 301265.7567 | r_Loss: 54613.7945 | g_Loss: 18448.9050 | l_Loss: 9747.8759 | 
                                                                                 881		301265.7567		-4.5000
25-09-27 18:09:53.901 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:09:53.902 - INFO: Train epoch 882:   Loss: 115329.8184 | r_Loss: 12631.2159 | g_Loss: 43648.9271 | l_Loss: 8524.8147 | 
                                                                                 882		115329.8184		-4.5000
25-09-27 18:10:12.336 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:10:12.338 - INFO: Train epoch 883:   Loss: 29316.6797 | r_Loss: 2656.8437 | g_Loss: 15433.0275 | l_Loss: 599.4329 | 
                                                                                 883		29316.6797		-4.5000
25-09-27 18:10:40.752 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:10:40.753 - INFO: Train epoch 884:   Loss: 19185.9151 | r_Loss: 1781.1934 | g_Loss: 10019.7939 | l_Loss: 260.1539 | 
                                                                                 884		19185.9151		-4.5000
25-09-27 18:10:52.015 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:10:52.017 - INFO: Train epoch 885:   Loss: 15268.2355 | r_Loss: 1439.0956 | g_Loss: 7905.8502 | l_Loss: 166.9069 | 
                                                                                 885		15268.2355		-4.5000
25-09-27 18:11:04.313 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:11:04.315 - INFO: Train epoch 886:   Loss: 13233.3200 | r_Loss: 1249.7583 | g_Loss: 6856.3318 | l_Loss: 128.1964 | 
                                                                                 886		13233.3200		-4.5000
25-09-27 18:11:15.486 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:11:15.487 - INFO: Train epoch 887:   Loss: 11673.9281 | r_Loss: 1092.8402 | g_Loss: 6105.1484 | l_Loss: 104.5788 | 
                                                                                 887		11673.9281		-4.5000
25-09-27 18:11:26.650 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:11:26.651 - INFO: Train epoch 888:   Loss: 10574.9720 | r_Loss: 994.8120 | g_Loss: 5510.1344 | l_Loss: 90.7777 | 
                                                                                 888		10574.9720		-4.5000
25-09-27 18:11:43.680 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:11:43.682 - INFO: Train epoch 889:   Loss: 9986.5474 | r_Loss: 955.5882 | g_Loss: 5122.5834 | l_Loss: 86.0229 | 
                                                                                 889		9986.5474		-4.5000
25-09-27 18:11:54.801 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:11:54.803 - INFO: Train epoch 890:   Loss: 9681.5643 | r_Loss: 962.6916 | g_Loss: 4787.1167 | l_Loss: 80.9898 | 
                                                                                 890		9681.5643		-4.5000
25-09-27 18:12:06.054 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:12:06.056 - INFO: Train epoch 891:   Loss: 8831.8054 | r_Loss: 861.6043 | g_Loss: 4448.2078 | l_Loss: 75.5760 | 
                                                                                 891		8831.8054		-4.5000
25-09-27 18:12:18.756 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:12:18.758 - INFO: Train epoch 892:   Loss: 8838.4664 | r_Loss: 909.7433 | g_Loss: 4217.5606 | l_Loss: 72.1893 | 
                                                                                 892		8838.4664		-4.5000
25-09-27 18:12:30.014 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:12:30.016 - INFO: Train epoch 893:   Loss: 11958.3302 | r_Loss: 1580.2015 | g_Loss: 3987.0914 | l_Loss: 70.2310 | 
                                                                                 893		11958.3302		-4.5000
25-09-27 18:12:41.171 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:12:41.172 - INFO: Train epoch 894:   Loss: 8352.5943 | r_Loss: 831.5425 | g_Loss: 4123.6890 | l_Loss: 71.1929 | 
                                                                                 894		8352.5943		-4.5000
25-09-27 18:12:55.558 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:12:55.559 - INFO: Train epoch 895:   Loss: 7531.3373 | r_Loss: 722.0623 | g_Loss: 3857.0224 | l_Loss: 64.0031 | 
                                                                                 895		7531.3373		-4.5000
25-09-27 18:13:06.771 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:13:06.773 - INFO: Train epoch 896:   Loss: 7260.7724 | r_Loss: 721.5205 | g_Loss: 3592.6985 | l_Loss: 60.4714 | 
                                                                                 896		7260.7724		-4.5000
25-09-27 18:13:51.472 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:13:51.474 - INFO: Train epoch 897:   Loss: 6986.9763 | r_Loss: 697.4609 | g_Loss: 3441.5653 | l_Loss: 58.1066 | 
                                                                                 897		6986.9763		-4.5000
25-09-27 18:14:02.658 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:14:02.660 - INFO: Train epoch 898:   Loss: 6925.5784 | r_Loss: 697.7219 | g_Loss: 3379.3482 | l_Loss: 57.6207 | 
                                                                                 898		6925.5784		-4.5000
25-09-27 18:14:13.912 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:14:13.914 - INFO: Train epoch 899:   Loss: 6607.7405 | r_Loss: 667.7738 | g_Loss: 3213.4075 | l_Loss: 55.4640 | 
                                                                                 899		6607.7405		-4.5000
25-09-27 18:27:39.116 - INFO: TEST:   PSNR_S: 35.6088 | PSNR_C: 25.6141 | 
25-09-27 18:27:39.117 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:27:39.118 - INFO: Train epoch 900:   Loss: 6516.5556 | r_Loss: 666.9836 | g_Loss: 3126.8676 | l_Loss: 54.7701 | 
                                                                                 900		6516.5556		-4.5000
25-09-27 18:28:02.854 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:28:02.855 - INFO: Train epoch 901:   Loss: 6460.0423 | r_Loss: 672.9327 | g_Loss: 3041.5813 | l_Loss: 53.7973 | 
                                                                                 901		6460.0423		-4.5000
25-09-27 18:29:22.352 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:29:22.354 - INFO: Train epoch 902:   Loss: 6174.6290 | r_Loss: 643.2812 | g_Loss: 2907.1060 | l_Loss: 51.1171 | 
                                                                                 902		6174.6290		-4.5000
25-09-27 18:29:33.519 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:29:33.521 - INFO: Train epoch 903:   Loss: 6161.8344 | r_Loss: 651.0564 | g_Loss: 2855.2042 | l_Loss: 51.3482 | 
                                                                                 903		6161.8344		-4.5000
25-09-27 18:29:44.692 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:29:44.694 - INFO: Train epoch 904:   Loss: 5920.6831 | r_Loss: 627.9254 | g_Loss: 2731.0461 | l_Loss: 50.0100 | 
                                                                                 904		5920.6831		-4.5000
25-09-27 18:30:22.966 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:30:22.968 - INFO: Train epoch 905:   Loss: 5922.4510 | r_Loss: 638.1791 | g_Loss: 2681.6118 | l_Loss: 49.9435 | 
                                                                                 905		5922.4510		-4.5000
25-09-27 18:30:34.320 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:30:34.321 - INFO: Train epoch 906:   Loss: 5883.6084 | r_Loss: 640.6608 | g_Loss: 2631.2077 | l_Loss: 49.0967 | 
                                                                                 906		5883.6084		-4.5000
25-09-27 18:31:01.081 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:31:01.083 - INFO: Train epoch 907:   Loss: 5804.0469 | r_Loss: 647.3596 | g_Loss: 2519.1788 | l_Loss: 48.0699 | 
                                                                                 907		5804.0469		-4.5000
25-09-27 18:31:48.628 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:31:48.629 - INFO: Train epoch 908:   Loss: 5974.7729 | r_Loss: 681.2203 | g_Loss: 2521.0071 | l_Loss: 47.6642 | 
                                                                                 908		5974.7729		-4.5000
25-09-27 18:32:02.966 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:32:02.967 - INFO: Train epoch 909:   Loss: 5463.6570 | r_Loss: 609.2243 | g_Loss: 2372.6323 | l_Loss: 44.9033 | 
                                                                                 909		5463.6570		-4.5000
25-09-27 18:32:26.189 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:32:26.191 - INFO: Train epoch 910:   Loss: 5641.7112 | r_Loss: 643.5131 | g_Loss: 2378.4186 | l_Loss: 45.7268 | 
                                                                                 910		5641.7112		-4.5000
25-09-27 18:32:37.456 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:32:37.457 - INFO: Train epoch 911:   Loss: 5191.1192 | r_Loss: 569.0368 | g_Loss: 2302.0355 | l_Loss: 43.8998 | 
                                                                                 911		5191.1192		-4.5000
25-09-27 18:32:49.600 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:32:49.601 - INFO: Train epoch 912:   Loss: 5364.7697 | r_Loss: 602.9151 | g_Loss: 2305.3311 | l_Loss: 44.8631 | 
                                                                                 912		5364.7697		-4.5000
25-09-27 18:33:00.694 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:33:00.695 - INFO: Train epoch 913:   Loss: 5218.2330 | r_Loss: 584.3475 | g_Loss: 2252.5557 | l_Loss: 43.9395 | 
                                                                                 913		5218.2330		-4.5000
25-09-27 18:33:31.137 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:33:31.139 - INFO: Train epoch 914:   Loss: 5310.8081 | r_Loss: 610.3912 | g_Loss: 2215.1695 | l_Loss: 43.6830 | 
                                                                                 914		5310.8081		-4.5000
25-09-27 18:33:50.201 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:33:50.203 - INFO: Train epoch 915:   Loss: 5480.4482 | r_Loss: 657.3819 | g_Loss: 2150.5367 | l_Loss: 43.0021 | 
                                                                                 915		5480.4482		-4.5000
25-09-27 18:34:16.966 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:34:16.967 - INFO: Train epoch 916:   Loss: 5098.5564 | r_Loss: 580.8622 | g_Loss: 2151.5784 | l_Loss: 42.6670 | 
                                                                                 916		5098.5564		-4.5000
25-09-27 18:34:28.684 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:34:28.685 - INFO: Train epoch 917:   Loss: 5003.6895 | r_Loss: 568.4183 | g_Loss: 2118.8480 | l_Loss: 42.7499 | 
                                                                                 917		5003.6895		-4.5000
25-09-27 18:34:39.864 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:34:39.866 - INFO: Train epoch 918:   Loss: 4991.8079 | r_Loss: 578.6408 | g_Loss: 2056.6105 | l_Loss: 41.9935 | 
                                                                                 918		4991.8079		-4.5000
25-09-27 18:34:51.881 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:34:51.883 - INFO: Train epoch 919:   Loss: 4964.9901 | r_Loss: 582.3111 | g_Loss: 2012.8712 | l_Loss: 40.5633 | 
                                                                                 919		4964.9901		-4.5000
25-09-27 18:35:13.695 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:35:13.696 - INFO: Train epoch 920:   Loss: 4886.3833 | r_Loss: 568.0998 | g_Loss: 2005.0826 | l_Loss: 40.8018 | 
                                                                                 920		4886.3833		-4.5000
25-09-27 18:35:49.489 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:35:49.490 - INFO: Train epoch 921:   Loss: 4846.8857 | r_Loss: 564.5906 | g_Loss: 1982.7875 | l_Loss: 41.1451 | 
                                                                                 921		4846.8857		-4.5000
25-09-27 18:36:00.679 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:36:00.680 - INFO: Train epoch 922:   Loss: 4965.7869 | r_Loss: 594.5267 | g_Loss: 1952.9887 | l_Loss: 40.1647 | 
                                                                                 922		4965.7869		-4.5000
25-09-27 18:36:18.266 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:36:18.268 - INFO: Train epoch 923:   Loss: 4707.4322 | r_Loss: 541.8110 | g_Loss: 1957.8801 | l_Loss: 40.4970 | 
                                                                                 923		4707.4322		-4.5000
25-09-27 18:36:29.543 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:36:29.545 - INFO: Train epoch 924:   Loss: 4505.2793 | r_Loss: 523.0546 | g_Loss: 1851.6393 | l_Loss: 38.3672 | 
                                                                                 924		4505.2793		-4.5000
25-09-27 18:38:01.689 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:38:01.691 - INFO: Train epoch 925:   Loss: 4480.5353 | r_Loss: 515.9306 | g_Loss: 1862.2178 | l_Loss: 38.6647 | 
                                                                                 925		4480.5353		-4.5000
25-09-27 18:38:13.024 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:38:13.026 - INFO: Train epoch 926:   Loss: 4487.2363 | r_Loss: 523.5317 | g_Loss: 1830.8489 | l_Loss: 38.7287 | 
                                                                                 926		4487.2363		-4.5000
25-09-27 18:38:50.693 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:38:50.695 - INFO: Train epoch 927:   Loss: 4481.4865 | r_Loss: 523.0370 | g_Loss: 1827.3863 | l_Loss: 38.9150 | 
                                                                                 927		4481.4865		-4.5000
25-09-27 18:39:01.784 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:39:01.785 - INFO: Train epoch 928:   Loss: 5828.8769 | r_Loss: 787.3679 | g_Loss: 1851.2376 | l_Loss: 40.7996 | 
                                                                                 928		5828.8769		-4.5000
25-09-27 18:39:13.030 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:39:13.031 - INFO: Train epoch 929:   Loss: 4465.0425 | r_Loss: 518.8512 | g_Loss: 1831.2907 | l_Loss: 39.4957 | 
                                                                                 929		4465.0425		-4.5000
25-09-27 18:39:32.324 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:39:32.325 - INFO: Train epoch 930:   Loss: 4389.9132 | r_Loss: 511.3529 | g_Loss: 1793.9345 | l_Loss: 39.2142 | 
                                                                                 930		4389.9132		-4.5000
25-09-27 18:39:44.657 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:39:44.658 - INFO: Train epoch 931:   Loss: 4316.4780 | r_Loss: 501.7673 | g_Loss: 1768.9778 | l_Loss: 38.6637 | 
                                                                                 931		4316.4780		-4.5000
25-09-27 18:41:08.660 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:41:08.661 - INFO: Train epoch 932:   Loss: 4349.9274 | r_Loss: 508.4091 | g_Loss: 1769.0876 | l_Loss: 38.7941 | 
                                                                                 932		4349.9274		-4.5000
25-09-27 18:41:20.002 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:41:20.003 - INFO: Train epoch 933:   Loss: 4320.7300 | r_Loss: 507.2974 | g_Loss: 1745.9329 | l_Loss: 38.3100 | 
                                                                                 933		4320.7300		-4.5000
25-09-27 18:41:31.083 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:41:31.085 - INFO: Train epoch 934:   Loss: 4238.1627 | r_Loss: 497.3432 | g_Loss: 1712.9662 | l_Loss: 38.4802 | 
                                                                                 934		4238.1627		-4.5000
25-09-27 18:41:44.137 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:41:44.138 - INFO: Train epoch 935:   Loss: 4206.7399 | r_Loss: 493.2855 | g_Loss: 1702.6708 | l_Loss: 37.6416 | 
                                                                                 935		4206.7399		-4.5000
25-09-27 18:41:55.328 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:41:55.329 - INFO: Train epoch 936:   Loss: 4074.1042 | r_Loss: 477.8616 | g_Loss: 1647.8157 | l_Loss: 36.9805 | 
                                                                                 936		4074.1042		-4.5000
25-09-27 18:42:24.213 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:42:24.214 - INFO: Train epoch 937:   Loss: 4160.9185 | r_Loss: 492.1988 | g_Loss: 1662.0385 | l_Loss: 37.8863 | 
                                                                                 937		4160.9185		-4.5000
25-09-27 18:42:35.459 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:42:35.460 - INFO: Train epoch 938:   Loss: 4022.7719 | r_Loss: 471.8872 | g_Loss: 1626.8427 | l_Loss: 36.4934 | 
                                                                                 938		4022.7719		-4.5000
25-09-27 18:43:03.638 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:43:03.639 - INFO: Train epoch 939:   Loss: 4052.4508 | r_Loss: 479.9212 | g_Loss: 1615.9212 | l_Loss: 36.9237 | 
                                                                                 939		4052.4508		-4.5000
25-09-27 18:43:49.931 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:43:49.933 - INFO: Train epoch 940:   Loss: 4396.2269 | r_Loss: 552.3401 | g_Loss: 1597.5197 | l_Loss: 37.0068 | 
                                                                                 940		4396.2269		-4.5000
25-09-27 18:44:01.645 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:44:01.646 - INFO: Train epoch 941:   Loss: 4341.9954 | r_Loss: 533.8644 | g_Loss: 1634.9921 | l_Loss: 37.6811 | 
                                                                                 941		4341.9954		-4.5000
25-09-27 18:44:25.046 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:44:25.047 - INFO: Train epoch 942:   Loss: 3936.9728 | r_Loss: 465.3590 | g_Loss: 1573.2627 | l_Loss: 36.9150 | 
                                                                                 942		3936.9728		-4.5000
25-09-27 18:44:36.087 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:44:36.088 - INFO: Train epoch 943:   Loss: 3797.4550 | r_Loss: 444.1468 | g_Loss: 1541.6454 | l_Loss: 35.0755 | 
                                                                                 943		3797.4550		-4.5000
25-09-27 18:44:50.027 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:44:50.029 - INFO: Train epoch 944:   Loss: 3903.8614 | r_Loss: 465.6900 | g_Loss: 1539.2797 | l_Loss: 36.1316 | 
                                                                                 944		3903.8614		-4.5000
25-09-27 18:45:01.284 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:45:01.285 - INFO: Train epoch 945:   Loss: 3814.9077 | r_Loss: 452.7326 | g_Loss: 1515.3675 | l_Loss: 35.8771 | 
                                                                                 945		3814.9077		-4.5000
25-09-27 18:45:21.402 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:45:21.404 - INFO: Train epoch 946:   Loss: 3873.8342 | r_Loss: 457.3712 | g_Loss: 1550.7121 | l_Loss: 36.2661 | 
                                                                                 946		3873.8342		-4.5000
25-09-27 18:45:32.581 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:45:32.582 - INFO: Train epoch 947:   Loss: 3969.3935 | r_Loss: 484.2451 | g_Loss: 1512.3562 | l_Loss: 35.8116 | 
                                                                                 947		3969.3935		-4.5000
25-09-27 18:45:48.668 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:45:48.670 - INFO: Train epoch 948:   Loss: 3918.4911 | r_Loss: 465.9629 | g_Loss: 1551.8762 | l_Loss: 36.8005 | 
                                                                                 948		3918.4911		-4.5000
25-09-27 18:45:59.888 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 18:45:59.889 - INFO: Train epoch 949:   Loss: 4150.3993 | r_Loss: 517.6448 | g_Loss: 1525.4345 | l_Loss: 36.7409 | 
                                                                                 949		4150.3993		-4.5000
25-09-27 19:00:04.471 - INFO: TEST:   PSNR_S: 38.5227 | PSNR_C: 29.7997 | 
25-09-27 19:00:04.473 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:00:04.474 - INFO: Train epoch 950:   Loss: 3852.5288 | r_Loss: 459.0054 | g_Loss: 1521.1128 | l_Loss: 36.3892 | 
                                                                                 950		3852.5288		-4.5000
25-09-27 19:01:14.659 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:01:14.660 - INFO: Train epoch 951:   Loss: 3790.0281 | r_Loss: 451.2068 | g_Loss: 1497.7848 | l_Loss: 36.2091 | 
                                                                                 951		3790.0281		-4.5000
25-09-27 19:01:26.024 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:01:26.026 - INFO: Train epoch 952:   Loss: 3635.8483 | r_Loss: 430.4474 | g_Loss: 1448.5553 | l_Loss: 35.0561 | 
                                                                                 952		3635.8483		-4.5000
25-09-27 19:01:37.063 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:01:37.064 - INFO: Train epoch 953:   Loss: 3765.7585 | r_Loss: 451.1798 | g_Loss: 1473.7918 | l_Loss: 36.0677 | 
                                                                                 953		3765.7585		-4.5000
25-09-27 19:01:48.182 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:01:48.184 - INFO: Train epoch 954:   Loss: 3677.8705 | r_Loss: 438.3488 | g_Loss: 1450.5066 | l_Loss: 35.6200 | 
                                                                                 954		3677.8705		-4.5000
25-09-27 19:01:59.365 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:01:59.367 - INFO: Train epoch 955:   Loss: 3878.1974 | r_Loss: 482.1488 | g_Loss: 1431.9822 | l_Loss: 35.4710 | 
                                                                                 955		3878.1974		-4.5000
25-09-27 19:02:10.646 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:02:10.648 - INFO: Train epoch 956:   Loss: 3673.1795 | r_Loss: 441.2322 | g_Loss: 1432.3383 | l_Loss: 34.6805 | 
                                                                                 956		3673.1795		-4.5000
25-09-27 19:02:21.942 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:02:21.944 - INFO: Train epoch 957:   Loss: 3698.5209 | r_Loss: 443.3360 | g_Loss: 1445.9258 | l_Loss: 35.9152 | 
                                                                                 957		3698.5209		-4.5000
25-09-27 19:02:33.110 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:02:33.112 - INFO: Train epoch 958:   Loss: 3548.3034 | r_Loss: 425.2346 | g_Loss: 1388.2443 | l_Loss: 33.8860 | 
                                                                                 958		3548.3034		-4.5000
25-09-27 19:02:44.407 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:02:44.409 - INFO: Train epoch 959:   Loss: 3743.8937 | r_Loss: 454.6297 | g_Loss: 1435.2467 | l_Loss: 35.4986 | 
                                                                                 959		3743.8937		-4.5000
25-09-27 19:02:55.625 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:02:55.627 - INFO: Train epoch 960:   Loss: 3760.4635 | r_Loss: 460.4450 | g_Loss: 1422.7316 | l_Loss: 35.5066 | 
                                                                                 960		3760.4635		-4.5000
25-09-27 19:03:06.973 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:03:06.975 - INFO: Train epoch 961:   Loss: 3747.3251 | r_Loss: 458.0350 | g_Loss: 1422.0536 | l_Loss: 35.0963 | 
                                                                                 961		3747.3251		-4.5000
25-09-27 19:03:18.245 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:03:18.247 - INFO: Train epoch 962:   Loss: 3594.1628 | r_Loss: 432.5636 | g_Loss: 1396.4183 | l_Loss: 34.9266 | 
                                                                                 962		3594.1628		-4.5000
25-09-27 19:03:29.583 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:03:29.585 - INFO: Train epoch 963:   Loss: 3710.6796 | r_Loss: 449.5488 | g_Loss: 1426.9743 | l_Loss: 35.9611 | 
                                                                                 963		3710.6796		-4.5000
25-09-27 19:03:40.728 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:03:40.729 - INFO: Train epoch 964:   Loss: 3731.5969 | r_Loss: 456.0905 | g_Loss: 1415.5982 | l_Loss: 35.5462 | 
                                                                                 964		3731.5969		-4.5000
25-09-27 19:03:51.921 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:03:51.922 - INFO: Train epoch 965:   Loss: 3562.3965 | r_Loss: 432.7599 | g_Loss: 1364.5751 | l_Loss: 34.0222 | 
                                                                                 965		3562.3965		-4.5000
25-09-27 19:04:03.070 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:04:03.071 - INFO: Train epoch 966:   Loss: 3605.9445 | r_Loss: 436.5306 | g_Loss: 1387.8931 | l_Loss: 35.3986 | 
                                                                                 966		3605.9445		-4.5000
25-09-27 19:04:14.402 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:04:14.403 - INFO: Train epoch 967:   Loss: 3609.8203 | r_Loss: 441.4591 | g_Loss: 1367.8845 | l_Loss: 34.6405 | 
                                                                                 967		3609.8203		-4.5000
25-09-27 19:04:25.586 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:04:25.587 - INFO: Train epoch 968:   Loss: 3599.4549 | r_Loss: 437.4036 | g_Loss: 1377.6864 | l_Loss: 34.7506 | 
                                                                                 968		3599.4549		-4.5000
25-09-27 19:04:36.770 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:04:36.772 - INFO: Train epoch 969:   Loss: 3548.0512 | r_Loss: 431.1093 | g_Loss: 1357.8771 | l_Loss: 34.6275 | 
                                                                                 969		3548.0512		-4.5000
25-09-27 19:04:47.953 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:04:47.954 - INFO: Train epoch 970:   Loss: 3604.0115 | r_Loss: 445.1150 | g_Loss: 1344.5731 | l_Loss: 33.8636 | 
                                                                                 970		3604.0115		-4.5000
25-09-27 19:04:59.099 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:04:59.101 - INFO: Train epoch 971:   Loss: 3396.8637 | r_Loss: 407.5702 | g_Loss: 1325.3883 | l_Loss: 33.6246 | 
                                                                                 971		3396.8637		-4.5000
25-09-27 19:05:10.313 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:05:10.315 - INFO: Train epoch 972:   Loss: 3573.8208 | r_Loss: 436.5792 | g_Loss: 1356.4403 | l_Loss: 34.4844 | 
                                                                                 972		3573.8208		-4.5000
25-09-27 19:05:21.645 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:05:21.646 - INFO: Train epoch 973:   Loss: 3522.9289 | r_Loss: 430.7548 | g_Loss: 1335.0194 | l_Loss: 34.1356 | 
                                                                                 973		3522.9289		-4.5000
25-09-27 19:05:32.849 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:05:32.850 - INFO: Train epoch 974:   Loss: 3496.2376 | r_Loss: 423.7039 | g_Loss: 1343.2268 | l_Loss: 34.4912 | 
                                                                                 974		3496.2376		-4.5000
25-09-27 19:05:44.239 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:05:44.240 - INFO: Train epoch 975:   Loss: 3389.4064 | r_Loss: 405.9412 | g_Loss: 1325.8947 | l_Loss: 33.8059 | 
                                                                                 975		3389.4064		-4.5000
25-09-27 19:05:55.501 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:05:55.503 - INFO: Train epoch 976:   Loss: 3431.0511 | r_Loss: 418.0408 | g_Loss: 1306.7423 | l_Loss: 34.1049 | 
                                                                                 976		3431.0511		-4.5000
25-09-27 19:06:06.775 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:06:06.777 - INFO: Train epoch 977:   Loss: 3660.7748 | r_Loss: 459.5465 | g_Loss: 1327.5856 | l_Loss: 35.4566 | 
                                                                                 977		3660.7748		-4.5000
25-09-27 19:06:17.989 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:06:17.990 - INFO: Train epoch 978:   Loss: 3369.8400 | r_Loss: 403.9488 | g_Loss: 1316.1939 | l_Loss: 33.9024 | 
                                                                                 978		3369.8400		-4.5000
25-09-27 19:06:29.255 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:06:29.257 - INFO: Train epoch 979:   Loss: 3353.7935 | r_Loss: 401.5882 | g_Loss: 1312.4007 | l_Loss: 33.4519 | 
                                                                                 979		3353.7935		-4.5000
25-09-27 19:06:40.668 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:06:40.669 - INFO: Train epoch 980:   Loss: 3606.7411 | r_Loss: 457.1206 | g_Loss: 1286.8023 | l_Loss: 34.3358 | 
                                                                                 980		3606.7411		-4.5000
25-09-27 19:06:52.007 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:06:52.008 - INFO: Train epoch 981:   Loss: 3403.0037 | r_Loss: 409.8710 | g_Loss: 1319.4313 | l_Loss: 34.2174 | 
                                                                                 981		3403.0037		-4.5000
25-09-27 19:07:03.203 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:07:03.204 - INFO: Train epoch 982:   Loss: 3353.2905 | r_Loss: 405.4378 | g_Loss: 1292.1154 | l_Loss: 33.9860 | 
                                                                                 982		3353.2905		-4.5000
25-09-27 19:07:20.684 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:07:20.685 - INFO: Train epoch 983:   Loss: 3319.4536 | r_Loss: 397.4379 | g_Loss: 1298.7245 | l_Loss: 33.5397 | 
                                                                                 983		3319.4536		-4.5000
25-09-27 19:07:31.970 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:07:31.971 - INFO: Train epoch 984:   Loss: 3300.0287 | r_Loss: 397.5260 | g_Loss: 1279.1851 | l_Loss: 33.2135 | 
                                                                                 984		3300.0287		-4.5000
25-09-27 19:07:43.361 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:07:43.363 - INFO: Train epoch 985:   Loss: 3355.7033 | r_Loss: 405.2541 | g_Loss: 1295.4739 | l_Loss: 33.9590 | 
                                                                                 985		3355.7033		-4.5000
25-09-27 19:07:54.530 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:07:54.532 - INFO: Train epoch 986:   Loss: 3294.3612 | r_Loss: 399.5144 | g_Loss: 1263.1562 | l_Loss: 33.6329 | 
                                                                                 986		3294.3612		-4.5000
25-09-27 19:08:05.693 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:08:05.695 - INFO: Train epoch 987:   Loss: 3403.6011 | r_Loss: 423.0433 | g_Loss: 1255.0510 | l_Loss: 33.3338 | 
                                                                                 987		3403.6011		-4.5000
25-09-27 19:08:16.947 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:08:16.949 - INFO: Train epoch 988:   Loss: 3303.7087 | r_Loss: 402.9222 | g_Loss: 1254.3300 | l_Loss: 34.7679 | 
                                                                                 988		3303.7087		-4.5000
25-09-27 19:08:28.150 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:08:28.152 - INFO: Train epoch 989:   Loss: 3281.0209 | r_Loss: 399.8504 | g_Loss: 1248.9829 | l_Loss: 32.7860 | 
                                                                                 989		3281.0209		-4.5000
25-09-27 19:08:39.476 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:08:39.477 - INFO: Train epoch 990:   Loss: 3447.3466 | r_Loss: 430.1799 | g_Loss: 1258.5440 | l_Loss: 37.9031 | 
                                                                                 990		3447.3466		-4.5000
25-09-27 19:08:50.748 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:08:50.749 - INFO: Train epoch 991:   Loss: 3381.6019 | r_Loss: 416.1893 | g_Loss: 1265.7600 | l_Loss: 34.8952 | 
                                                                                 991		3381.6019		-4.5000
25-09-27 19:09:01.910 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:09:01.911 - INFO: Train epoch 992:   Loss: 3200.4633 | r_Loss: 383.3546 | g_Loss: 1250.1298 | l_Loss: 33.5607 | 
                                                                                 992		3200.4633		-4.5000
25-09-27 19:09:13.288 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:09:13.289 - INFO: Train epoch 993:   Loss: 3171.4923 | r_Loss: 378.8615 | g_Loss: 1244.1499 | l_Loss: 33.0350 | 
                                                                                 993		3171.4923		-4.5000
25-09-27 19:09:24.579 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:09:24.581 - INFO: Train epoch 994:   Loss: 3192.7319 | r_Loss: 386.4286 | g_Loss: 1228.0412 | l_Loss: 32.5475 | 
                                                                                 994		3192.7319		-4.5000
25-09-27 19:09:36.017 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:09:36.019 - INFO: Train epoch 995:   Loss: 3329.3347 | r_Loss: 410.3210 | g_Loss: 1244.5908 | l_Loss: 33.1392 | 
                                                                                 995		3329.3347		-4.5000
25-09-27 19:09:47.168 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:09:47.169 - INFO: Train epoch 996:   Loss: 3358.9196 | r_Loss: 412.7374 | g_Loss: 1260.8972 | l_Loss: 34.3356 | 
                                                                                 996		3358.9196		-4.5000
25-09-27 19:09:58.326 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:09:58.327 - INFO: Train epoch 997:   Loss: 3254.5298 | r_Loss: 391.7527 | g_Loss: 1262.1707 | l_Loss: 33.5954 | 
                                                                                 997		3254.5298		-4.5000
25-09-27 19:10:09.503 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:10:09.504 - INFO: Train epoch 998:   Loss: 3057.4236 | r_Loss: 365.5810 | g_Loss: 1197.1813 | l_Loss: 32.3375 | 
                                                                                 998		3057.4236		-4.5000
25-09-27 19:10:20.752 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:10:20.753 - INFO: Train epoch 999:   Loss: 3116.3426 | r_Loss: 377.0526 | g_Loss: 1198.1235 | l_Loss: 32.9564 | 
                                                                                 999		3116.3426		-4.5000
25-09-27 19:23:54.184 - INFO: TEST:   PSNR_S: 39.8498 | PSNR_C: 31.3472 | 
25-09-27 19:23:54.186 - INFO: Learning rate: 3.1622776601683795e-05
25-09-27 19:23:54.187 - INFO: Train epoch 1000:   Loss: 3275.5512 | r_Loss: 402.5694 | g_Loss: 1229.8763 | l_Loss: 32.8281 | 
                                                                                 1000		3275.5512		-4.5000
